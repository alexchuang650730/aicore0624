#!/usr/bin/env python3
"""
REQ_001 AICore è™•ç†å™¨
å°ˆé–€è™•ç† REQ_001: ç”¨æˆ¶ç•Œé¢è¨­è¨ˆéœ€æ±‚çš„ AICore è™•ç†å™¨
åŸºæ–¼ AICore éœ€æ±‚è™•ç†å™¨æ¡†æ¶ï¼Œé‡å°ç”¨æˆ¶çš„å…·é«”éœ€æ±‚é€²è¡Œå„ªåŒ–
"""

import asyncio
import json
import logging
import time
from datetime import datetime
from typing import Dict, List, Optional, Any
from pathlib import Path

# å°å…¥ AICore éœ€æ±‚è™•ç†å™¨
from components.aicore_requirement_processor_mcp import AICoreRequirementProcessor

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class REQ001AICoreProcessor:
    """REQ_001 å°ˆç”¨ AICore è™•ç†å™¨"""
    
    def __init__(self):
        self.base_processor = AICoreRequirementProcessor()
        self.req_001_context = {
            "target_requirement": "REQ_001",
            "requirement_title": "ç”¨æˆ¶ç•Œé¢è¨­è¨ˆéœ€æ±‚",
            "focus_areas": [
                "æ™ºæ…§ä¸‹è¼‰åŠŸèƒ½å°èˆªæ¬„æ•´åˆ",
                "UI/UXè¨­è¨ˆå„ªåŒ–",
                "è·¨ä»»å‹™éœ€æ±‚åˆ†æ",
                "æª”æ¡ˆé—œè¯åˆ†æ"
            ],
            "expected_outputs": [
                "æ˜ç¢ºéœ€æ±‚åˆ—è¡¨",
                "Manus action æ¸…å–®",
                "ç›¸é—œæª”æ¡ˆåˆ—è¡¨",
                "è·¨ä»»å‹™é—œè¯åˆ†æ"
            ]
        }
    
    async def initialize(self):
        """åˆå§‹åŒ–è™•ç†å™¨"""
        logger.info("ğŸš€ åˆå§‹åŒ– REQ_001 AICore è™•ç†å™¨")
        await self.base_processor.initialize()
        logger.info("âœ… REQ_001 AICore è™•ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def process_user_requirement(self) -> Dict[str, Any]:
        """è™•ç†ç”¨æˆ¶çš„å…·é«”éœ€æ±‚"""
        logger.info("ğŸ¯ é–‹å§‹è™•ç†ç”¨æˆ¶éœ€æ±‚: REQ_001 åˆ†æ")
        
        # ç”¨æˆ¶çš„åŸå§‹éœ€æ±‚
        user_requirement = "é¦–å…ˆå…ˆé‡å° REQ_001: ç”¨æˆ¶ç•Œé¢è¨­è¨ˆéœ€æ±‚ åˆ—å‡ºæˆ‘çš„æ˜ç¢ºéœ€æ±‚ åŠmanus action åŒ…å«ç›¸é—œçš„æª”æ¡ˆåˆ—è¡¨ æ³¨æ„åŒä¸€å€‹éœ€æ±‚å¯èƒ½è·¨ä»»å‹™"
        
        try:
            # ä½¿ç”¨ AICore éœ€æ±‚è™•ç†å™¨è™•ç†
            result = await self.base_processor.process_requirement(
                user_requirement, 
                self.req_001_context
            )
            
            # æ ¼å¼åŒ–ç‚ºç”¨æˆ¶å‹å¥½çš„è¼¸å‡º
            formatted_result = await self._format_user_friendly_output(result)
            
            # ä¿å­˜çµæœ
            await self._save_processing_result(formatted_result)
            
            logger.info("âœ… REQ_001 éœ€æ±‚è™•ç†å®Œæˆ")
            return formatted_result
            
        except Exception as e:
            logger.error(f"âŒ REQ_001 éœ€æ±‚è™•ç†å¤±æ•—: {e}")
            raise
    
    async def _format_user_friendly_output(self, result) -> Dict[str, Any]:
        """æ ¼å¼åŒ–ç‚ºç”¨æˆ¶å‹å¥½çš„è¼¸å‡º"""
        logger.info("ğŸ“‹ æ ¼å¼åŒ–ç”¨æˆ¶å‹å¥½è¼¸å‡º")
        
        # æå–æ˜ç¢ºéœ€æ±‚åˆ—è¡¨
        requirements_list = []
        for req in result.requirements_list:
            requirements_list.append({
                "éœ€æ±‚ID": req.requirement_id,
                "éœ€æ±‚æ¨™é¡Œ": req.title,
                "éœ€æ±‚æè¿°": req.description,
                "å„ªå…ˆç´š": req.priority,
                "ä¾†æºä»»å‹™": req.source_tasks,
                "æŠ€è¡“è¤‡é›œåº¦": req.technical_complexity,
                "é ä¼°å·¥æ™‚": f"{req.estimated_hours}å°æ™‚",
                "éœ€æ±‚é¡åˆ¥": req.category
            })
        
        # æå– Manus Actions
        manus_actions = []
        for action in result.manus_actions:
            manus_actions.append({
                "è¡Œå‹•ID": action.action_id,
                "è¡Œå‹•é¡å‹": action.action_type,
                "æè¿°": action.description,
                "ç›¸é—œä»»å‹™": action.related_tasks,
                "åŸ·è¡Œç‹€æ…‹": action.execution_status,
                "å„ªå…ˆç´š": action.priority,
                "é ä¼°å·¥ä½œé‡": action.estimated_effort
            })
        
        # æå–æª”æ¡ˆåˆ—è¡¨
        file_list = []
        for file_ref in result.file_references:
            file_list.append({
                "æª”æ¡ˆè·¯å¾‘": file_ref.file_path,
                "æª”æ¡ˆé¡å‹": file_ref.file_type,
                "ç›¸é—œæ€§è©•åˆ†": f"{file_ref.relevance_score:.2f}",
                "è·¨ä»»å‹™é—œè¯": file_ref.cross_task_relations,
                "æè¿°": file_ref.description
            })
        
        # è·¨ä»»å‹™åˆ†æ
        cross_task_analysis = {
            "é—œè¯ä»»å‹™æ•¸é‡": result.cross_task_analysis.related_task_count,
            "å…±äº«éœ€æ±‚": result.cross_task_analysis.shared_requirements,
            "ä¾è³´é—œä¿‚éˆ": result.cross_task_analysis.dependency_chain,
            "å½±éŸ¿è©•ä¼°": result.cross_task_analysis.impact_assessment,
            "å”èª¿éœ€æ±‚": result.cross_task_analysis.coordination_needs
        }
        
        # è™•ç†çµ±è¨ˆ
        processing_stats = {
            "åˆ†æä»»å‹™ç¸½æ•¸": result.processing_metrics.get("total_tasks_analyzed", 0),
            "è­˜åˆ¥éœ€æ±‚æ•¸é‡": result.processing_metrics.get("requirements_identified", 0),
            "ç”Ÿæˆè¡Œå‹•æ•¸é‡": result.processing_metrics.get("actions_generated", 0),
            "åˆ†ææª”æ¡ˆæ•¸é‡": result.processing_metrics.get("files_analyzed", 0),
            "å°ˆå®¶ä¿¡å¿ƒå¹³å‡å€¼": f"{result.processing_metrics.get('expert_confidence_average', 0.0):.2f}"
        }
        
        return {
            "REQ_001_åˆ†æçµæœ": {
                "åˆ†ææ™‚é–“": result.analysis_timestamp,
                "æ˜ç¢ºéœ€æ±‚åˆ—è¡¨": requirements_list,
                "Manus_Actions": manus_actions,
                "ç›¸é—œæª”æ¡ˆåˆ—è¡¨": file_list,
                "è·¨ä»»å‹™åˆ†æ": cross_task_analysis,
                "è™•ç†çµ±è¨ˆ": processing_stats,
                "å°ˆå®¶æ´å¯Ÿ": result.expert_insights
            },
            "å…ƒæ•¸æ“š": {
                "éœ€æ±‚ID": result.requirement_id,
                "è™•ç†å™¨ç‰ˆæœ¬": "REQ_001_AICore_Processor_v1.0",
                "AICoreç‰ˆæœ¬": "3.0",
                "è™•ç†ç‹€æ…‹": "æˆåŠŸ"
            }
        }
    
    async def _save_processing_result(self, result: Dict[str, Any]):
        """ä¿å­˜è™•ç†çµæœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ä¿å­˜ JSON æ ¼å¼çµæœ
        json_file = f"/home/ubuntu/req001_aicore_processing_result_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        # ç”Ÿæˆ Markdown å ±å‘Š
        md_file = f"/home/ubuntu/req001_aicore_processing_report_{timestamp}.md"
        await self._generate_markdown_report(result, md_file)
        
        logger.info(f"âœ… è™•ç†çµæœå·²ä¿å­˜:")
        logger.info(f"ğŸ“„ JSON æ ¼å¼: {json_file}")
        logger.info(f"ğŸ“ Markdown å ±å‘Š: {md_file}")
    
    async def _generate_markdown_report(self, result: Dict[str, Any], file_path: str):
        """ç”Ÿæˆ Markdown å ±å‘Š"""
        analysis_result = result["REQ_001_åˆ†æçµæœ"]
        metadata = result["å…ƒæ•¸æ“š"]
        
        markdown_content = f"""# REQ_001: ç”¨æˆ¶ç•Œé¢è¨­è¨ˆéœ€æ±‚ - AICore åˆ†æå ±å‘Š

## ğŸ“Š åˆ†ææ¦‚è¦½

**åˆ†ææ™‚é–“**: {analysis_result["åˆ†ææ™‚é–“"]}  
**éœ€æ±‚ID**: {metadata["éœ€æ±‚ID"]}  
**è™•ç†å™¨ç‰ˆæœ¬**: {metadata["è™•ç†å™¨ç‰ˆæœ¬"]}  
**è™•ç†ç‹€æ…‹**: {metadata["è™•ç†ç‹€æ…‹"]}

## ğŸ¯ æ˜ç¢ºéœ€æ±‚åˆ—è¡¨

"""
        
        # æ·»åŠ éœ€æ±‚åˆ—è¡¨
        for i, req in enumerate(analysis_result["æ˜ç¢ºéœ€æ±‚åˆ—è¡¨"], 1):
            markdown_content += f"""### éœ€æ±‚ {i}: {req["éœ€æ±‚æ¨™é¡Œ"]}

- **éœ€æ±‚ID**: {req["éœ€æ±‚ID"]}
- **æè¿°**: {req["éœ€æ±‚æè¿°"]}
- **å„ªå…ˆç´š**: {req["å„ªå…ˆç´š"]}
- **ä¾†æºä»»å‹™**: {', '.join(req["ä¾†æºä»»å‹™"])}
- **æŠ€è¡“è¤‡é›œåº¦**: {req["æŠ€è¡“è¤‡é›œåº¦"]}
- **é ä¼°å·¥æ™‚**: {req["é ä¼°å·¥æ™‚"]}
- **éœ€æ±‚é¡åˆ¥**: {req["éœ€æ±‚é¡åˆ¥"]}

"""
        
        # æ·»åŠ  Manus Actions
        markdown_content += "## ğŸš€ Manus Actions\n\n"
        for i, action in enumerate(analysis_result["Manus_Actions"], 1):
            markdown_content += f"""### Action {i}: {action["è¡Œå‹•é¡å‹"]}

- **è¡Œå‹•ID**: {action["è¡Œå‹•ID"]}
- **æè¿°**: {action["æè¿°"]}
- **ç›¸é—œä»»å‹™**: {', '.join(action["ç›¸é—œä»»å‹™"])}
- **åŸ·è¡Œç‹€æ…‹**: {action["åŸ·è¡Œç‹€æ…‹"]}
- **å„ªå…ˆç´š**: {action["å„ªå…ˆç´š"]}
- **é ä¼°å·¥ä½œé‡**: {action["é ä¼°å·¥ä½œé‡"]}

"""
        
        # æ·»åŠ æª”æ¡ˆåˆ—è¡¨
        markdown_content += "## ğŸ“ ç›¸é—œæª”æ¡ˆåˆ—è¡¨\n\n"
        for i, file_info in enumerate(analysis_result["ç›¸é—œæª”æ¡ˆåˆ—è¡¨"], 1):
            markdown_content += f"""### æª”æ¡ˆ {i}

- **æª”æ¡ˆè·¯å¾‘**: `{file_info["æª”æ¡ˆè·¯å¾‘"]}`
- **æª”æ¡ˆé¡å‹**: {file_info["æª”æ¡ˆé¡å‹"]}
- **ç›¸é—œæ€§è©•åˆ†**: {file_info["ç›¸é—œæ€§è©•åˆ†"]}
- **è·¨ä»»å‹™é—œè¯**: {', '.join(file_info["è·¨ä»»å‹™é—œè¯"])}
- **æè¿°**: {file_info["æè¿°"]}

"""
        
        # æ·»åŠ è·¨ä»»å‹™åˆ†æ
        cross_task = analysis_result["è·¨ä»»å‹™åˆ†æ"]
        markdown_content += f"""## ğŸ”— è·¨ä»»å‹™åˆ†æ

- **é—œè¯ä»»å‹™æ•¸é‡**: {cross_task["é—œè¯ä»»å‹™æ•¸é‡"]}
- **å…±äº«éœ€æ±‚**: {', '.join(cross_task["å…±äº«éœ€æ±‚"])}
- **ä¾è³´é—œä¿‚éˆ**: {cross_task["ä¾è³´é—œä¿‚éˆ"]}
- **å½±éŸ¿è©•ä¼°**: {cross_task["å½±éŸ¿è©•ä¼°"]}
- **å”èª¿éœ€æ±‚**: {', '.join(cross_task["å”èª¿éœ€æ±‚"]) if cross_task["å”èª¿éœ€æ±‚"] else 'ç„¡'}

"""
        
        # æ·»åŠ è™•ç†çµ±è¨ˆ
        stats = analysis_result["è™•ç†çµ±è¨ˆ"]
        markdown_content += f"""## ğŸ“ˆ è™•ç†çµ±è¨ˆ

- **åˆ†æä»»å‹™ç¸½æ•¸**: {stats["åˆ†æä»»å‹™ç¸½æ•¸"]}
- **è­˜åˆ¥éœ€æ±‚æ•¸é‡**: {stats["è­˜åˆ¥éœ€æ±‚æ•¸é‡"]}
- **ç”Ÿæˆè¡Œå‹•æ•¸é‡**: {stats["ç”Ÿæˆè¡Œå‹•æ•¸é‡"]}
- **åˆ†ææª”æ¡ˆæ•¸é‡**: {stats["åˆ†ææª”æ¡ˆæ•¸é‡"]}
- **å°ˆå®¶ä¿¡å¿ƒå¹³å‡å€¼**: {stats["å°ˆå®¶ä¿¡å¿ƒå¹³å‡å€¼"]}

## ğŸ§  å°ˆå®¶æ´å¯Ÿ

"""
        
        # æ·»åŠ å°ˆå®¶æ´å¯Ÿ
        for expert_domain, insights in analysis_result["å°ˆå®¶æ´å¯Ÿ"].items():
            markdown_content += f"""### {expert_domain}

- **ä¿¡å¿ƒåº¦**: {insights.get('confidence', 'N/A')}
- **è™•ç†æ™‚é–“**: {insights.get('processing_time', 'N/A')}ç§’

"""
        
        markdown_content += """## ğŸ“ çµè«–

æœ¬æ¬¡ REQ_001 åˆ†æé€šé AICore 3.0 å‹•æ…‹å°ˆå®¶ç³»çµ±ï¼ŒæˆåŠŸè­˜åˆ¥äº†ç”¨æˆ¶ç•Œé¢è¨­è¨ˆéœ€æ±‚çš„æ˜ç¢ºéœ€æ±‚ã€ç›¸é—œè¡Œå‹•é …ç›®å’Œæª”æ¡ˆé—œè¯ã€‚åˆ†æçµæœç‚ºå¾ŒçºŒçš„å¯¦æ–½æä¾›äº†æ¸…æ™°çš„æŒ‡å°æ–¹å‘ã€‚

## ğŸ”„ ä¸‹ä¸€æ­¥å»ºè­°

1. **å„ªå…ˆåŸ·è¡Œé«˜å„ªå…ˆç´šéœ€æ±‚**ï¼šå°ˆæ³¨æ–¼æ™ºæ…§ä¸‹è¼‰å°èˆªæ¬„æ•´åˆç­‰æ ¸å¿ƒéœ€æ±‚
2. **å”èª¿è·¨ä»»å‹™ä¾è³´**ï¼šç¢ºä¿ç›¸é—œä»»å‹™é–“çš„å”èª¿å’ŒåŒæ­¥
3. **å¯¦æ–½ç›£æ§æ©Ÿåˆ¶**ï¼šå»ºç«‹é€²åº¦è¿½è¹¤å’Œè³ªé‡ç›£æ§
4. **æŒçºŒå„ªåŒ–**ï¼šåŸºæ–¼å¯¦æ–½åé¥‹æŒçºŒæ”¹é€²éœ€æ±‚å’Œå¯¦æ–½æ–¹æ¡ˆ

---

*æœ¬å ±å‘Šç”± AICore 3.0 å‹•æ…‹å°ˆå®¶ç³»çµ±è‡ªå‹•ç”Ÿæˆ*
"""
        
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)
    
    async def get_processing_summary(self) -> Dict[str, Any]:
        """ç²å–è™•ç†æ‘˜è¦"""
        stats = self.base_processor.get_processing_stats()
        
        return {
            "è™•ç†å™¨ç‹€æ…‹": "å°±ç·’",
            "æ”¯æŒçš„éœ€æ±‚": ["REQ_001"],
            "è™•ç†çµ±è¨ˆ": stats,
            "åŠŸèƒ½ç‰¹æ€§": [
                "æ™ºèƒ½éœ€æ±‚è§£æ",
                "å‹•æ…‹å°ˆå®¶å”èª¿",
                "è·¨ä»»å‹™é—œè¯åˆ†æ",
                "è‡ªå‹•åŒ–å ±å‘Šç”Ÿæˆ"
            ]
        }

async def main():
    """ä¸»å‡½æ•¸ - è™•ç†ç”¨æˆ¶çš„ REQ_001 éœ€æ±‚"""
    logger.info("ğŸš€ å•Ÿå‹• REQ_001 AICore è™•ç†å™¨")
    
    try:
        # å‰µå»ºè™•ç†å™¨
        processor = REQ001AICoreProcessor()
        
        # åˆå§‹åŒ–
        await processor.initialize()
        
        # è™•ç†ç”¨æˆ¶éœ€æ±‚
        result = await processor.process_user_requirement()
        
        # è¼¸å‡ºæ‘˜è¦
        print("\n" + "="*60)
        print("ğŸ¯ REQ_001: ç”¨æˆ¶ç•Œé¢è¨­è¨ˆéœ€æ±‚ - è™•ç†å®Œæˆ")
        print("="*60)
        
        analysis_result = result["REQ_001_åˆ†æçµæœ"]
        
        print(f"ğŸ“‹ è­˜åˆ¥éœ€æ±‚æ•¸é‡: {len(analysis_result['æ˜ç¢ºéœ€æ±‚åˆ—è¡¨'])}")
        print(f"ğŸš€ Manus è¡Œå‹•æ•¸é‡: {len(analysis_result['Manus_Actions'])}")
        print(f"ğŸ“ ç›¸é—œæª”æ¡ˆæ•¸é‡: {len(analysis_result['ç›¸é—œæª”æ¡ˆåˆ—è¡¨'])}")
        print(f"ğŸ”— è·¨ä»»å‹™é—œè¯: {analysis_result['è·¨ä»»å‹™åˆ†æ']['é—œè¯ä»»å‹™æ•¸é‡']} å€‹ä»»å‹™")
        
        print("\nğŸ“Š æ˜ç¢ºéœ€æ±‚åˆ—è¡¨:")
        for i, req in enumerate(analysis_result["æ˜ç¢ºéœ€æ±‚åˆ—è¡¨"], 1):
            print(f"  {i}. {req['éœ€æ±‚æ¨™é¡Œ']} (å„ªå…ˆç´š: {req['å„ªå…ˆç´š']})")
        
        print("\nğŸš€ Manus Actions:")
        for i, action in enumerate(analysis_result["Manus_Actions"], 1):
            print(f"  {i}. {action['è¡Œå‹•é¡å‹']}: {action['æè¿°']}")
        
        print("\nğŸ“ ç›¸é—œæª”æ¡ˆ:")
        for i, file_info in enumerate(analysis_result["ç›¸é—œæª”æ¡ˆåˆ—è¡¨"], 1):
            print(f"  {i}. {file_info['æª”æ¡ˆé¡å‹']}: {file_info['æª”æ¡ˆè·¯å¾‘']}")
        
        print(f"\nğŸ”— è·¨ä»»å‹™åˆ†æ:")
        cross_task = analysis_result["è·¨ä»»å‹™åˆ†æ"]
        print(f"  - é—œè¯ä»»å‹™: {cross_task['é—œè¯ä»»å‹™æ•¸é‡']} å€‹")
        print(f"  - å…±äº«éœ€æ±‚: {', '.join(cross_task['å…±äº«éœ€æ±‚'])}")
        print(f"  - ä¾è³´éˆ: {cross_task['ä¾è³´é—œä¿‚éˆ']}")
        
        print("\nâœ… è™•ç†å®Œæˆï¼è©³ç´°å ±å‘Šå·²ä¿å­˜åˆ°æª”æ¡ˆã€‚")
        
        # ç²å–è™•ç†æ‘˜è¦
        summary = await processor.get_processing_summary()
        print(f"\nğŸ“ˆ è™•ç†å™¨çµ±è¨ˆ:")
        print(f"  - æˆåŠŸç‡: {summary['è™•ç†çµ±è¨ˆ'].get('success_rate', 0):.1%}")
        print(f"  - å¹³å‡è™•ç†æ™‚é–“: {summary['è™•ç†çµ±è¨ˆ'].get('average_processing_time', 0):.2f}ç§’")
        
    except Exception as e:
        logger.error(f"âŒ REQ_001 è™•ç†å¤±æ•—: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())

