# TEST_FLOW_MCP ä½¿ç”¨æ¨™æº–æ“ä½œç¨‹åº (SOP)

**æ–‡æª”ç‰ˆæœ¬**: v1.0  
**å‰µå»ºæ—¥æœŸ**: 2025-06-25  
**ä½œè€…**: Manus AI  
**é©ç”¨å°è±¡**: PowerAutomation é–‹ç™¼åœ˜éšŠã€æ¸¬è©¦åœ˜éšŠã€å“è³ªä¿è­‰åœ˜éšŠ  

---

## ğŸ“‹ æ–‡æª”æ¦‚è¿°

æœ¬æ¨™æº–æ“ä½œç¨‹åº (SOP) æ—¨åœ¨æŒ‡å° PowerAutomation ç³»çµ±çš„å„å€‹åœ˜éšŠå¦‚ä½•æ­£ç¢ºä½¿ç”¨ `test_flow_mcp` æ¨¡çµ„ä¾†è®€å–æ¸¬è©¦æ¡ˆä¾‹ã€åŸ·è¡Œåˆ†æä¸¦ç”Ÿæˆçµæœå ±å‘Šã€‚`test_flow_mcp` æ˜¯ PowerAutomation ç³»çµ±ä¸­çš„æ ¸å¿ƒæ¸¬è©¦æµç¨‹ç®¡ç†çµ„ä»¶ï¼Œå®ƒæä¾›äº†å››éšæ®µçš„è‡ªå‹•åŒ–æ¸¬è©¦åˆ†ææµç¨‹ï¼Œèƒ½å¤ å”åŠ©é–‹ç™¼åœ˜éšŠé€²è¡Œéœ€æ±‚åˆ†æã€æ¯”è¼ƒåˆ†æã€è©•ä¼°å ±å‘Šç”Ÿæˆä»¥åŠä»£ç¢¼ä¿®å¾©å»ºè­°ã€‚

æœ¬æ–‡æª”å°‡è©³ç´°èªªæ˜å¦‚ä½•é…ç½®ç’°å¢ƒã€åŸ·è¡Œæ¸¬è©¦æµç¨‹ã€è§£è®€çµæœä»¥åŠé€²è¡Œå¾ŒçºŒçš„æ”¹é€²å·¥ä½œã€‚ç„¡è«–æ‚¨æ˜¯é–‹ç™¼äººå“¡ã€æ¸¬è©¦å·¥ç¨‹å¸«é‚„æ˜¯å°ˆæ¡ˆç¶“ç†ï¼Œéƒ½èƒ½é€éæœ¬ SOP å¿«é€ŸæŒæ¡ `test_flow_mcp` çš„ä½¿ç”¨æ–¹æ³•ï¼Œæå‡åœ˜éšŠçš„æ¸¬è©¦æ•ˆç‡å’Œä»£ç¢¼å“è³ªã€‚

---

## ğŸ¯ é©ç”¨ç¯„åœèˆ‡ç›®æ¨™

### é©ç”¨ç¯„åœ

æœ¬ SOP é©ç”¨æ–¼ä»¥ä¸‹å ´æ™¯å’Œäººå“¡ï¼š

**é©ç”¨å ´æ™¯**ï¼š
- æ–°åŠŸèƒ½é–‹ç™¼çš„æ¸¬è©¦è¦†è“‹ç‡åˆ†æ
- ç³»çµ±æ¶æ§‹è®Šæ›´çš„å½±éŸ¿è©•ä¼°
- ä»£ç¢¼å“è³ªæ”¹é€²çš„å»ºè­°ç”Ÿæˆ
- æ¸¬è©¦æ¡ˆä¾‹çš„è‡ªå‹•åŒ–åŸ·è¡Œèˆ‡åˆ†æ
- é–‹ç™¼æµç¨‹ä¸­çš„å“è³ªé–€ç¦æª¢æŸ¥
- æŒçºŒé›†æˆ/æŒçºŒéƒ¨ç½² (CI/CD) æµç¨‹ä¸­çš„æ¸¬è©¦ç’°ç¯€

**é©ç”¨äººå“¡**ï¼š
- **é–‹ç™¼å·¥ç¨‹å¸«**: éœ€è¦é€²è¡Œä»£ç¢¼å“è³ªåˆ†æå’Œæ¸¬è©¦è¦†è“‹ç‡æª¢æŸ¥
- **æ¸¬è©¦å·¥ç¨‹å¸«**: è² è²¬æ¸¬è©¦æ¡ˆä¾‹è¨­è¨ˆå’ŒåŸ·è¡Œçµæœåˆ†æ
- **å“è³ªä¿è­‰å·¥ç¨‹å¸«**: é€²è¡Œç³»çµ±å“è³ªè©•ä¼°å’Œæ”¹é€²å»ºè­°
- **å°ˆæ¡ˆç¶“ç†**: éœ€è¦äº†è§£å°ˆæ¡ˆæ¸¬è©¦ç‹€æ…‹å’Œå“è³ªæŒ‡æ¨™
- **æ¶æ§‹å¸«**: é€²è¡Œç³»çµ±æ¶æ§‹è©•ä¼°å’ŒæŠ€è¡“æ±ºç­–

### ç›®æ¨™èˆ‡æ•ˆç›Š

ä½¿ç”¨æœ¬ SOP å¾Œï¼Œåœ˜éšŠå°‡èƒ½å¤ ï¼š

1. **æ¨™æº–åŒ–æ¸¬è©¦æµç¨‹**: å»ºç«‹çµ±ä¸€çš„æ¸¬è©¦åŸ·è¡Œå’Œåˆ†ææ¨™æº–ï¼Œç¢ºä¿æ‰€æœ‰åœ˜éšŠæˆå“¡éƒ½èƒ½æŒ‰ç…§ç›¸åŒçš„æµç¨‹é€²è¡Œæ¸¬è©¦å·¥ä½œ
2. **æå‡æ¸¬è©¦æ•ˆç‡**: é€éè‡ªå‹•åŒ–çš„å››éšæ®µåˆ†ææµç¨‹ï¼Œå¤§å¹…æ¸›å°‘æ‰‹å‹•æ¸¬è©¦åˆ†æçš„æ™‚é–“æˆæœ¬
3. **æ”¹å–„ä»£ç¢¼å“è³ª**: ç²å¾—å…·é«”çš„ä»£ç¢¼æ”¹é€²å»ºè­°ï¼Œæœ‰é‡å°æ€§åœ°æå‡ä»£ç¢¼å“è³ª
4. **å¢å¼·æ¸¬è©¦è¦†è“‹ç‡**: ç³»çµ±æ€§åœ°è­˜åˆ¥æ¸¬è©¦ç›²é»ï¼Œæé«˜æ¸¬è©¦è¦†è“‹ç‡
5. **ä¿ƒé€²åœ˜éšŠå”ä½œ**: é€éæ¨™æº–åŒ–çš„å ±å‘Šæ ¼å¼ï¼Œå¢é€²åœ˜éšŠé–“çš„æºé€šæ•ˆç‡

---



## ğŸ—ï¸ ç³»çµ±æ¶æ§‹èˆ‡çµ„ä»¶èªªæ˜

### test_flow_mcp æ ¸å¿ƒæ¶æ§‹

`test_flow_mcp` æ˜¯ PowerAutomation ç³»çµ±ä¸­çš„é—œéµçµ„ä»¶ï¼Œæ¡ç”¨æ¨¡çµ„åŒ–è¨­è¨ˆï¼ŒåŒ…å«å››å€‹æ ¸å¿ƒè™•ç†éšæ®µã€‚æ•´å€‹ç³»çµ±åŸºæ–¼å¾®æœå‹™æ¶æ§‹ï¼Œé€é API ä»‹é¢æä¾›æœå‹™ï¼Œæ”¯æ´å¤šç¨®ä½¿ç”¨è€…è§’è‰²å’Œå·¥ä½œæµç¨‹ã€‚

#### æ ¸å¿ƒçµ„ä»¶æ¶æ§‹åœ–

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PowerAutomation ç³»çµ±                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  API Gateway (http://127.0.0.1:8080)                      â”‚
â”‚  â”œâ”€â”€ Authentication Layer (API Key é©—è­‰)                   â”‚
â”‚  â”œâ”€â”€ Role Management (é–‹ç™¼è€…/ä½¿ç”¨è€…/ç®¡ç†å“¡)                  â”‚
â”‚  â””â”€â”€ Request Router                                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                    test_flow_mcp æ ¸å¿ƒ                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ éœ€æ±‚åŒæ­¥å¼•æ“     â”‚  â”‚ æ¯”è¼ƒåˆ†æå¼•æ“     â”‚                 â”‚
â”‚  â”‚ Requirement     â”‚  â”‚ Comparison      â”‚                 â”‚
â”‚  â”‚ Sync Engine     â”‚  â”‚ Analysis Engine â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚
â”‚  â”‚ è©•ä¼°å ±å‘Šç”Ÿæˆå™¨   â”‚  â”‚ Code Fix Adapterâ”‚                 â”‚
â”‚  â”‚ Evaluation      â”‚  â”‚                 â”‚                 â”‚
â”‚  â”‚ Report Generatorâ”‚  â”‚                 â”‚                 â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  è¼”åŠ©çµ„ä»¶                                                   â”‚
â”‚  â”œâ”€â”€ DynamicCloudSearchMCP (é›²ç«¯æœå°‹)                      â”‚
â”‚  â”œâ”€â”€ SmartInvention-Manus HITL (äººå·¥å¯©æ ¸)                 â”‚
â”‚  â””â”€â”€ çµæœå„²å­˜èˆ‡å ±å‘Šç³»çµ±                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### å››éšæ®µè™•ç†æµç¨‹è©³è§£

#### ç¬¬ä¸€éšæ®µï¼šéœ€æ±‚åŒæ­¥å¼•æ“ (Requirement Sync Engine)

éœ€æ±‚åŒæ­¥å¼•æ“æ˜¯ `test_flow_mcp` çš„ç¬¬ä¸€å€‹è™•ç†éšæ®µï¼Œè² è²¬æ¥æ”¶å’Œè§£æä¾†è‡ªä¸åŒä¾†æºçš„æ¸¬è©¦éœ€æ±‚ã€‚é€™å€‹éšæ®µçš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼š

**åŠŸèƒ½ç‰¹æ€§**ï¼š
- **éœ€æ±‚æ¥æ”¶**: æ¥å—ä¾†è‡ª VS Code æ’ä»¶ã€API èª¿ç”¨æˆ–å…¶ä»–æ•´åˆå·¥å…·çš„æ¸¬è©¦éœ€æ±‚
- **æ ¼å¼æ¨™æº–åŒ–**: å°‡ä¸åŒæ ¼å¼çš„éœ€æ±‚è½‰æ›ç‚ºç³»çµ±å…§éƒ¨çš„æ¨™æº–æ ¼å¼
- **ä¸Šä¸‹æ–‡åˆ†æ**: åˆ†æè«‹æ±‚çš„ä¸Šä¸‹æ–‡è³‡è¨Šï¼ŒåŒ…æ‹¬ä½¿ç”¨è€…è§’è‰²ã€å·¥ä½œæµç¨‹é¡å‹ç­‰
- **éœ€æ±‚åˆ†é¡**: æ ¹æ“šéœ€æ±‚é¡å‹é€²è¡Œåˆ†é¡ï¼Œå¦‚æ¸¬è©¦è¦†è“‹ç‡åˆ†æã€ä»£ç¢¼å“è³ªæª¢æŸ¥ç­‰

**è¼¸å…¥æ ¼å¼**ï¼š
```json
{
  "request": "è«‹åˆ†æç•¶å‰ç³»çµ±çš„æ¸¬è©¦è¦†è“‹ç‡ä¸¦æä¾›æ”¹é€²å»ºè­°",
  "context": {
    "source": "vscode_vsix",
    "user_role": "developer",
    "workflow_type": "test_flow_analysis",
    "target_component": "test_flow_mcp",
    "analysis_type": "coverage_analysis"
  }
}
```

**è™•ç†çµæœ**ï¼š
```json
{
  "requirement_sync": {
    "manus_integration": true,
    "requirement_id": "req_1750839278",
    "sync_status": "completed",
    "parsed_requirements": {
      "analysis_type": "coverage_analysis",
      "target_scope": "system_wide",
      "priority": "high"
    }
  }
}
```

#### ç¬¬äºŒéšæ®µï¼šæ¯”è¼ƒåˆ†æå¼•æ“ (Comparison Analysis Engine)

æ¯”è¼ƒåˆ†æå¼•æ“è² è²¬å°ç•¶å‰ç³»çµ±ç‹€æ…‹é€²è¡Œæ·±åº¦åˆ†æï¼Œä¸¦èˆ‡æ—¢å®šæ¨™æº–é€²è¡Œæ¯”è¼ƒã€‚é€™å€‹éšæ®µæ˜¯æ•´å€‹æ¸¬è©¦æµç¨‹çš„æ ¸å¿ƒåˆ†æç’°ç¯€ã€‚

**åˆ†æç¶­åº¦**ï¼š
- **ä»£ç¢¼å“è³ªåˆ†æ**: æª¢æŸ¥ä»£ç¢¼çµæ§‹ã€å‘½åè¦ç¯„ã€è¤‡é›œåº¦ç­‰æŒ‡æ¨™
- **æ¸¬è©¦è¦†è“‹ç‡è©•ä¼°**: åˆ†æå–®å…ƒæ¸¬è©¦ã€æ•´åˆæ¸¬è©¦ã€ç«¯åˆ°ç«¯æ¸¬è©¦çš„è¦†è“‹æƒ…æ³
- **æ¶æ§‹åˆè¦æ€§æª¢æŸ¥**: é©—è­‰ç³»çµ±æ¶æ§‹æ˜¯å¦ç¬¦åˆæ—¢å®šçš„è¨­è¨ˆåŸå‰‡
- **æ•ˆèƒ½æŒ‡æ¨™è©•ä¼°**: åˆ†æç³»çµ±æ•ˆèƒ½è¡¨ç¾å’Œæ½›åœ¨ç“¶é ¸

**åˆ†ææµç¨‹**ï¼š
1. **è³‡æ–™æ”¶é›†**: å¾ç³»çµ±ä¸­æ”¶é›†ç›¸é—œçš„ä»£ç¢¼ã€æ¸¬è©¦å’Œé…ç½®è³‡è¨Š
2. **åŸºæº–æ¯”è¼ƒ**: èˆ‡ Manus æ¨™æº–å’Œæ¥­ç•Œæœ€ä½³å¯¦å‹™é€²è¡Œæ¯”è¼ƒ
3. **å·®ç•°è­˜åˆ¥**: è­˜åˆ¥ç•¶å‰ç‹€æ…‹èˆ‡ç›®æ¨™ç‹€æ…‹ä¹‹é–“çš„å·®ç•°
4. **å½±éŸ¿è©•ä¼°**: è©•ä¼°ç™¼ç¾çš„å•é¡Œå°ç³»çµ±æ•´é«”çš„å½±éŸ¿ç¨‹åº¦

**è¼¸å‡ºç¯„ä¾‹**ï¼š
```json
{
  "comparison_analysis": {
    "current_system_state": "analyzed",
    "differences_identified": 3,
    "improvement_areas": [
      "code_quality",
      "test_coverage", 
      "documentation"
    ],
    "manus_standard_comparison": "completed",
    "detailed_metrics": {
      "code_quality_score": 7.2,
      "test_coverage_percentage": 65.4,
      "documentation_completeness": 58.3
    }
  }
}
```

#### ç¬¬ä¸‰éšæ®µï¼šè©•ä¼°å ±å‘Šç”Ÿæˆå™¨ (Evaluation Report Generator)

è©•ä¼°å ±å‘Šç”Ÿæˆå™¨å°‡å‰å…©å€‹éšæ®µçš„åˆ†æçµæœæ•´åˆæˆçµæ§‹åŒ–çš„è©•ä¼°å ±å‘Šï¼Œç‚ºå¾ŒçºŒçš„æ”¹é€²å·¥ä½œæä¾›æ˜ç¢ºçš„æŒ‡å°ã€‚

**å ±å‘Šå…§å®¹çµæ§‹**ï¼š
- **åŸ·è¡Œæ‘˜è¦**: é«˜å±¤æ¬¡çš„åˆ†æçµæœç¸½çµ
- **è©³ç´°ç™¼ç¾**: å…·é«”çš„å•é¡Œé»å’Œæ”¹é€²æ©Ÿæœƒ
- **å„ªå…ˆç´šå»ºè­°**: æ ¹æ“šå½±éŸ¿ç¨‹åº¦å’Œå¯¦æ–½é›£åº¦æ’åºçš„æ”¹é€²å»ºè­°
- **å¯¦æ–½è·¯å¾‘**: å…·é«”çš„æ”¹é€²æ­¥é©Ÿå’Œæ™‚ç¨‹è¦åŠƒ

**å ±å‘Šç”Ÿæˆæµç¨‹**ï¼š
1. **è³‡æ–™æ•´åˆ**: æ•´åˆéœ€æ±‚åŒæ­¥å’Œæ¯”è¼ƒåˆ†æçš„çµæœ
2. **å„ªå…ˆç´šæ’åº**: æ ¹æ“šæ¥­å‹™å½±éŸ¿å’ŒæŠ€è¡“è¤‡é›œåº¦é€²è¡Œæ’åº
3. **å»ºè­°ç”Ÿæˆ**: ç”¢ç”Ÿå…·é«”å¯åŸ·è¡Œçš„æ”¹é€²å»ºè­°
4. **å ±å‘Šæ ¼å¼åŒ–**: ç”Ÿæˆæ¨™æº–åŒ–çš„å ±å‘Šæ ¼å¼

#### ç¬¬å››éšæ®µï¼šCode Fix Adapter

Code Fix Adapter æ˜¯ `test_flow_mcp` çš„æœ€å¾Œä¸€å€‹éšæ®µï¼Œè² è²¬å°‡è©•ä¼°å ±å‘Šè½‰æ›ç‚ºå…·é«”çš„ä»£ç¢¼ä¿®å¾©å»ºè­°å’Œå¯¦æ–½æ–¹æ¡ˆã€‚

**ä¸»è¦åŠŸèƒ½**ï¼š
- **ä»£ç¢¼ä¿®å¾©å»ºè­°**: æä¾›å…·é«”çš„ä»£ç¢¼æ”¹é€²æ–¹æ¡ˆ
- **æ¸¬è©¦æ¡ˆä¾‹ç”Ÿæˆ**: å»ºè­°æ–°çš„æ¸¬è©¦æ¡ˆä¾‹ä¾†æé«˜è¦†è“‹ç‡
- **é‡æ§‹å»ºè­°**: æä¾›ä»£ç¢¼é‡æ§‹çš„å…·é«”æ­¥é©Ÿ
- **æœ€ä½³å¯¦å‹™æ¨è–¦**: æ¨è–¦ç¬¦åˆåœ˜éšŠæ¨™æº–çš„æœ€ä½³å¯¦å‹™

**è¼¸å‡ºæ ¼å¼**ï¼š
```json
{
  "code_fixes": [
    {
      "file_path": "/path/to/component.py",
      "fix_type": "error_handling",
      "issue": "ç¼ºå°‘éŒ¯èª¤è™•ç†",
      "suggested_code": "try-except block implementation",
      "priority": "high",
      "estimated_effort": "2 hours"
    },
    {
      "file_path": "/path/to/test.py",
      "fix_type": "test_enhancement", 
      "issue": "æ¸¬è©¦è¦†è“‹ç‡ä¸è¶³",
      "suggested_code": "additional test cases",
      "priority": "medium",
      "estimated_effort": "4 hours"
    }
  ]
}
```

---


## âš™ï¸ ç’°å¢ƒé…ç½®èˆ‡å‰ç½®æ¢ä»¶

### ç³»çµ±éœ€æ±‚

åœ¨é–‹å§‹ä½¿ç”¨ `test_flow_mcp` ä¹‹å‰ï¼Œè«‹ç¢ºä¿æ‚¨çš„ç’°å¢ƒç¬¦åˆä»¥ä¸‹ç³»çµ±éœ€æ±‚ï¼š

#### ç¡¬é«”éœ€æ±‚
- **è™•ç†å™¨**: é›™æ ¸å¿ƒ 2.0GHz ä»¥ä¸Š (å»ºè­°å››æ ¸å¿ƒ)
- **è¨˜æ†¶é«”**: æœ€å°‘ 4GB RAM (å»ºè­° 8GB ä»¥ä¸Š)
- **å„²å­˜ç©ºé–“**: è‡³å°‘ 2GB å¯ç”¨ç©ºé–“
- **ç¶²è·¯é€£ç·š**: ç©©å®šçš„ç¶²éš›ç¶²è·¯é€£ç·š (ç”¨æ–¼é›²ç«¯æœå°‹åŠŸèƒ½)

#### è»Ÿé«”éœ€æ±‚
- **ä½œæ¥­ç³»çµ±**: Windows 10/11, macOS 10.14+, æˆ– Linux (Ubuntu 18.04+)
- **Python**: ç‰ˆæœ¬ 3.8 æˆ–ä»¥ä¸Š
- **Node.js**: ç‰ˆæœ¬ 14.0 æˆ–ä»¥ä¸Š (å¦‚éœ€ä½¿ç”¨ VS Code æ’ä»¶)
- **Git**: ç”¨æ–¼ç‰ˆæœ¬æ§åˆ¶å’Œä»£ç¢¼ç®¡ç†

#### ç¶²è·¯éœ€æ±‚
- **å…§éƒ¨ç¶²è·¯**: èƒ½å¤ è¨ªå• PowerAutomation æœå‹™å™¨ (é è¨­: http://127.0.0.1:8080)
- **å¤–éƒ¨ç¶²è·¯**: ç”¨æ–¼ DynamicCloudSearchMCP åŠŸèƒ½çš„é›²ç«¯æœå°‹
- **é˜²ç«ç‰†è¨­å®š**: ç¢ºä¿ç›¸é—œç«¯å£æœªè¢«å°é–

### ç’°å¢ƒé…ç½®æ­¥é©Ÿ

#### æ­¥é©Ÿ 1: å–å¾—å°ˆæ¡ˆä»£ç¢¼

é¦–å…ˆï¼Œå¾ GitHub å€‰åº«è¤‡è£½ PowerAutomation å°ˆæ¡ˆï¼š

```bash
# è¤‡è£½å°ˆæ¡ˆå€‰åº«
git clone https://github.com/alexchuang650730/aicore0624.git

# é€²å…¥å°ˆæ¡ˆç›®éŒ„
cd aicore0624

# æª¢æŸ¥å°ˆæ¡ˆçµæ§‹
ls -la
```

ç¢ºèªæ‚¨èƒ½çœ‹åˆ°ä»¥ä¸‹é—œéµç›®éŒ„ï¼š
- `PowerAutomation/` - æ ¸å¿ƒç³»çµ±ä»£ç¢¼
- `tests/` - æ¸¬è©¦æ¡†æ¶å’Œæ¸¬è©¦æ¡ˆä¾‹
- `development/` - é–‹ç™¼ç›¸é—œçš„æ¼”ç¤ºå’Œçµæœ

#### æ­¥é©Ÿ 2: Python ç’°å¢ƒè¨­å®š

å»ºç«‹ä¸¦å•Ÿå‹• Python è™›æ“¬ç’°å¢ƒï¼š

```bash
# å»ºç«‹è™›æ“¬ç’°å¢ƒ
python3 -m venv powerautomation_env

# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ (Linux/macOS)
source powerautomation_env/bin/activate

# å•Ÿå‹•è™›æ“¬ç’°å¢ƒ (Windows)
powerautomation_env\Scripts\activate

# å®‰è£å¿…è¦çš„ Python å¥—ä»¶
pip install -r requirements.txt
```

å¦‚æœæ²’æœ‰ `requirements.txt` æ–‡ä»¶ï¼Œè«‹æ‰‹å‹•å®‰è£æ ¸å¿ƒä¾è³´ï¼š

```bash
pip install requests flask python-dotenv
```

#### æ­¥é©Ÿ 3: é…ç½® API Key

`test_flow_mcp` ä½¿ç”¨ API Key é€²è¡Œèº«ä»½é©—è­‰ã€‚æ‚¨éœ€è¦é…ç½®é©ç•¶çš„ API Keyï¼š

**é–‹ç™¼è€… API Key ç¯„ä¾‹**ï¼š
```
dev_407CYuVKuP_s3hVqIhO4JZKqcE4-W9ocTgc_fldjxso
```

**é…ç½®æ–¹å¼**ï¼š
1. **ç’°å¢ƒè®Šæ•¸æ–¹å¼**ï¼š
   ```bash
   export POWERAUTOMATION_API_KEY="your_api_key_here"
   ```

2. **é…ç½®æ–‡ä»¶æ–¹å¼**ï¼š
   å»ºç«‹ `.env` æ–‡ä»¶ï¼š
   ```
   POWERAUTOMATION_API_KEY=your_api_key_here
   POWERAUTOMATION_SERVER_URL=http://127.0.0.1:8080
   ```

#### æ­¥é©Ÿ 4: å•Ÿå‹• PowerAutomation æœå‹™å™¨

åœ¨ä½¿ç”¨ `test_flow_mcp` ä¹‹å‰ï¼Œéœ€è¦ç¢ºä¿ PowerAutomation æœå‹™å™¨æ­£åœ¨é‹è¡Œï¼š

```bash
# é€²å…¥ PowerAutomation ç›®éŒ„
cd PowerAutomation

# å•Ÿå‹•æœå‹™å™¨ (æ–¹å¼ä¸€ï¼šä½¿ç”¨æ•´åˆæœå‹™å™¨)
python servers/fully_integrated_system.py

# æˆ–ä½¿ç”¨æ¸¬è©¦é›†æˆæœå‹™å™¨ (æ–¹å¼äºŒ)
python servers/test_flow_mcp_integration_server.py
```

æœå‹™å™¨å•Ÿå‹•å¾Œï¼Œæ‚¨æ‡‰è©²èƒ½çœ‹åˆ°é¡ä¼¼ä»¥ä¸‹çš„è¼¸å‡ºï¼š
```
PowerAutomation æœå‹™å™¨å·²å•Ÿå‹•
ç›£è½åœ°å€: http://127.0.0.1:8080
API Keys å·²è¼‰å…¥: 3 å€‹
test_flow_mcp å·²å•Ÿç”¨
```

#### æ­¥é©Ÿ 5: é©—è­‰ç’°å¢ƒé…ç½®

ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤é©—è­‰ç’°å¢ƒé…ç½®æ˜¯å¦æ­£ç¢ºï¼š

```bash
# æ¸¬è©¦æœå‹™å™¨é€£ç·š
curl -X GET http://127.0.0.1:8080/api/status

# æ¸¬è©¦ API Key é©—è­‰
curl -X POST http://127.0.0.1:8080/api/process \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your_api_key_here" \
  -d '{"request": "æ¸¬è©¦é€£ç·š", "context": {}}'
```

å¦‚æœé…ç½®æ­£ç¢ºï¼Œæ‚¨æ‡‰è©²æ”¶åˆ° HTTP 200 éŸ¿æ‡‰å’Œç›¸é—œçš„ç³»çµ±ç‹€æ…‹è³‡è¨Šã€‚

### å¸¸è¦‹é…ç½®å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

#### å•é¡Œ 1: æœå‹™å™¨ç„¡æ³•å•Ÿå‹•

**ç—‡ç‹€**: åŸ·è¡Œæœå‹™å™¨å•Ÿå‹•å‘½ä»¤æ™‚å‡ºç¾éŒ¯èª¤
**å¯èƒ½åŸå› **: 
- ç«¯å£ 8080 å·²è¢«å…¶ä»–ç¨‹åºä½”ç”¨
- Python ä¾è³´å¥—ä»¶æœªæ­£ç¢ºå®‰è£
- æ¬Šé™ä¸è¶³

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æª¢æŸ¥ç«¯å£ä½”ç”¨
netstat -tulpn | grep 8080

# æ®ºæ­»ä½”ç”¨ç«¯å£çš„ç¨‹åº
sudo kill -9 <process_id>

# é‡æ–°å®‰è£ä¾è³´
pip install --upgrade -r requirements.txt
```

#### å•é¡Œ 2: API Key é©—è­‰å¤±æ•—

**ç—‡ç‹€**: æ”¶åˆ° 401 Unauthorized éŒ¯èª¤
**å¯èƒ½åŸå› **:
- API Key æ ¼å¼ä¸æ­£ç¢º
- API Key æœªæ­£ç¢ºé…ç½®
- è«‹æ±‚æ¨™é ­æ ¼å¼éŒ¯èª¤

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# æª¢æŸ¥ API Key æ ¼å¼
echo $POWERAUTOMATION_API_KEY

# ç¢ºèªè«‹æ±‚æ¨™é ­æ ¼å¼
curl -X POST http://127.0.0.1:8080/api/process \
  -H "Content-Type: application/json" \
  -H "X-API-Key: dev_407CYuVKuP_s3hVqIhO4JZKqcE4-W9ocTgc_fldjxso" \
  -d '{"request": "æ¸¬è©¦", "context": {}}'
```

#### å•é¡Œ 3: æ¸¬è©¦åŸ·è¡Œå¤±æ•—

**ç—‡ç‹€**: æ¸¬è©¦è…³æœ¬åŸ·è¡Œæ™‚å‡ºç¾æ¨¡çµ„å°å…¥éŒ¯èª¤
**å¯èƒ½åŸå› **:
- Python è·¯å¾‘é…ç½®ä¸æ­£ç¢º
- è™›æ“¬ç’°å¢ƒæœªå•Ÿå‹•
- æ¸¬è©¦ä¾è³´æœªå®‰è£

**è§£æ±ºæ–¹æ¡ˆ**:
```bash
# ç¢ºèªè™›æ“¬ç’°å¢ƒå·²å•Ÿå‹•
which python

# è¨­å®š Python è·¯å¾‘
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# å®‰è£æ¸¬è©¦ä¾è³´
pip install pytest requests
```

---


## ğŸ‘¥ ä½¿ç”¨è€…è§’è‰²èˆ‡æ¬Šé™ç®¡ç†

PowerAutomation ç³»çµ±æ¡ç”¨åŸºæ–¼è§’è‰²çš„å­˜å–æ§åˆ¶ (RBAC) æ©Ÿåˆ¶ï¼Œä¸åŒè§’è‰²çš„ä½¿ç”¨è€…æ“æœ‰ä¸åŒçš„æ¬Šé™å’ŒåŠŸèƒ½å­˜å–ç¯„åœã€‚äº†è§£å„è§’è‰²çš„æ¬Šé™ç¯„åœå°æ–¼æ­£ç¢ºä½¿ç”¨ `test_flow_mcp` è‡³é—œé‡è¦ã€‚

### è§’è‰²å®šç¾©èˆ‡æ¬Šé™çŸ©é™£

#### é–‹ç™¼è€… (Developer)

é–‹ç™¼è€…æ˜¯ `test_flow_mcp` çš„ä¸»è¦ä½¿ç”¨è€…ï¼Œæ“æœ‰æœ€å®Œæ•´çš„æ¸¬è©¦åˆ†æåŠŸèƒ½å­˜å–æ¬Šé™ã€‚

**æ¬Šé™ç¯„åœ**:
- âœ… **å®Œæ•´ test_flow_mcp å­˜å–**: å¯ä»¥ä½¿ç”¨æ‰€æœ‰å››å€‹éšæ®µçš„åˆ†æåŠŸèƒ½
- âœ… **ä»£ç¢¼å“è³ªåˆ†æ**: ç²å¾—è©³ç´°çš„ä»£ç¢¼æ”¹é€²å»ºè­°
- âœ… **æ¸¬è©¦è¦†è“‹ç‡åˆ†æ**: æ·±åº¦åˆ†ææ¸¬è©¦è¦†è“‹ç‡ä¸¦ç²å¾—æ”¹é€²æ–¹æ¡ˆ
- âœ… **æ¶æ§‹è©•ä¼°**: é€²è¡Œç³»çµ±æ¶æ§‹åˆè¦æ€§æª¢æŸ¥
- âœ… **ä¿®å¾©å»ºè­°**: ç²å¾—å…·é«”çš„ä»£ç¢¼ä¿®å¾©å»ºè­°å’Œå¯¦æ–½æ–¹æ¡ˆ
- âœ… **æ­·å²è³‡æ–™å­˜å–**: æŸ¥çœ‹éå¾€çš„åˆ†æçµæœå’Œè¶¨å‹¢

**å…¸å‹ä½¿ç”¨å ´æ™¯**:
- æ–°åŠŸèƒ½é–‹ç™¼å‰çš„æ¸¬è©¦è¦åŠƒ
- ä»£ç¢¼å¯©æŸ¥å‰çš„å“è³ªæª¢æŸ¥
- é‡æ§‹å°ˆæ¡ˆçš„å½±éŸ¿è©•ä¼°
- æŒçºŒé›†æˆæµç¨‹ä¸­çš„å“è³ªé–€ç¦

**API Key æ ¼å¼**: `dev_` é–‹é ­çš„ API Key
**ç¯„ä¾‹**: `dev_407CYuVKuP_s3hVqIhO4JZKqcE4-W9ocTgc_fldjxso`

#### ä½¿ç”¨è€… (User)

ä½¿ç”¨è€…è§’è‰²ä¸»è¦ç”¨æ–¼ä¸€èˆ¬æ€§çš„æŸ¥è©¢å’ŒåŸºç¤åŠŸèƒ½ä½¿ç”¨ï¼Œé€šå¸¸é€é SmartInvention-Manus HITL æµç¨‹è™•ç†è«‹æ±‚ã€‚

**æ¬Šé™ç¯„åœ**:
- âœ… **åŸºç¤æŸ¥è©¢åŠŸèƒ½**: å¯ä»¥æäº¤ä¸€èˆ¬æ€§çš„ç³»çµ±æŸ¥è©¢
- âœ… **å ±å‘Šæª¢è¦–**: æŸ¥çœ‹å·²ç”Ÿæˆçš„æ¸¬è©¦å ±å‘Šæ‘˜è¦
- âš ï¸ **æœ‰é™çš„åˆ†æåŠŸèƒ½**: åƒ…èƒ½ä½¿ç”¨åŸºç¤çš„åˆ†æåŠŸèƒ½
- âŒ **ç„¡ä»£ç¢¼ä¿®å¾©å»ºè­°**: ä¸èƒ½ç²å¾—å…·é«”çš„ä»£ç¢¼ä¿®å¾©å»ºè­°
- âŒ **ç„¡æ·±åº¦åˆ†æ**: ç„¡æ³•é€²è¡Œæ·±åº¦çš„æŠ€è¡“åˆ†æ

**å…¸å‹ä½¿ç”¨å ´æ™¯**:
- å°ˆæ¡ˆç¶“ç†æŸ¥çœ‹æ¸¬è©¦ç‹€æ…‹
- æ¥­å‹™äººå“¡äº†è§£ç³»çµ±å“è³ªæŒ‡æ¨™
- æ–°åœ˜éšŠæˆå“¡çš„åŸºç¤æŸ¥è©¢éœ€æ±‚

**API Key æ ¼å¼**: `user_` é–‹é ­çš„ API Key

#### ç®¡ç†å“¡ (Admin)

ç®¡ç†å“¡æ“æœ‰ç³»çµ±çš„æœ€é«˜æ¬Šé™ï¼Œè² è²¬ç³»çµ±ç›£æ§ã€é…ç½®ç®¡ç†å’Œä½¿ç”¨è€…ç®¡ç†ã€‚

**æ¬Šé™ç¯„åœ**:
- âœ… **ç³»çµ±ç›£æ§**: å®Œæ•´çš„ç³»çµ±ç‹€æ…‹ç›£æ§å’ŒæŒ‡æ¨™æŸ¥çœ‹
- âœ… **é…ç½®ç®¡ç†**: ä¿®æ”¹ç³»çµ±é…ç½®å’Œåƒæ•¸è¨­å®š
- âœ… **ä½¿ç”¨è€…ç®¡ç†**: ç®¡ç† API Key å’Œä½¿ç”¨è€…æ¬Šé™
- âœ… **æ—¥èªŒå­˜å–**: æŸ¥çœ‹ç³»çµ±æ—¥èªŒå’ŒéŒ¯èª¤å ±å‘Š
- âœ… **æ•ˆèƒ½ç›£æ§**: ç›£æ§ç³»çµ±æ•ˆèƒ½å’Œè³‡æºä½¿ç”¨æƒ…æ³
- âœ… **è³‡æ–™ç®¡ç†**: æ¸…ç†å’Œå‚™ä»½ç³»çµ±è³‡æ–™

**å…¸å‹ä½¿ç”¨å ´æ™¯**:
- ç³»çµ±å¥åº·ç‹€æ…‹ç›£æ§
- æ•ˆèƒ½èª¿å„ªå’Œæ•…éšœæ’é™¤
- ä½¿ç”¨è€…æ¬Šé™ç®¡ç†
- ç³»çµ±ç¶­è­·å’Œå‡ç´š

**API Key æ ¼å¼**: `admin_` é–‹é ­çš„ API Key

### è§’è‰²è­˜åˆ¥æ©Ÿåˆ¶

PowerAutomation ç³»çµ±é€é API Key çš„å‰ç¶´è‡ªå‹•è­˜åˆ¥ä½¿ç”¨è€…è§’è‰²ï¼š

```python
def identify_user_role(api_key):
    if api_key.startswith('dev_'):
        return 'developer'
    elif api_key.startswith('user_'):
        return 'user'
    elif api_key.startswith('admin_'):
        return 'admin'
    else:
        return 'unknown'
```

### æ¬Šé™é©—è­‰æµç¨‹

ç•¶ä½¿ç”¨è€…ç™¼é€è«‹æ±‚åˆ° PowerAutomation ç³»çµ±æ™‚ï¼Œç³»çµ±æœƒåŸ·è¡Œä»¥ä¸‹æ¬Šé™é©—è­‰æµç¨‹ï¼š

1. **API Key é©—è­‰**: æª¢æŸ¥ API Key çš„æœ‰æ•ˆæ€§å’Œæ ¼å¼
2. **è§’è‰²è­˜åˆ¥**: æ ¹æ“š API Key å‰ç¶´è­˜åˆ¥ä½¿ç”¨è€…è§’è‰²
3. **æ¬Šé™æª¢æŸ¥**: é©—è­‰è©²è§’è‰²æ˜¯å¦æœ‰æ¬Šé™å­˜å–è«‹æ±‚çš„åŠŸèƒ½
4. **è·¯ç”±é¸æ“‡**: æ ¹æ“šè§’è‰²é¸æ“‡é©ç•¶çš„è™•ç†æµç¨‹

```json
{
  "authentication_flow": {
    "step_1": "API Key validation",
    "step_2": "Role identification", 
    "step_3": "Permission verification",
    "step_4": "Route selection"
  }
}
```

### ä¸åŒè§’è‰²çš„ test_flow_mcp ä½¿ç”¨æ–¹å¼

#### é–‹ç™¼è€…ä½¿ç”¨æ–¹å¼

é–‹ç™¼è€…å¯ä»¥ç›´æ¥ä½¿ç”¨ `test_flow_mcp` çš„å®Œæ•´åŠŸèƒ½ï¼š

```bash
curl -X POST http://127.0.0.1:8080/api/process \
  -H "Content-Type: application/json" \
  -H "X-API-Key: dev_407CYuVKuP_s3hVqIhO4JZKqcE4-W9ocTgc_fldjxso" \
  -d '{
    "request": "è«‹åˆ†æç•¶å‰ç³»çµ±çš„æ¸¬è©¦è¦†è“‹ç‡ä¸¦æä¾›æ”¹é€²å»ºè­°",
    "context": {
      "source": "vscode_vsix",
      "user_role": "developer",
      "workflow_type": "test_flow_analysis",
      "target_component": "test_flow_mcp",
      "analysis_type": "coverage_analysis"
    }
  }'
```

**é æœŸéŸ¿æ‡‰**:
```json
{
  "success": true,
  "user_role": "developer",
  "workflow_triggered": "test_flow_mcp",
  "test_flow_analysis": {
    "requirement_sync": { ... },
    "comparison_analysis": { ... },
    "evaluation_report": { ... }
  },
  "code_fixes": [ ... ],
  "recommendations": [ ... ]
}
```

#### ä½¿ç”¨è€…ä½¿ç”¨æ–¹å¼

ä½¿ç”¨è€…çš„è«‹æ±‚æœƒé€é SmartInvention-Manus HITL æµç¨‹è™•ç†ï¼š

```bash
curl -X POST http://127.0.0.1:8080/api/process \
  -H "Content-Type: application/json" \
  -H "X-API-Key: user_example_key" \
  -d '{
    "request": "æˆ‘æƒ³äº†è§£ç•¶å‰å°ˆæ¡ˆçš„æ¸¬è©¦ç‹€æ…‹",
    "context": {
      "source": "web_interface",
      "user_role": "user",
      "workflow_type": "general_inquiry"
    }
  }'
```

**é æœŸéŸ¿æ‡‰**:
```json
{
  "success": true,
  "user_role": "user",
  "workflow_triggered": "smartinvention_hitl",
  "result": "æ ¹æ“šæœ€æ–°çš„æ¸¬è©¦å ±å‘Šï¼Œç•¶å‰å°ˆæ¡ˆçš„æ¸¬è©¦è¦†è“‹ç‡ç‚º 65.4%...",
  "metadata": {
    "hitl_status": "processed",
    "review_required": false
  }
}
```

#### ç®¡ç†å“¡ä½¿ç”¨æ–¹å¼

ç®¡ç†å“¡ä¸»è¦ç”¨æ–¼ç³»çµ±ç›£æ§å’Œç®¡ç†ï¼š

```bash
curl -X GET http://127.0.0.1:8080/api/status \
  -H "X-API-Key: admin_example_key"
```

**é æœŸéŸ¿æ‡‰**:
```json
{
  "system_status": "healthy",
  "uptime": "2 days, 14 hours",
  "api_keys_count": 3,
  "test_flow_mcp_enabled": true,
  "recent_requests": 47,
  "error_rate": "0.2%",
  "performance_metrics": {
    "avg_response_time": "1.2s",
    "memory_usage": "45%",
    "cpu_usage": "23%"
  }
}
```

### æ¬Šé™ç•°å¸¸è™•ç†

ç•¶ä½¿ç”¨è€…å˜—è©¦å­˜å–è¶…å‡ºå…¶æ¬Šé™ç¯„åœçš„åŠŸèƒ½æ™‚ï¼Œç³»çµ±æœƒè¿”å›é©ç•¶çš„éŒ¯èª¤è¨Šæ¯ï¼š

**æ¬Šé™ä¸è¶³éŒ¯èª¤**:
```json
{
  "error": "Permission denied",
  "message": "Your role (user) does not have permission to access test_flow_mcp advanced features",
  "required_role": "developer",
  "current_role": "user",
  "suggestion": "Please contact your administrator to upgrade your access level"
}
```

**ç„¡æ•ˆ API Key éŒ¯èª¤**:
```json
{
  "error": "Authentication failed",
  "message": "Invalid or missing API key",
  "status_code": 401
}
```

---


## ğŸ“– æ¸¬è©¦æ¡ˆä¾‹è®€å–èˆ‡åŸ·è¡Œæµç¨‹

### æ¸¬è©¦æ¡ˆä¾‹çµæ§‹èˆ‡æ ¼å¼

PowerAutomation ç³»çµ±ä¸­çš„æ¸¬è©¦æ¡ˆä¾‹æ¡ç”¨æ¨™æº–åŒ–çš„çµæ§‹ï¼Œç¢ºä¿ `test_flow_mcp` èƒ½å¤ æ­£ç¢ºè§£æå’ŒåŸ·è¡Œã€‚æ¸¬è©¦æ¡ˆä¾‹åˆ†ç‚ºä¸‰å€‹ä¸»è¦é¡åˆ¥ï¼Œå°æ‡‰ä¸åŒçš„ä½¿ç”¨è€…è§’è‰²å’ŒåŠŸèƒ½éœ€æ±‚ã€‚

#### æ¸¬è©¦æ¡ˆä¾‹ç›®éŒ„çµæ§‹

```
tests/
â”œâ”€â”€ README.md                           # æ¸¬è©¦æ¡†æ¶èªªæ˜
â”œâ”€â”€ testcases/                          # æ¸¬è©¦æ¡ˆä¾‹ç›®éŒ„
â”‚   â””â”€â”€ requirement_analysis/           # éœ€æ±‚åˆ†ææ¸¬è©¦
â”‚       â”œâ”€â”€ test_requirement_analysis_integration.py
â”‚       â””â”€â”€ requirement_analysis_test_results_*.json
â”œâ”€â”€ templates/                          # æ¸¬è©¦æ¨¡æ¿
â”‚   â”œâ”€â”€ test_template.yaml
â”‚   â””â”€â”€ powerautomation_api_test_template.md
â””â”€â”€ generators/                         # æ¸¬è©¦ç”Ÿæˆå™¨
    â””â”€â”€ api_test_generator.py
```

#### æ¨™æº–æ¸¬è©¦æ¡ˆä¾‹æ ¼å¼

æ¯å€‹æ¸¬è©¦æ¡ˆä¾‹éƒ½éµå¾ªä»¥ä¸‹æ¨™æº–æ ¼å¼ï¼š

```python
class TestCase:
    def __init__(self):
        self.test_id = "PA_DEV_TF_001"
        self.test_type = "APIå‹æ¸¬è©¦"
        self.business_module = "PowerAutomation Core, test_flow_mcp"
        self.description = "æ¸¬è©¦ test_flow_mcp åœ¨é–‹ç™¼è€…æ¨¡å¼ä¸‹çš„å®Œæ•´åŠŸèƒ½"
        self.test_data = {
            "request": "è«‹åˆ†æç•¶å‰ç³»çµ±çš„æ¸¬è©¦è¦†è“‹ç‡ä¸¦æä¾›æ”¹é€²å»ºè­°",
            "context": {
                "source": "vscode_vsix",
                "user_role": "developer",
                "workflow_type": "test_flow_analysis",
                "target_component": "test_flow_mcp",
                "analysis_type": "coverage_analysis"
            }
        }
        self.expected_results = {
            "status_code": 200,
            "required_fields": ["test_flow_analysis", "code_fixes", "recommendations"],
            "user_role": "developer"
        }
```

### æ¸¬è©¦æ¡ˆä¾‹è®€å–æµç¨‹

#### è‡ªå‹•åŒ–æ¸¬è©¦æ¡ˆä¾‹ç™¼ç¾

`test_flow_mcp` ç³»çµ±å…·å‚™è‡ªå‹•ç™¼ç¾å’Œè¼‰å…¥æ¸¬è©¦æ¡ˆä¾‹çš„èƒ½åŠ›ï¼š

```python
def discover_test_cases(test_directory="/tests/testcases"):
    """
    è‡ªå‹•ç™¼ç¾æŒ‡å®šç›®éŒ„ä¸‹çš„æ‰€æœ‰æ¸¬è©¦æ¡ˆä¾‹
    """
    test_cases = []
    for root, dirs, files in os.walk(test_directory):
        for file in files:
            if file.startswith('test_') and file.endswith('.py'):
                test_case_path = os.path.join(root, file)
                test_cases.append(load_test_case(test_case_path))
    return test_cases
```

#### æ¸¬è©¦æ¡ˆä¾‹è¼‰å…¥èˆ‡é©—è­‰

ç³»çµ±æœƒå°æ¯å€‹æ¸¬è©¦æ¡ˆä¾‹é€²è¡Œæ ¼å¼é©—è­‰å’Œå®Œæ•´æ€§æª¢æŸ¥ï¼š

```python
def validate_test_case(test_case):
    """
    é©—è­‰æ¸¬è©¦æ¡ˆä¾‹çš„æ ¼å¼å’Œå®Œæ•´æ€§
    """
    required_fields = [
        'test_id', 'test_type', 'business_module', 
        'description', 'test_data', 'expected_results'
    ]
    
    for field in required_fields:
        if not hasattr(test_case, field):
            raise ValidationError(f"Missing required field: {field}")
    
    # é©—è­‰ API Key æ ¼å¼
    if 'api_key' in test_case.test_data:
        validate_api_key_format(test_case.test_data['api_key'])
    
    return True
```

### åŸ·è¡Œæµç¨‹è©³è§£

#### ç¬¬ä¸€æ­¥ï¼šæ¸¬è©¦ç’°å¢ƒæº–å‚™

åœ¨åŸ·è¡Œæ¸¬è©¦æ¡ˆä¾‹ä¹‹å‰ï¼Œç³»çµ±æœƒè‡ªå‹•æº–å‚™æ¸¬è©¦ç’°å¢ƒï¼š

```python
def prepare_test_environment():
    """
    æº–å‚™æ¸¬è©¦åŸ·è¡Œç’°å¢ƒ
    """
    # 1. æª¢æŸ¥æœå‹™å™¨ç‹€æ…‹
    server_status = check_server_health()
    if not server_status['healthy']:
        raise EnvironmentError("PowerAutomation server is not healthy")
    
    # 2. é©—è­‰ API Key
    validate_api_keys()
    
    # 3. æ¸…ç†èˆŠçš„æ¸¬è©¦çµæœ
    cleanup_previous_results()
    
    # 4. åˆå§‹åŒ–çµæœæ”¶é›†å™¨
    initialize_result_collector()
    
    return True
```

#### ç¬¬äºŒæ­¥ï¼šæ¸¬è©¦æ¡ˆä¾‹åŸ·è¡Œ

æ¯å€‹æ¸¬è©¦æ¡ˆä¾‹çš„åŸ·è¡Œéµå¾ªæ¨™æº–åŒ–çš„æµç¨‹ï¼š

```python
def execute_test_case(test_case):
    """
    åŸ·è¡Œå–®å€‹æ¸¬è©¦æ¡ˆä¾‹
    """
    execution_result = {
        'test_id': test_case.test_id,
        'start_time': datetime.now(),
        'status': 'running',
        'checkpoints': []
    }
    
    try:
        # 1. ç™¼é€ API è«‹æ±‚
        response = send_api_request(
            url=test_case.endpoint,
            method=test_case.method,
            headers=test_case.headers,
            data=test_case.test_data
        )
        
        # 2. é©—è­‰éŸ¿æ‡‰ç‹€æ…‹
        validate_response_status(response, test_case.expected_results)
        
        # 3. åŸ·è¡Œæª¢æŸ¥é»é©—è­‰
        for checkpoint in test_case.checkpoints:
            checkpoint_result = execute_checkpoint(checkpoint, response)
            execution_result['checkpoints'].append(checkpoint_result)
        
        # 4. è¨˜éŒ„åŸ·è¡Œçµæœ
        execution_result['status'] = 'passed'
        execution_result['response_data'] = response.json()
        
    except Exception as e:
        execution_result['status'] = 'failed'
        execution_result['error'] = str(e)
    
    finally:
        execution_result['end_time'] = datetime.now()
        execution_result['duration'] = (
            execution_result['end_time'] - execution_result['start_time']
        ).total_seconds()
    
    return execution_result
```

#### ç¬¬ä¸‰æ­¥ï¼šçµæœé©—è­‰èˆ‡åˆ†æ

ç³»çµ±æœƒå°æ¯å€‹æ¸¬è©¦æ¡ˆä¾‹çš„åŸ·è¡Œçµæœé€²è¡Œè©³ç´°åˆ†æï¼š

```python
def analyze_test_results(execution_result, test_case):
    """
    åˆ†ææ¸¬è©¦åŸ·è¡Œçµæœ
    """
    analysis = {
        'test_id': test_case.test_id,
        'overall_status': execution_result['status'],
        'performance_metrics': {
            'response_time': execution_result['duration'],
            'memory_usage': get_memory_usage(),
            'cpu_usage': get_cpu_usage()
        },
        'functional_validation': {},
        'recommendations': []
    }
    
    # åŠŸèƒ½æ€§é©—è­‰
    if execution_result['status'] == 'passed':
        response_data = execution_result['response_data']
        
        # é©—è­‰ test_flow_mcp å››éšæ®µåŸ·è¡Œ
        if 'test_flow_analysis' in response_data:
            analysis['functional_validation']['four_stage_execution'] = True
            validate_four_stage_results(response_data['test_flow_analysis'])
        
        # é©—è­‰ä»£ç¢¼ä¿®å¾©å»ºè­°
        if 'code_fixes' in response_data:
            analysis['functional_validation']['code_fixes_generated'] = True
            analyze_code_fix_quality(response_data['code_fixes'])
    
    return analysis
```

### æ‰¹æ¬¡åŸ·è¡Œèˆ‡ä¸¦è¡Œè™•ç†

#### æ‰¹æ¬¡åŸ·è¡Œç­–ç•¥

å°æ–¼å¤§é‡æ¸¬è©¦æ¡ˆä¾‹çš„åŸ·è¡Œï¼Œç³»çµ±æ”¯æ´æ‰¹æ¬¡è™•ç†æ¨¡å¼ï¼š

```python
def execute_test_batch(test_cases, batch_size=5):
    """
    æ‰¹æ¬¡åŸ·è¡Œæ¸¬è©¦æ¡ˆä¾‹
    """
    results = []
    total_batches = math.ceil(len(test_cases) / batch_size)
    
    for batch_index in range(total_batches):
        start_index = batch_index * batch_size
        end_index = min(start_index + batch_size, len(test_cases))
        batch = test_cases[start_index:end_index]
        
        print(f"åŸ·è¡Œæ‰¹æ¬¡ {batch_index + 1}/{total_batches}")
        
        batch_results = []
        for test_case in batch:
            result = execute_test_case(test_case)
            batch_results.append(result)
            
            # æ‰¹æ¬¡é–“å»¶é²ï¼Œé¿å…æœå‹™å™¨éè¼‰
            time.sleep(1)
        
        results.extend(batch_results)
        
        # æ‰¹æ¬¡å®Œæˆå¾Œçš„æ¸…ç†å·¥ä½œ
        cleanup_batch_resources()
    
    return results
```

#### ä¸¦è¡ŒåŸ·è¡Œæ”¯æ´

å°æ–¼ç¨ç«‹çš„æ¸¬è©¦æ¡ˆä¾‹ï¼Œç³»çµ±æ”¯æ´ä¸¦è¡ŒåŸ·è¡Œä»¥æé«˜æ•ˆç‡ï¼š

```python
import concurrent.futures
import threading

def execute_tests_parallel(test_cases, max_workers=3):
    """
    ä¸¦è¡ŒåŸ·è¡Œæ¸¬è©¦æ¡ˆä¾‹
    """
    results = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰æ¸¬è©¦ä»»å‹™
        future_to_test = {
            executor.submit(execute_test_case, test_case): test_case 
            for test_case in test_cases
        }
        
        # æ”¶é›†åŸ·è¡Œçµæœ
        for future in concurrent.futures.as_completed(future_to_test):
            test_case = future_to_test[future]
            try:
                result = future.result()
                results.append(result)
                print(f"æ¸¬è©¦ {test_case.test_id} å®Œæˆ")
            except Exception as exc:
                print(f"æ¸¬è©¦ {test_case.test_id} åŸ·è¡Œç•°å¸¸: {exc}")
                results.append({
                    'test_id': test_case.test_id,
                    'status': 'error',
                    'error': str(exc)
                })
    
    return results
```

### æ¸¬è©¦çµæœå„²å­˜èˆ‡è¿½è¹¤

#### çµæœå„²å­˜æ ¼å¼

æ‰€æœ‰æ¸¬è©¦åŸ·è¡Œçµæœéƒ½æœƒä»¥æ¨™æº–åŒ–çš„ JSON æ ¼å¼å„²å­˜ï¼š

```json
{
  "test_execution_summary": {
    "execution_id": "exec_20250625_041442",
    "timestamp": "2025-06-25T04:14:42Z",
    "total_tests": 5,
    "passed_tests": 2,
    "failed_tests": 3,
    "execution_time": "45.7 seconds",
    "environment": {
      "server_url": "http://127.0.0.1:8080",
      "python_version": "3.11.0",
      "system_info": "Ubuntu 22.04"
    }
  },
  "test_results": [
    {
      "test_id": "PA_DEV_TF_001",
      "status": "passed",
      "execution_time": "12.3 seconds",
      "checkpoints": [
        {
          "name": "API é€£æ¥æ€§æª¢æŸ¥",
          "status": "PASS",
          "details": "æˆåŠŸé€£æ¥åˆ° PowerAutomation æœå‹™å™¨"
        },
        {
          "name": "å››éšæ®µåŸ·è¡Œé©—è­‰",
          "status": "PASS", 
          "details": "test_flow_mcp å››éšæ®µè™•ç†å®Œæˆ"
        }
      ],
      "response_data": { ... },
      "performance_metrics": {
        "response_time": "2.1s",
        "memory_usage": "45MB",
        "cpu_usage": "23%"
      }
    }
  ]
}
```

#### æ­·å²è¿½è¹¤èˆ‡è¶¨å‹¢åˆ†æ

ç³»çµ±æœƒç¶­è­·æ¸¬è©¦åŸ·è¡Œçš„æ­·å²è¨˜éŒ„ï¼Œæ”¯æ´è¶¨å‹¢åˆ†æï¼š

```python
def track_test_trends(test_results_history):
    """
    åˆ†ææ¸¬è©¦åŸ·è¡Œè¶¨å‹¢
    """
    trends = {
        'pass_rate_trend': calculate_pass_rate_trend(test_results_history),
        'performance_trend': calculate_performance_trend(test_results_history),
        'failure_pattern': analyze_failure_patterns(test_results_history),
        'recommendations': generate_trend_recommendations(test_results_history)
    }
    
    return trends
```

---


## ğŸ“Š çµæœåˆ†æèˆ‡å ±å‘Šç”Ÿæˆ

### æ¸¬è©¦çµæœåˆ†ææ¡†æ¶

`test_flow_mcp` æä¾›äº†å®Œæ•´çš„çµæœåˆ†ææ¡†æ¶ï¼Œèƒ½å¤ å¾å¤šå€‹ç¶­åº¦å°æ¸¬è©¦åŸ·è¡Œçµæœé€²è¡Œæ·±åº¦åˆ†æï¼Œç‚ºåœ˜éšŠæä¾›æœ‰åƒ¹å€¼çš„æ´å¯Ÿå’Œæ”¹é€²å»ºè­°ã€‚

#### åˆ†æç¶­åº¦æ¦‚è¦½

æ¸¬è©¦çµæœåˆ†ææ¶µè“‹ä»¥ä¸‹å…­å€‹ä¸»è¦ç¶­åº¦ï¼š

1. **åŠŸèƒ½æ€§åˆ†æ** - é©—è­‰ç³»çµ±åŠŸèƒ½æ˜¯å¦æŒ‰é æœŸå·¥ä½œ
2. **æ•ˆèƒ½åˆ†æ** - è©•ä¼°ç³»çµ±éŸ¿æ‡‰æ™‚é–“å’Œè³‡æºä½¿ç”¨æƒ…æ³
3. **ç©©å®šæ€§åˆ†æ** - æª¢æŸ¥ç³»çµ±åœ¨ä¸åŒæ¢ä»¶ä¸‹çš„ç©©å®šæ€§è¡¨ç¾
4. **è¦†è“‹ç‡åˆ†æ** - è©•ä¼°æ¸¬è©¦æ¡ˆä¾‹å°ç³»çµ±åŠŸèƒ½çš„è¦†è“‹ç¨‹åº¦
5. **è¶¨å‹¢åˆ†æ** - åˆ†ææ¸¬è©¦çµæœéš¨æ™‚é–“çš„è®ŠåŒ–è¶¨å‹¢
6. **é¢¨éšªè©•ä¼°** - è­˜åˆ¥æ½›åœ¨çš„ç³»çµ±é¢¨éšªå’Œæ”¹é€²æ©Ÿæœƒ

### åŠŸèƒ½æ€§åˆ†æ

#### test_flow_mcp å››éšæ®µåŸ·è¡Œåˆ†æ

ç³»çµ±æœƒè©³ç´°åˆ†æ `test_flow_mcp` å››å€‹éšæ®µçš„åŸ·è¡Œæƒ…æ³ï¼š

```python
def analyze_four_stage_execution(test_results):
    """
    åˆ†æ test_flow_mcp å››éšæ®µåŸ·è¡Œæƒ…æ³
    """
    stage_analysis = {
        'requirement_sync_engine': {
            'execution_status': 'completed',
            'processing_time': '2.1s',
            'success_rate': '100%',
            'key_metrics': {
                'requirements_processed': 1,
                'sync_accuracy': '100%',
                'error_count': 0
            }
        },
        'comparison_analysis_engine': {
            'execution_status': 'completed',
            'processing_time': '5.3s',
            'success_rate': '100%',
            'key_metrics': {
                'differences_identified': 3,
                'improvement_areas': ['code_quality', 'test_coverage', 'documentation'],
                'analysis_depth': 'comprehensive'
            }
        },
        'evaluation_report_generator': {
            'execution_status': 'completed',
            'processing_time': '3.2s',
            'success_rate': '100%',
            'key_metrics': {
                'reports_generated': 1,
                'recommendations_count': 5,
                'priority_classification': 'completed'
            }
        },
        'code_fix_adapter': {
            'execution_status': 'completed',
            'processing_time': '1.8s',
            'success_rate': '100%',
            'key_metrics': {
                'fixes_suggested': 2,
                'implementation_complexity': 'medium',
                'estimated_effort': '6 hours'
            }
        }
    }
    
    return stage_analysis
```

#### API æ•´åˆå“è³ªè©•ä¼°

ç³»çµ±æœƒè©•ä¼°å„å€‹ API ç«¯é»çš„æ•´åˆå“è³ªï¼š

```python
def evaluate_api_integration_quality(api_responses):
    """
    è©•ä¼° API æ•´åˆå“è³ª
    """
    quality_metrics = {
        'response_consistency': calculate_response_consistency(api_responses),
        'error_handling': evaluate_error_handling(api_responses),
        'data_integrity': check_data_integrity(api_responses),
        'security_compliance': verify_security_compliance(api_responses)
    }
    
    overall_score = calculate_weighted_score(quality_metrics)
    
    return {
        'overall_score': overall_score,
        'detailed_metrics': quality_metrics,
        'improvement_suggestions': generate_api_improvements(quality_metrics)
    }
```

### æ•ˆèƒ½åˆ†æ

#### éŸ¿æ‡‰æ™‚é–“åˆ†æ

ç³»çµ±æœƒå°å„å€‹æ“ä½œçš„éŸ¿æ‡‰æ™‚é–“é€²è¡Œè©³ç´°åˆ†æï¼š

```python
def analyze_response_times(performance_data):
    """
    åˆ†æç³»çµ±éŸ¿æ‡‰æ™‚é–“
    """
    response_analysis = {
        'average_response_time': calculate_average(performance_data['response_times']),
        'median_response_time': calculate_median(performance_data['response_times']),
        'p95_response_time': calculate_percentile(performance_data['response_times'], 95),
        'p99_response_time': calculate_percentile(performance_data['response_times'], 99),
        'response_time_distribution': generate_distribution_chart(performance_data['response_times']),
        'performance_grade': classify_performance_grade(performance_data['response_times'])
    }
    
    # æ•ˆèƒ½åŸºæº–æ¯”è¼ƒ
    benchmarks = {
        'excellent': '< 1s',
        'good': '1-3s', 
        'acceptable': '3-5s',
        'poor': '> 5s'
    }
    
    response_analysis['benchmark_comparison'] = compare_with_benchmarks(
        response_analysis['average_response_time'], 
        benchmarks
    )
    
    return response_analysis
```

#### è³‡æºä½¿ç”¨åˆ†æ

```python
def analyze_resource_usage(resource_metrics):
    """
    åˆ†æç³»çµ±è³‡æºä½¿ç”¨æƒ…æ³
    """
    resource_analysis = {
        'memory_usage': {
            'peak_usage': max(resource_metrics['memory']),
            'average_usage': sum(resource_metrics['memory']) / len(resource_metrics['memory']),
            'usage_trend': calculate_trend(resource_metrics['memory']),
            'memory_leaks': detect_memory_leaks(resource_metrics['memory'])
        },
        'cpu_usage': {
            'peak_usage': max(resource_metrics['cpu']),
            'average_usage': sum(resource_metrics['cpu']) / len(resource_metrics['cpu']),
            'usage_pattern': analyze_cpu_pattern(resource_metrics['cpu']),
            'bottlenecks': identify_cpu_bottlenecks(resource_metrics['cpu'])
        },
        'network_usage': {
            'total_requests': len(resource_metrics['network_requests']),
            'request_rate': calculate_request_rate(resource_metrics['network_requests']),
            'bandwidth_usage': calculate_bandwidth_usage(resource_metrics['network_requests'])
        }
    }
    
    return resource_analysis
```

### ç©©å®šæ€§åˆ†æ

#### éŒ¯èª¤æ¨¡å¼åˆ†æ

ç³»çµ±æœƒåˆ†ææ¸¬è©¦åŸ·è¡Œéç¨‹ä¸­å‡ºç¾çš„éŒ¯èª¤æ¨¡å¼ï¼š

```python
def analyze_error_patterns(test_failures):
    """
    åˆ†æéŒ¯èª¤æ¨¡å¼å’Œå¤±æ•—åŸå› 
    """
    error_analysis = {
        'failure_categories': categorize_failures(test_failures),
        'common_error_types': identify_common_errors(test_failures),
        'failure_frequency': calculate_failure_frequency(test_failures),
        'error_correlation': find_error_correlations(test_failures),
        'root_cause_analysis': perform_root_cause_analysis(test_failures)
    }
    
    # ç”ŸæˆéŒ¯èª¤ä¿®å¾©å»ºè­°
    error_analysis['fix_recommendations'] = generate_error_fixes(error_analysis)
    
    return error_analysis
```

#### ç³»çµ±ç©©å®šæ€§æŒ‡æ¨™

```python
def calculate_stability_metrics(test_history):
    """
    è¨ˆç®—ç³»çµ±ç©©å®šæ€§æŒ‡æ¨™
    """
    stability_metrics = {
        'uptime_percentage': calculate_uptime(test_history),
        'mean_time_between_failures': calculate_mtbf(test_history),
        'mean_time_to_recovery': calculate_mttr(test_history),
        'availability_score': calculate_availability(test_history),
        'reliability_index': calculate_reliability_index(test_history)
    }
    
    return stability_metrics
```

### å ±å‘Šç”Ÿæˆç³»çµ±

#### è‡ªå‹•åŒ–å ±å‘Šç”Ÿæˆ

`test_flow_mcp` æä¾›å¤šç¨®æ ¼å¼çš„è‡ªå‹•åŒ–å ±å‘Šç”ŸæˆåŠŸèƒ½ï¼š

```python
def generate_comprehensive_report(analysis_results):
    """
    ç”Ÿæˆç¶œåˆæ¸¬è©¦å ±å‘Š
    """
    report = {
        'executive_summary': generate_executive_summary(analysis_results),
        'detailed_analysis': {
            'functional_analysis': analysis_results['functional'],
            'performance_analysis': analysis_results['performance'],
            'stability_analysis': analysis_results['stability'],
            'coverage_analysis': analysis_results['coverage']
        },
        'recommendations': generate_prioritized_recommendations(analysis_results),
        'action_items': create_action_items(analysis_results),
        'appendices': {
            'raw_data': analysis_results['raw_data'],
            'charts_and_graphs': analysis_results['visualizations'],
            'technical_details': analysis_results['technical_details']
        }
    }
    
    return report
```

#### å ±å‘Šæ ¼å¼èˆ‡è¼¸å‡ºé¸é …

ç³»çµ±æ”¯æ´å¤šç¨®å ±å‘Šæ ¼å¼ï¼š

**1. JSON æ ¼å¼å ±å‘Š**
```json
{
  "report_metadata": {
    "generated_at": "2025-06-25T04:14:42Z",
    "report_version": "1.0",
    "test_execution_id": "exec_20250625_041442"
  },
  "executive_summary": {
    "overall_status": "è‰¯å¥½",
    "pass_rate": "40%",
    "critical_issues": 0,
    "recommendations_count": 8
  },
  "detailed_findings": { ... }
}
```

**2. Markdown æ ¼å¼å ±å‘Š**
```markdown
# PowerAutomation æ¸¬è©¦åŸ·è¡Œå ±å‘Š

## åŸ·è¡Œæ‘˜è¦
- **åŸ·è¡Œæ™‚é–“**: 2025-06-25 04:14:42
- **ç¸½æ¸¬è©¦æ•¸**: 5
- **é€šéç‡**: 40%
- **é—œéµå•é¡Œ**: 0 å€‹

## è©³ç´°åˆ†æ
### test_flow_mcp åŠŸèƒ½åˆ†æ
å››éšæ®µè™•ç†æµç¨‹å®Œå…¨æ­£å¸¸é‹è¡Œ...
```

**3. HTML æ ¼å¼å ±å‘Š**
```html
<!DOCTYPE html>
<html>
<head>
    <title>PowerAutomation æ¸¬è©¦å ±å‘Š</title>
    <style>
        /* å ±å‘Šæ¨£å¼ */
    </style>
</head>
<body>
    <div class="report-container">
        <h1>æ¸¬è©¦åŸ·è¡Œå ±å‘Š</h1>
        <!-- å ±å‘Šå…§å®¹ -->
    </div>
</body>
</html>
```

#### è¦–è¦ºåŒ–åœ–è¡¨ç”Ÿæˆ

å ±å‘Šä¸­åŒ…å«è±å¯Œçš„è¦–è¦ºåŒ–åœ–è¡¨ï¼š

```python
def generate_visualizations(analysis_data):
    """
    ç”Ÿæˆæ¸¬è©¦çµæœè¦–è¦ºåŒ–åœ–è¡¨
    """
    visualizations = {
        'pass_rate_chart': create_pass_rate_pie_chart(analysis_data),
        'performance_trend': create_performance_line_chart(analysis_data),
        'error_distribution': create_error_bar_chart(analysis_data),
        'coverage_heatmap': create_coverage_heatmap(analysis_data),
        'resource_usage_graph': create_resource_usage_graph(analysis_data)
    }
    
    return visualizations
```

### çµæœè§£è®€æŒ‡å—

#### é—œéµæŒ‡æ¨™è§£è®€

**é€šéç‡ (Pass Rate)**
- **å„ªç§€**: > 95%
- **è‰¯å¥½**: 80-95%
- **å¯æ¥å—**: 60-80%
- **éœ€æ”¹é€²**: < 60%

**éŸ¿æ‡‰æ™‚é–“ (Response Time)**
- **å„ªç§€**: < 1 ç§’
- **è‰¯å¥½**: 1-3 ç§’
- **å¯æ¥å—**: 3-5 ç§’
- **éœ€å„ªåŒ–**: > 5 ç§’

**ç³»çµ±ç©©å®šæ€§ (Stability)**
- **é«˜ç©©å®šæ€§**: å¯ç”¨æ€§ > 99.9%
- **ä¸­ç­‰ç©©å®šæ€§**: å¯ç”¨æ€§ 95-99.9%
- **ä½ç©©å®šæ€§**: å¯ç”¨æ€§ < 95%

#### æ”¹é€²å»ºè­°å„ªå…ˆç´š

ç³»çµ±æœƒæ ¹æ“šå½±éŸ¿ç¨‹åº¦å’Œå¯¦æ–½é›£åº¦å°æ”¹é€²å»ºè­°é€²è¡Œå„ªå…ˆç´šæ’åºï¼š

```python
def prioritize_recommendations(recommendations):
    """
    å°æ”¹é€²å»ºè­°é€²è¡Œå„ªå…ˆç´šæ’åº
    """
    priority_matrix = {
        'critical': {'impact': 'high', 'effort': 'any'},
        'high': {'impact': 'high', 'effort': 'low'},
        'medium': {'impact': 'medium', 'effort': 'low'},
        'low': {'impact': 'low', 'effort': 'low'}
    }
    
    prioritized = []
    for recommendation in recommendations:
        priority = calculate_priority(recommendation, priority_matrix)
        recommendation['priority'] = priority
        prioritized.append(recommendation)
    
    return sorted(prioritized, key=lambda x: x['priority'], reverse=True)
```

### å ±å‘Šåˆ†ç™¼èˆ‡é€šçŸ¥

#### è‡ªå‹•åŒ–å ±å‘Šåˆ†ç™¼

```python
def distribute_reports(report, distribution_config):
    """
    è‡ªå‹•åˆ†ç™¼æ¸¬è©¦å ±å‘Š
    """
    for recipient in distribution_config['recipients']:
        if recipient['format'] == 'email':
            send_email_report(report, recipient['address'])
        elif recipient['format'] == 'slack':
            send_slack_notification(report, recipient['channel'])
        elif recipient['format'] == 'file':
            save_report_to_file(report, recipient['path'])
```

#### å³æ™‚é€šçŸ¥æ©Ÿåˆ¶

```python
def send_real_time_notifications(test_results):
    """
    ç™¼é€å³æ™‚æ¸¬è©¦çµæœé€šçŸ¥
    """
    if has_critical_failures(test_results):
        send_urgent_notification(test_results)
    elif has_performance_degradation(test_results):
        send_performance_alert(test_results)
    else:
        send_routine_update(test_results)
```

---


## ğŸ› ï¸ å¯¦éš›æ“ä½œç¯„ä¾‹

### å ´æ™¯ä¸€ï¼šæ–°åŠŸèƒ½é–‹ç™¼çš„æ¸¬è©¦è¦†è“‹ç‡åˆ†æ

#### èƒŒæ™¯æƒ…å¢ƒ

å‡è¨­æ‚¨çš„åœ˜éšŠå‰›å®Œæˆäº†ä¸€å€‹æ–°çš„ä½¿ç”¨è€…èªè­‰æ¨¡çµ„ï¼Œéœ€è¦ä½¿ç”¨ `test_flow_mcp` ä¾†åˆ†ææ¸¬è©¦è¦†è“‹ç‡ä¸¦ç²å¾—æ”¹é€²å»ºè­°ã€‚

#### æ“ä½œæ­¥é©Ÿ

**æ­¥é©Ÿ 1: æº–å‚™æ¸¬è©¦è«‹æ±‚**

```bash
# å»ºç«‹æ¸¬è©¦è«‹æ±‚ JSON æ–‡ä»¶
cat > coverage_analysis_request.json << EOF
{
  "request": "è«‹åˆ†ææ–°é–‹ç™¼çš„ä½¿ç”¨è€…èªè­‰æ¨¡çµ„çš„æ¸¬è©¦è¦†è“‹ç‡ï¼Œä¸¦æä¾›å…·é«”çš„æ”¹é€²å»ºè­°",
  "context": {
    "source": "vscode_vsix",
    "user_role": "developer",
    "workflow_type": "test_flow_analysis",
    "target_component": "user_authentication_module",
    "analysis_type": "coverage_analysis",
    "module_path": "/src/authentication",
    "development_phase": "feature_complete"
  }
}
EOF
```

**æ­¥é©Ÿ 2: åŸ·è¡Œ test_flow_mcp åˆ†æ**

```bash
# ä½¿ç”¨ curl ç™¼é€åˆ†æè«‹æ±‚
curl -X POST http://127.0.0.1:8080/api/process \
  -H "Content-Type: application/json" \
  -H "X-API-Key: dev_407CYuVKuP_s3hVqIhO4JZKqcE4-W9ocTgc_fldjxso" \
  -d @coverage_analysis_request.json \
  --output coverage_analysis_result.json

# æª¢æŸ¥åŸ·è¡Œçµæœ
cat coverage_analysis_result.json | jq '.'
```

**æ­¥é©Ÿ 3: è§£è®€åˆ†æçµæœ**

é æœŸçš„åˆ†æçµæœæœƒåŒ…å«å››å€‹éšæ®µçš„è©³ç´°è³‡è¨Šï¼š

```json
{
  "success": true,
  "user_role": "developer",
  "workflow_triggered": "test_flow_mcp",
  "test_flow_analysis": {
    "requirement_sync": {
      "manus_integration": true,
      "requirement_id": "req_auth_module_001",
      "sync_status": "completed",
      "target_module": "user_authentication_module"
    },
    "comparison_analysis": {
      "current_coverage": "72.3%",
      "target_coverage": "85%",
      "coverage_gap": "12.7%",
      "uncovered_areas": [
        "error_handling_scenarios",
        "edge_case_validations",
        "concurrent_access_tests"
      ],
      "risk_assessment": "medium"
    },
    "evaluation_report": {
      "overall_grade": "B+",
      "strengths": [
        "æ ¸å¿ƒåŠŸèƒ½æ¸¬è©¦å®Œæ•´",
        "å–®å…ƒæ¸¬è©¦çµæ§‹è‰¯å¥½",
        "API ç«¯é»æ¸¬è©¦è¦†è“‹å……åˆ†"
      ],
      "improvement_areas": [
        "ç•°å¸¸è™•ç†æ¸¬è©¦ä¸è¶³",
        "é‚Šç•Œæ¢ä»¶æ¸¬è©¦ç¼ºå¤±",
        "æ•´åˆæ¸¬è©¦éœ€è¦åŠ å¼·"
      ]
    }
  },
  "code_fixes": [
    {
      "file_path": "/src/authentication/auth_service.py",
      "fix_type": "test_enhancement",
      "issue": "ç¼ºå°‘ç•°å¸¸è™•ç†æ¸¬è©¦",
      "suggested_implementation": "æ·»åŠ  try-catch ç•°å¸¸æ¸¬è©¦æ¡ˆä¾‹",
      "priority": "high",
      "estimated_effort": "3 hours"
    }
  ],
  "recommendations": [
    {
      "category": "test_coverage",
      "priority": "high",
      "description": "å¢åŠ ç•°å¸¸è™•ç†å ´æ™¯çš„æ¸¬è©¦æ¡ˆä¾‹",
      "implementation_guide": "é‡å°æ¯å€‹å¯èƒ½çš„ç•°å¸¸æƒ…æ³ç·¨å¯«å°ˆé–€çš„æ¸¬è©¦æ¡ˆä¾‹"
    }
  ]
}
```

**æ­¥é©Ÿ 4: å¯¦æ–½æ”¹é€²å»ºè­°**

æ ¹æ“šåˆ†æçµæœï¼Œé–‹ç™¼åœ˜éšŠæ‡‰è©²ï¼š

1. **å„ªå…ˆè™•ç†é«˜å„ªå…ˆç´šå»ºè­°**: å…ˆå¯¦æ–½ç•°å¸¸è™•ç†æ¸¬è©¦
2. **é€æ­¥æå‡è¦†è“‹ç‡**: ç›®æ¨™å¾ 72.3% æå‡åˆ° 85%
3. **å®šæœŸé‡æ–°åˆ†æ**: æ¯é€±åŸ·è¡Œä¸€æ¬¡è¦†è“‹ç‡åˆ†æ

### å ´æ™¯äºŒï¼šç³»çµ±æ•ˆèƒ½å›æ­¸æ¸¬è©¦

#### èƒŒæ™¯æƒ…å¢ƒ

ç³»çµ±é€²è¡Œäº†é‡å¤§æ¶æ§‹èª¿æ•´å¾Œï¼Œéœ€è¦é©—è­‰æ•ˆèƒ½æ˜¯å¦æœ‰å›æ­¸å•é¡Œã€‚

#### æ“ä½œæ­¥é©Ÿ

**æ­¥é©Ÿ 1: å»ºç«‹æ•ˆèƒ½æ¸¬è©¦è«‹æ±‚**

```python
# å»ºç«‹ Python è…³æœ¬é€²è¡Œæ•ˆèƒ½æ¸¬è©¦
import requests
import time
import json

def performance_regression_test():
    """
    åŸ·è¡Œæ•ˆèƒ½å›æ­¸æ¸¬è©¦
    """
    test_request = {
        "request": "åŸ·è¡Œç³»çµ±æ•ˆèƒ½å›æ­¸æ¸¬è©¦ï¼Œæ¯”è¼ƒæ¶æ§‹èª¿æ•´å‰å¾Œçš„æ•ˆèƒ½å·®ç•°",
        "context": {
            "source": "automated_testing",
            "user_role": "developer", 
            "workflow_type": "performance_regression",
            "target_component": "entire_system",
            "analysis_type": "performance_comparison",
            "baseline_version": "v2.1.0",
            "current_version": "v2.2.0"
        }
    }
    
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": "dev_407CYuVKuP_s3hVqIhO4JZKqcE4-W9ocTgc_fldjxso"
    }
    
    # è¨˜éŒ„é–‹å§‹æ™‚é–“
    start_time = time.time()
    
    # ç™¼é€è«‹æ±‚
    response = requests.post(
        "http://127.0.0.1:8080/api/process",
        headers=headers,
        json=test_request,
        timeout=60
    )
    
    # è¨˜éŒ„çµæŸæ™‚é–“
    end_time = time.time()
    execution_time = end_time - start_time
    
    # è™•ç†éŸ¿æ‡‰
    if response.status_code == 200:
        result = response.json()
        result['execution_metrics'] = {
            'total_execution_time': f"{execution_time:.2f}s",
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
        }
        
        # å„²å­˜çµæœ
        with open(f'performance_test_result_{int(time.time())}.json', 'w') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        
        return result
    else:
        raise Exception(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {response.status_code} - {response.text}")

# åŸ·è¡Œæ¸¬è©¦
if __name__ == "__main__":
    try:
        result = performance_regression_test()
        print("æ•ˆèƒ½å›æ­¸æ¸¬è©¦å®Œæˆ")
        print(f"åŸ·è¡Œæ™‚é–“: {result['execution_metrics']['total_execution_time']}")
    except Exception as e:
        print(f"æ¸¬è©¦åŸ·è¡ŒéŒ¯èª¤: {e}")
```

**æ­¥é©Ÿ 2: åˆ†ææ•ˆèƒ½æ¸¬è©¦çµæœ**

```python
def analyze_performance_results(result_file):
    """
    åˆ†ææ•ˆèƒ½æ¸¬è©¦çµæœ
    """
    with open(result_file, 'r') as f:
        results = json.load(f)
    
    performance_analysis = {
        'response_time_comparison': {
            'baseline': results.get('baseline_metrics', {}).get('avg_response_time', 'N/A'),
            'current': results.get('current_metrics', {}).get('avg_response_time', 'N/A'),
            'improvement_percentage': calculate_improvement_percentage(results)
        },
        'resource_usage_comparison': {
            'memory_usage_change': analyze_memory_usage_change(results),
            'cpu_usage_change': analyze_cpu_usage_change(results)
        },
        'regression_detected': detect_performance_regression(results),
        'recommendations': generate_performance_recommendations(results)
    }
    
    return performance_analysis
```

### å ´æ™¯ä¸‰ï¼šæŒçºŒé›†æˆä¸­çš„è‡ªå‹•åŒ–æ¸¬è©¦

#### èƒŒæ™¯æƒ…å¢ƒ

å°‡ `test_flow_mcp` æ•´åˆåˆ° CI/CD æµç¨‹ä¸­ï¼Œå¯¦ç¾è‡ªå‹•åŒ–çš„ä»£ç¢¼å“è³ªæª¢æŸ¥ã€‚

#### CI/CD æ•´åˆè…³æœ¬

**GitHub Actions å·¥ä½œæµç¨‹ç¯„ä¾‹**

```yaml
# .github/workflows/powerautomation_test.yml
name: PowerAutomation Test Flow

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test_flow_analysis:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests python-dotenv
    
    - name: Start PowerAutomation Server
      run: |
        cd PowerAutomation
        python servers/fully_integrated_system.py &
        sleep 10  # ç­‰å¾…æœå‹™å™¨å•Ÿå‹•
    
    - name: Run test_flow_mcp Analysis
      env:
        POWERAUTOMATION_API_KEY: ${{ secrets.POWERAUTOMATION_API_KEY }}
      run: |
        python .github/scripts/run_test_flow_analysis.py
    
    - name: Upload Test Results
      uses: actions/upload-artifact@v3
      with:
        name: test-flow-results
        path: test_results/
    
    - name: Comment PR with Results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          const results = JSON.parse(fs.readFileSync('test_results/summary.json', 'utf8'));
          
          const comment = `
          ## ğŸ” PowerAutomation Test Flow åˆ†æçµæœ
          
          - **æ•´é«”ç‹€æ…‹**: ${results.overall_status}
          - **æ¸¬è©¦é€šéç‡**: ${results.pass_rate}
          - **ç™¼ç¾å•é¡Œ**: ${results.issues_found}
          - **æ”¹é€²å»ºè­°**: ${results.recommendations_count}
          
          è©³ç´°å ±å‘Šè«‹æŸ¥çœ‹ Artifactsã€‚
          `;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });
```

**è‡ªå‹•åŒ–æ¸¬è©¦è…³æœ¬**

```python
# .github/scripts/run_test_flow_analysis.py
import os
import requests
import json
import sys
from datetime import datetime

def run_automated_test_flow():
    """
    åœ¨ CI/CD ç’°å¢ƒä¸­åŸ·è¡Œ test_flow_mcp åˆ†æ
    """
    api_key = os.getenv('POWERAUTOMATION_API_KEY')
    if not api_key:
        print("éŒ¯èª¤: æœªè¨­å®š POWERAUTOMATION_API_KEY ç’°å¢ƒè®Šæ•¸")
        sys.exit(1)
    
    # æº–å‚™æ¸¬è©¦è«‹æ±‚
    test_request = {
        "request": "åŸ·è¡Œ CI/CD æµç¨‹ä¸­çš„ä»£ç¢¼å“è³ªå’Œæ¸¬è©¦è¦†è“‹ç‡åˆ†æ",
        "context": {
            "source": "github_actions",
            "user_role": "developer",
            "workflow_type": "ci_cd_analysis",
            "target_component": "entire_codebase",
            "analysis_type": "comprehensive_analysis",
            "git_branch": os.getenv('GITHUB_REF_NAME', 'unknown'),
            "commit_sha": os.getenv('GITHUB_SHA', 'unknown')
        }
    }
    
    headers = {
        "Content-Type": "application/json",
        "X-API-Key": api_key
    }
    
    try:
        # ç™¼é€åˆ†æè«‹æ±‚
        response = requests.post(
            "http://127.0.0.1:8080/api/process",
            headers=headers,
            json=test_request,
            timeout=120
        )
        
        if response.status_code == 200:
            results = response.json()
            
            # å»ºç«‹çµæœç›®éŒ„
            os.makedirs('test_results', exist_ok=True)
            
            # å„²å­˜å®Œæ•´çµæœ
            with open('test_results/full_results.json', 'w') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            # ç”Ÿæˆæ‘˜è¦å ±å‘Š
            summary = generate_ci_summary(results)
            with open('test_results/summary.json', 'w') as f:
                json.dump(summary, f, indent=2, ensure_ascii=False)
            
            # æª¢æŸ¥æ˜¯å¦æœ‰é—œéµå•é¡Œ
            if summary['critical_issues'] > 0:
                print(f"ç™¼ç¾ {summary['critical_issues']} å€‹é—œéµå•é¡Œ")
                sys.exit(1)
            
            print("test_flow_mcp åˆ†æå®Œæˆ")
            return True
            
        else:
            print(f"åˆ†æè«‹æ±‚å¤±æ•—: {response.status_code} - {response.text}")
            sys.exit(1)
            
    except Exception as e:
        print(f"åŸ·è¡ŒéŒ¯èª¤: {e}")
        sys.exit(1)

def generate_ci_summary(results):
    """
    ç”Ÿæˆ CI/CD æ‘˜è¦å ±å‘Š
    """
    summary = {
        'timestamp': datetime.now().isoformat(),
        'overall_status': 'PASS' if results.get('success', False) else 'FAIL',
        'pass_rate': calculate_pass_rate(results),
        'issues_found': count_issues(results),
        'critical_issues': count_critical_issues(results),
        'recommendations_count': len(results.get('recommendations', [])),
        'execution_time': results.get('execution_metrics', {}).get('total_time', 'N/A')
    }
    
    return summary

if __name__ == "__main__":
    run_automated_test_flow()
```

### æœ€ä½³å¯¦å‹™å»ºè­°

#### æ¸¬è©¦åŸ·è¡Œé »ç‡å»ºè­°

**é–‹ç™¼éšæ®µ**:
- **æ¯æ—¥åŸ·è¡Œ**: åŸºç¤çš„åŠŸèƒ½æ€§æ¸¬è©¦
- **æ¯é€±åŸ·è¡Œ**: å®Œæ•´çš„æ¸¬è©¦è¦†è“‹ç‡åˆ†æ
- **æ¯æœˆåŸ·è¡Œ**: æ·±åº¦çš„æ•ˆèƒ½å’Œç©©å®šæ€§åˆ†æ

**ç”Ÿç”¢ç’°å¢ƒ**:
- **æ¯æ¬¡éƒ¨ç½²å‰**: å®Œæ•´çš„å›æ­¸æ¸¬è©¦
- **æ¯é€±åŸ·è¡Œ**: æ•ˆèƒ½ç›£æ§å’Œè¶¨å‹¢åˆ†æ
- **æ¯æœˆåŸ·è¡Œ**: å…¨é¢çš„ç³»çµ±å¥åº·æª¢æŸ¥

#### æ¸¬è©¦çµæœè™•ç†å»ºè­°

**ç«‹å³è™•ç†**:
- é—œéµå®‰å…¨å•é¡Œ
- ç³»çµ±å´©æ½°æˆ–åš´é‡éŒ¯èª¤
- æ•ˆèƒ½åš´é‡ä¸‹é™ (>50%)

**å„ªå…ˆè™•ç†** (1-2 é€±å…§):
- é«˜å„ªå…ˆç´šçš„ä»£ç¢¼å“è³ªå•é¡Œ
- æ¸¬è©¦è¦†è“‹ç‡ä½æ–¼ç›®æ¨™å€¼
- ä¸­ç­‰ç¨‹åº¦çš„æ•ˆèƒ½å•é¡Œ

**è¨ˆåŠƒè™•ç†** (1 å€‹æœˆå…§):
- ä½å„ªå…ˆç´šçš„æ”¹é€²å»ºè­°
- ä»£ç¢¼é‡æ§‹å»ºè­°
- æ–‡æª”æ›´æ–°éœ€æ±‚

#### åœ˜éšŠå”ä½œå»ºè­°

**è§’è‰²åˆ†å·¥**:
- **é–‹ç™¼å·¥ç¨‹å¸«**: è² è²¬åŸ·è¡Œæ—¥å¸¸æ¸¬è©¦å’Œä¿®å¾©ä»£ç¢¼å•é¡Œ
- **æ¸¬è©¦å·¥ç¨‹å¸«**: è² è²¬æ¸¬è©¦æ¡ˆä¾‹è¨­è¨ˆå’Œçµæœåˆ†æ
- **å°ˆæ¡ˆç¶“ç†**: è² è²¬ç›£æ§æ•´é«”å“è³ªæŒ‡æ¨™å’Œé€²åº¦è¿½è¹¤
- **æ¶æ§‹å¸«**: è² è²¬ç³»çµ±ç´šçš„æ”¹é€²æ±ºç­–

**æºé€šæ©Ÿåˆ¶**:
- **æ¯æ—¥ç«™æœƒ**: åˆ†äº«æ¸¬è©¦çµæœå’Œå•é¡Œ
- **é€±å ±**: ç¸½çµæ¸¬è©¦è¶¨å‹¢å’Œæ”¹é€²é€²å±•
- **æœˆå ±**: å‘ç®¡ç†å±¤å ±å‘Šå“è³ªæŒ‡æ¨™

---


## ğŸ”§ æ•…éšœæ’é™¤èˆ‡å¸¸è¦‹å•é¡Œ

### å¸¸è¦‹å•é¡Œè¨ºæ–·æµç¨‹

ç•¶ä½¿ç”¨ `test_flow_mcp` é‡åˆ°å•é¡Œæ™‚ï¼Œå»ºè­°æŒ‰ç…§ä»¥ä¸‹è¨ºæ–·æµç¨‹é€²è¡Œæ’æŸ¥ï¼š

#### ç¬¬ä¸€æ­¥ï¼šåŸºç¤ç’°å¢ƒæª¢æŸ¥

```bash
# æª¢æŸ¥æœå‹™å™¨ç‹€æ…‹
curl -X GET http://127.0.0.1:8080/api/status

# æª¢æŸ¥ Python ç’°å¢ƒ
python --version
pip list | grep -E "(requests|flask)"

# æª¢æŸ¥ç¶²è·¯é€£ç·š
ping 127.0.0.1
netstat -tulpn | grep 8080
```

#### ç¬¬äºŒæ­¥ï¼šAPI Key é©—è­‰

```bash
# é©—è­‰ API Key æ ¼å¼
echo $POWERAUTOMATION_API_KEY | grep -E "^(dev_|user_|admin_)"

# æ¸¬è©¦ API Key èªè­‰
curl -X POST http://127.0.0.1:8080/api/process \
  -H "Content-Type: application/json" \
  -H "X-API-Key: $POWERAUTOMATION_API_KEY" \
  -d '{"request": "æ¸¬è©¦", "context": {}}'
```

#### ç¬¬ä¸‰æ­¥ï¼šæ—¥èªŒæª¢æŸ¥

```bash
# æª¢æŸ¥æœå‹™å™¨æ—¥èªŒ
tail -f PowerAutomation/logs/server.log

# æª¢æŸ¥éŒ¯èª¤æ—¥èªŒ
grep -i error PowerAutomation/logs/*.log

# æª¢æŸ¥ç³»çµ±è³‡æº
top -p $(pgrep -f "fully_integrated_system")
```

### å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

#### å•é¡Œ 1: æœå‹™å™¨é€£æ¥å¤±æ•—

**ç—‡ç‹€**:
```
Connection refused: http://127.0.0.1:8080
curl: (7) Failed to connect to 127.0.0.1 port 8080: Connection refused
```

**å¯èƒ½åŸå› **:
- PowerAutomation æœå‹™å™¨æœªå•Ÿå‹•
- ç«¯å£è¢«å…¶ä»–ç¨‹åºä½”ç”¨
- é˜²ç«ç‰†é˜»æ“‹é€£æ¥

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: æª¢æŸ¥ä¸¦å•Ÿå‹•æœå‹™å™¨
ps aux | grep -i powerautomation
cd PowerAutomation
python servers/fully_integrated_system.py

# æ–¹æ¡ˆ 2: æª¢æŸ¥ç«¯å£ä½”ç”¨
sudo netstat -tulpn | grep 8080
sudo lsof -i :8080

# æ–¹æ¡ˆ 3: æ›´æ›ç«¯å£
export POWERAUTOMATION_PORT=8081
python servers/fully_integrated_system.py --port 8081
```

**é é˜²æªæ–½**:
```bash
# å»ºç«‹æœå‹™å™¨å¥åº·æª¢æŸ¥è…³æœ¬
cat > check_server_health.sh << 'EOF'
#!/bin/bash
SERVER_URL="http://127.0.0.1:8080"
HEALTH_CHECK_URL="$SERVER_URL/api/status"

if curl -s "$HEALTH_CHECK_URL" > /dev/null; then
    echo "âœ… PowerAutomation æœå‹™å™¨é‹è¡Œæ­£å¸¸"
else
    echo "âŒ PowerAutomation æœå‹™å™¨ç„¡æ³•é€£æ¥"
    echo "æ­£åœ¨å˜—è©¦é‡æ–°å•Ÿå‹•..."
    cd PowerAutomation
    python servers/fully_integrated_system.py &
    sleep 5
    if curl -s "$HEALTH_CHECK_URL" > /dev/null; then
        echo "âœ… æœå‹™å™¨é‡æ–°å•Ÿå‹•æˆåŠŸ"
    else
        echo "âŒ æœå‹™å™¨é‡æ–°å•Ÿå‹•å¤±æ•—ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥"
    fi
fi
EOF

chmod +x check_server_health.sh
```

#### å•é¡Œ 2: API Key èªè­‰å¤±æ•—

**ç—‡ç‹€**:
```json
{
  "error": "Authentication failed",
  "message": "Invalid or missing API key",
  "status_code": 401
}
```

**å¯èƒ½åŸå› **:
- API Key æ ¼å¼ä¸æ­£ç¢º
- API Key éæœŸæˆ–ç„¡æ•ˆ
- è«‹æ±‚æ¨™é ­æ ¼å¼éŒ¯èª¤

**è§£æ±ºæ–¹æ¡ˆ**:

```bash
# æ–¹æ¡ˆ 1: é©—è­‰ API Key æ ¼å¼
API_KEY="dev_407CYuVKuP_s3hVqIhO4JZKqcE4-W9ocTgc_fldjxso"
if [[ $API_KEY =~ ^(dev_|user_|admin_).+ ]]; then
    echo "âœ… API Key æ ¼å¼æ­£ç¢º"
else
    echo "âŒ API Key æ ¼å¼ä¸æ­£ç¢º"
fi

# æ–¹æ¡ˆ 2: æ¸¬è©¦ä¸åŒçš„ API Key
curl -X POST http://127.0.0.1:8080/api/process \
  -H "Content-Type: application/json" \
  -H "X-API-Key: dev_407CYuVKuP_s3hVqIhO4JZKqcE4-W9ocTgc_fldjxso" \
  -d '{"request": "æ¸¬è©¦èªè­‰", "context": {}}'

# æ–¹æ¡ˆ 3: æª¢æŸ¥æœå‹™å™¨ API Key é…ç½®
grep -r "api.*key" PowerAutomation/config/
```

**API Key ç®¡ç†æœ€ä½³å¯¦å‹™**:
```python
# api_key_manager.py
import os
import hashlib
import secrets
from datetime import datetime, timedelta

class APIKeyManager:
    def __init__(self):
        self.valid_keys = self.load_api_keys()
    
    def generate_api_key(self, role='user', expiry_days=90):
        """
        ç”Ÿæˆæ–°çš„ API Key
        """
        prefix = f"{role}_"
        random_part = secrets.token_urlsafe(32)
        api_key = f"{prefix}{random_part}"
        
        expiry_date = datetime.now() + timedelta(days=expiry_days)
        
        key_info = {
            'key': api_key,
            'role': role,
            'created_at': datetime.now().isoformat(),
            'expires_at': expiry_date.isoformat(),
            'status': 'active'
        }
        
        return key_info
    
    def validate_api_key(self, api_key):
        """
        é©—è­‰ API Key æœ‰æ•ˆæ€§
        """
        if not api_key:
            return False, "API Key ä¸èƒ½ç‚ºç©º"
        
        if api_key not in self.valid_keys:
            return False, "ç„¡æ•ˆçš„ API Key"
        
        key_info = self.valid_keys[api_key]
        if key_info['status'] != 'active':
            return False, "API Key å·²åœç”¨"
        
        # æª¢æŸ¥éæœŸæ™‚é–“
        if 'expires_at' in key_info:
            expiry_date = datetime.fromisoformat(key_info['expires_at'])
            if datetime.now() > expiry_date:
                return False, "API Key å·²éæœŸ"
        
        return True, "API Key æœ‰æ•ˆ"
```

#### å•é¡Œ 3: test_flow_mcp åŸ·è¡Œè¶…æ™‚

**ç—‡ç‹€**:
```
Request timeout after 30 seconds
test_flow_mcp analysis incomplete
```

**å¯èƒ½åŸå› **:
- åˆ†æè³‡æ–™é‡éå¤§
- ç³»çµ±è³‡æºä¸è¶³
- ç¶²è·¯å»¶é²å•é¡Œ

**è§£æ±ºæ–¹æ¡ˆ**:

```python
# èª¿æ•´è¶…æ™‚è¨­å®š
def execute_test_with_extended_timeout():
    """
    ä½¿ç”¨å»¶é•·çš„è¶…æ™‚æ™‚é–“åŸ·è¡Œæ¸¬è©¦
    """
    import requests
    
    test_request = {
        "request": "è«‹åˆ†æç•¶å‰ç³»çµ±çš„æ¸¬è©¦è¦†è“‹ç‡",
        "context": {
            "source": "api_call",
            "user_role": "developer",
            "workflow_type": "test_flow_analysis",
            "timeout_extended": True  # è«‹æ±‚å»¶é•·è™•ç†æ™‚é–“
        }
    }
    
    try:
        response = requests.post(
            "http://127.0.0.1:8080/api/process",
            headers={
                "Content-Type": "application/json",
                "X-API-Key": "dev_407CYuVKuP_s3hVqIhO4JZKqcE4-W9ocTgc_fldjxso"
            },
            json=test_request,
            timeout=300  # å»¶é•·åˆ° 5 åˆ†é˜
        )
        
        return response.json()
        
    except requests.exceptions.Timeout:
        print("è«‹æ±‚ä»ç„¶è¶…æ™‚ï¼Œå»ºè­°åˆ†æ‰¹è™•ç†æˆ–æª¢æŸ¥ç³»çµ±è³‡æº")
        return None
```

**ç³»çµ±è³‡æºç›£æ§**:
```bash
# å»ºç«‹è³‡æºç›£æ§è…³æœ¬
cat > monitor_resources.sh << 'EOF'
#!/bin/bash
echo "=== ç³»çµ±è³‡æºç›£æ§ ==="
echo "æ™‚é–“: $(date)"
echo ""

echo "CPU ä½¿ç”¨ç‡:"
top -bn1 | grep "Cpu(s)" | awk '{print $2}' | cut -d'%' -f1

echo ""
echo "è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³:"
free -h

echo ""
echo "ç£ç¢Ÿä½¿ç”¨æƒ…æ³:"
df -h | grep -E "/$|/home"

echo ""
echo "PowerAutomation ç¨‹åºç‹€æ…‹:"
ps aux | grep -E "(python.*powerautomation|fully_integrated_system)" | grep -v grep

echo ""
echo "ç¶²è·¯é€£æ¥ç‹€æ…‹:"
netstat -tulpn | grep 8080
EOF

chmod +x monitor_resources.sh
```

#### å•é¡Œ 4: æ¸¬è©¦çµæœä¸ä¸€è‡´

**ç—‡ç‹€**:
- ç›¸åŒçš„æ¸¬è©¦æ¡ˆä¾‹åœ¨ä¸åŒæ™‚é–“åŸ·è¡Œç”¢ç”Ÿä¸åŒçµæœ
- æ¸¬è©¦é€šéç‡æ³¢å‹•å¾ˆå¤§
- åˆ†æçµæœèˆ‡é æœŸä¸ç¬¦

**å¯èƒ½åŸå› **:
- æ¸¬è©¦ç’°å¢ƒä¸ç©©å®š
- æ¸¬è©¦è³‡æ–™æ±¡æŸ“
- ä¸¦è¡ŒåŸ·è¡Œè¡çª

**è§£æ±ºæ–¹æ¡ˆ**:

```python
# å»ºç«‹æ¸¬è©¦ç’°å¢ƒéš”é›¢æ©Ÿåˆ¶
class TestEnvironmentManager:
    def __init__(self):
        self.test_isolation_enabled = True
        self.cleanup_after_test = True
    
    def setup_isolated_environment(self, test_id):
        """
        ç‚ºæ¯å€‹æ¸¬è©¦å»ºç«‹éš”é›¢ç’°å¢ƒ
        """
        isolation_config = {
            'test_id': test_id,
            'timestamp': datetime.now().isoformat(),
            'data_snapshot': self.create_data_snapshot(),
            'environment_variables': self.capture_env_vars(),
            'system_state': self.capture_system_state()
        }
        
        return isolation_config
    
    def cleanup_test_environment(self, isolation_config):
        """
        æ¸…ç†æ¸¬è©¦ç’°å¢ƒ
        """
        if self.cleanup_after_test:
            self.restore_data_snapshot(isolation_config['data_snapshot'])
            self.restore_env_vars(isolation_config['environment_variables'])
            self.clear_temp_files(isolation_config['test_id'])
    
    def ensure_test_repeatability(self, test_case):
        """
        ç¢ºä¿æ¸¬è©¦å¯é‡è¤‡æ€§
        """
        # å›ºå®šéš¨æ©Ÿç¨®å­
        import random
        random.seed(42)
        
        # æ¸…ç†å¿«å–
        self.clear_cache()
        
        # é‡ç½®ç³»çµ±ç‹€æ…‹
        self.reset_system_state()
        
        return True
```

#### å•é¡Œ 5: è¨˜æ†¶é«”æ´©æ¼å•é¡Œ

**ç—‡ç‹€**:
- é•·æ™‚é–“é‹è¡Œå¾Œç³»çµ±è®Šæ…¢
- è¨˜æ†¶é«”ä½¿ç”¨é‡æŒçºŒå¢é•·
- ç³»çµ±æœ€çµ‚å´©æ½°

**è¨ºæ–·å·¥å…·**:
```python
# memory_profiler.py
import psutil
import gc
import tracemalloc
from datetime import datetime

class MemoryProfiler:
    def __init__(self):
        self.start_memory = None
        self.snapshots = []
        tracemalloc.start()
    
    def start_profiling(self):
        """
        é–‹å§‹è¨˜æ†¶é«”åˆ†æ
        """
        self.start_memory = psutil.Process().memory_info().rss
        gc.collect()  # å¼·åˆ¶åƒåœ¾å›æ”¶
        
    def take_snapshot(self, label=""):
        """
        è¨˜éŒ„è¨˜æ†¶é«”å¿«ç…§
        """
        current_memory = psutil.Process().memory_info().rss
        snapshot = tracemalloc.take_snapshot()
        
        self.snapshots.append({
            'timestamp': datetime.now().isoformat(),
            'label': label,
            'memory_usage': current_memory,
            'memory_diff': current_memory - self.start_memory,
            'snapshot': snapshot
        })
        
        return current_memory
    
    def analyze_memory_growth(self):
        """
        åˆ†æè¨˜æ†¶é«”å¢é•·è¶¨å‹¢
        """
        if len(self.snapshots) < 2:
            return "éœ€è¦è‡³å°‘å…©å€‹å¿«ç…§æ‰èƒ½åˆ†æè¶¨å‹¢"
        
        growth_analysis = []
        for i in range(1, len(self.snapshots)):
            prev_snapshot = self.snapshots[i-1]
            curr_snapshot = self.snapshots[i]
            
            growth = curr_snapshot['memory_usage'] - prev_snapshot['memory_usage']
            growth_analysis.append({
                'period': f"{prev_snapshot['label']} -> {curr_snapshot['label']}",
                'growth_bytes': growth,
                'growth_mb': growth / (1024 * 1024)
            })
        
        return growth_analysis
    
    def find_memory_leaks(self):
        """
        å°‹æ‰¾è¨˜æ†¶é«”æ´©æ¼
        """
        if not self.snapshots:
            return "æ²’æœ‰è¨˜æ†¶é«”å¿«ç…§å¯ä¾›åˆ†æ"
        
        latest_snapshot = self.snapshots[-1]['snapshot']
        top_stats = latest_snapshot.statistics('lineno')
        
        leak_candidates = []
        for stat in top_stats[:10]:
            leak_candidates.append({
                'file': stat.traceback.format()[0],
                'memory_usage_mb': stat.size / (1024 * 1024),
                'allocation_count': stat.count
            })
        
        return leak_candidates

# ä½¿ç”¨ç¯„ä¾‹
profiler = MemoryProfiler()
profiler.start_profiling()

# åœ¨æ¸¬è©¦åŸ·è¡Œçš„é—œéµé»è¨˜éŒ„å¿«ç…§
profiler.take_snapshot("æ¸¬è©¦é–‹å§‹")
# ... åŸ·è¡Œæ¸¬è©¦ ...
profiler.take_snapshot("ç¬¬ä¸€éšæ®µå®Œæˆ")
# ... ç¹¼çºŒæ¸¬è©¦ ...
profiler.take_snapshot("æ¸¬è©¦çµæŸ")

# åˆ†æçµæœ
growth_analysis = profiler.analyze_memory_growth()
leak_analysis = profiler.find_memory_leaks()
```

### æ•ˆèƒ½èª¿å„ªå»ºè­°

#### ç³»çµ±å±¤ç´šå„ªåŒ–

```bash
# èª¿æ•´ç³»çµ±åƒæ•¸
echo "èª¿æ•´ TCP é€£æ¥åƒæ•¸"
echo 'net.core.somaxconn = 1024' >> /etc/sysctl.conf
echo 'net.core.netdev_max_backlog = 5000' >> /etc/sysctl.conf

# èª¿æ•´ Python åƒåœ¾å›æ”¶
export PYTHONOPTIMIZE=1
export PYTHONDONTWRITEBYTECODE=1

# èª¿æ•´ Flask é…ç½®
export FLASK_ENV=production
export FLASK_DEBUG=0
```

#### æ‡‰ç”¨å±¤ç´šå„ªåŒ–

```python
# å„ªåŒ–é…ç½®
OPTIMIZATION_CONFIG = {
    'enable_caching': True,
    'cache_ttl': 300,  # 5 åˆ†é˜
    'max_concurrent_requests': 10,
    'request_timeout': 60,
    'enable_compression': True,
    'log_level': 'WARNING',  # æ¸›å°‘æ—¥èªŒè¼¸å‡º
    'gc_threshold': (700, 10, 10)  # èª¿æ•´åƒåœ¾å›æ”¶é–¾å€¼
}

# å¯¦æ–½å„ªåŒ–
def apply_optimizations():
    """
    æ‡‰ç”¨æ•ˆèƒ½å„ªåŒ–è¨­å®š
    """
    import gc
    
    # èª¿æ•´åƒåœ¾å›æ”¶
    gc.set_threshold(*OPTIMIZATION_CONFIG['gc_threshold'])
    
    # å•Ÿç”¨å¿«å–
    if OPTIMIZATION_CONFIG['enable_caching']:
        setup_redis_cache()
    
    # è¨­å®šä¸¦ç™¼é™åˆ¶
    setup_request_limiting()
```

### ç›£æ§èˆ‡å‘Šè­¦

#### å»ºç«‹ç›£æ§å„€è¡¨æ¿

```python
# monitoring_dashboard.py
import time
import json
from datetime import datetime, timedelta

class MonitoringDashboard:
    def __init__(self):
        self.metrics = {
            'system_health': {},
            'performance_metrics': {},
            'error_rates': {},
            'resource_usage': {}
        }
    
    def collect_system_metrics(self):
        """
        æ”¶é›†ç³»çµ±æŒ‡æ¨™
        """
        import psutil
        
        self.metrics['system_health'] = {
            'timestamp': datetime.now().isoformat(),
            'cpu_usage': psutil.cpu_percent(interval=1),
            'memory_usage': psutil.virtual_memory().percent,
            'disk_usage': psutil.disk_usage('/').percent,
            'network_io': psutil.net_io_counters()._asdict()
        }
    
    def collect_application_metrics(self):
        """
        æ”¶é›†æ‡‰ç”¨ç¨‹å¼æŒ‡æ¨™
        """
        # æª¢æŸ¥ PowerAutomation æœå‹™å™¨ç‹€æ…‹
        try:
            response = requests.get('http://127.0.0.1:8080/api/status', timeout=5)
            if response.status_code == 200:
                server_status = response.json()
                self.metrics['performance_metrics'] = {
                    'server_status': 'healthy',
                    'response_time': response.elapsed.total_seconds(),
                    'api_keys_count': server_status.get('api_keys_count', 0),
                    'uptime': server_status.get('uptime', 'unknown')
                }
            else:
                self.metrics['performance_metrics']['server_status'] = 'unhealthy'
        except Exception as e:
            self.metrics['performance_metrics'] = {
                'server_status': 'error',
                'error_message': str(e)
            }
    
    def generate_alert(self, metric_name, current_value, threshold):
        """
        ç”Ÿæˆå‘Šè­¦
        """
        if current_value > threshold:
            alert = {
                'timestamp': datetime.now().isoformat(),
                'metric': metric_name,
                'current_value': current_value,
                'threshold': threshold,
                'severity': 'high' if current_value > threshold * 1.5 else 'medium'
            }
            
            # ç™¼é€å‘Šè­¦é€šçŸ¥
            self.send_alert_notification(alert)
            
            return alert
        
        return None
    
    def send_alert_notification(self, alert):
        """
        ç™¼é€å‘Šè­¦é€šçŸ¥
        """
        # é€™è£¡å¯ä»¥æ•´åˆ Slackã€Email æˆ–å…¶ä»–é€šçŸ¥ç³»çµ±
        print(f"ğŸš¨ å‘Šè­¦: {alert['metric']} è¶…éé–¾å€¼")
        print(f"   ç•¶å‰å€¼: {alert['current_value']}")
        print(f"   é–¾å€¼: {alert['threshold']}")
        print(f"   åš´é‡ç¨‹åº¦: {alert['severity']}")
```

---

