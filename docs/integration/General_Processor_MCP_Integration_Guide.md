# General Processor MCP é›†æˆä½¿ç”¨æŒ‡å—

## æ¦‚è¿°

General Processor MCP æ˜¯ PowerAutomation ä¸­çš„é€šç”¨ä»»å‹™è™•ç†å™¨ï¼Œè² è²¬è™•ç†å„ç¨®é¡å‹çš„è‡ªå‹•åŒ–ä»»å‹™ã€‚é€šéé›†æˆ Human Loop MCPï¼Œæˆ‘å€‘å¯ä»¥åœ¨è™•ç†è¤‡é›œä»»å‹™æ™‚å¼•å…¥äººå·¥æ™ºæ…§ï¼Œç¢ºä¿ä»»å‹™è™•ç†çš„æº–ç¢ºæ€§å’Œé©æ‡‰æ€§ã€‚

## ğŸ¯ é›†æˆç›®æ¨™

### ä¸»è¦ä½¿ç”¨å ´æ™¯
1. **è¤‡é›œä»»å‹™ç­–ç•¥é¸æ“‡** - é«˜è¤‡é›œåº¦ä»»å‹™çš„è™•ç†ç­–ç•¥æ±ºç­–
2. **ç•°å¸¸æƒ…æ³è™•ç†** - ä»»å‹™åŸ·è¡Œç•°å¸¸æ™‚çš„æ¢å¾©ç­–ç•¥
3. **è³‡æºåˆ†é…æ±ºç­–** - å¤§å‹ä»»å‹™çš„è³‡æºåˆ†é…ç­–ç•¥
4. **å„ªå…ˆç´šèª¿æ•´** - ä»»å‹™éšŠåˆ—çš„å„ªå…ˆç´šå‹•æ…‹èª¿æ•´
5. **å“è³ªæ§åˆ¶æª¢æŸ¥** - ä»»å‹™çµæœçš„äººå·¥å“è³ªé©—è­‰
6. **åƒæ•¸å„ªåŒ–** - ä»»å‹™åƒæ•¸çš„äººå·¥èª¿å„ª

### é›†æˆåŸå‰‡
- **æ™ºèƒ½åˆ†æµ** - ä½¿ç”¨ AICore è©•ä¼°ä»»å‹™è¤‡é›œåº¦ï¼Œæ±ºå®šæ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
- **ç­–ç•¥é¸æ“‡** - åœ¨å¤šç¨®è™•ç†ç­–ç•¥ä¸­è«‹æ±‚äººå·¥é¸æ“‡æœ€ä½³æ–¹æ¡ˆ
- **ç•°å¸¸è™•ç†** - è‡ªå‹•è™•ç†å¤±æ•—æ™‚çš„äººå·¥æ±ºç­–æ”¯æŒ
- **å­¸ç¿’å„ªåŒ–** - æ”¶é›†äººå·¥æ±ºç­–æ•¸æ“šï¼Œå„ªåŒ– AICore çš„è‡ªå‹•æ±ºç­–èƒ½åŠ›

## ğŸ—ï¸ é›†æˆæ¶æ§‹

### åŸºæœ¬æ¶æ§‹
```
General Processor MCP
â”œâ”€â”€ ä»»å‹™åˆ†æå™¨ (AICore)
â”‚   â”œâ”€â”€ è¤‡é›œåº¦è©•ä¼°
â”‚   â”œâ”€â”€ è³‡æºéœ€æ±‚åˆ†æ
â”‚   â”œâ”€â”€ é¢¨éšªè©•ä¼°
â”‚   â””â”€â”€ ç­–ç•¥æ¨è–¦
â”œâ”€â”€ Human Loop æ±ºç­–å™¨ (æ–°å¢)
â”‚   â”œâ”€â”€ ç­–ç•¥é¸æ“‡
â”‚   â”œâ”€â”€ åƒæ•¸ç¢ºèª
â”‚   â”œâ”€â”€ ç•°å¸¸è™•ç†
â”‚   â””â”€â”€ å“è³ªæª¢æŸ¥
â”œâ”€â”€ åŸ·è¡Œå¼•æ“ (AICore)
â”‚   â”œâ”€â”€ ä»»å‹™èª¿åº¦
â”‚   â”œâ”€â”€ è³‡æºç®¡ç†
â”‚   â”œâ”€â”€ é€²åº¦ç›£æ§
â”‚   â””â”€â”€ çµæœæ”¶é›†
â””â”€â”€ å­¸ç¿’ç³»çµ± (AICore)
    â”œâ”€â”€ æ±ºç­–è¨˜éŒ„
    â”œâ”€â”€ æ¨¡å¼è­˜åˆ¥
    â”œâ”€â”€ ç­–ç•¥å„ªåŒ–
    â””â”€â”€ æ€§èƒ½æå‡
```

### æ±ºç­–æµç¨‹
```
ä»»å‹™è«‹æ±‚
    â†“
AICore ä»»å‹™åˆ†æ
    â†“
è¤‡é›œåº¦ & é¢¨éšªè©•ä¼°
    â†“
éœ€è¦äººå·¥ä»‹å…¥ï¼Ÿ
â”œâ”€â”€ å¦ â†’ AICore è‡ªå‹•è™•ç†
â””â”€â”€ æ˜¯ â†’ Human Loop æ±ºç­–
    â”œâ”€â”€ ç­–ç•¥é¸æ“‡
    â”œâ”€â”€ åƒæ•¸ç¢ºèª
    â””â”€â”€ åŸ·è¡Œæ‰¹å‡†
    â†“
AICore åŸ·è¡Œæ±ºç­–
    â†“
çµæœé©—è­‰
    â†“
éœ€è¦äººå·¥æª¢æŸ¥ï¼Ÿ
â”œâ”€â”€ å¦ â†’ è¿”å›çµæœ
â””â”€â”€ æ˜¯ â†’ Human Loop å“è³ªæª¢æŸ¥
    â†“
æœ€çµ‚çµæœ
```

## ğŸ’» å¯¦ç¾æ–¹å¼

### æ–¹å¼1: ç¹¼æ‰¿ HumanLoopIntegrationMixin (æ¨è–¦)

```python
from PowerAutomation.components.human_loop_mcp_adapter import HumanLoopIntegrationMixin
import asyncio
from typing import Dict, List, Any, Optional
from enum import Enum

class TaskComplexity(Enum):
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class TaskStatus(Enum):
    PENDING = "pending"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"
    CANCELLED = "cancelled"

class GeneralProcessorMCP(HumanLoopIntegrationMixin):
    """
    é€šç”¨ä»»å‹™è™•ç†å™¨ï¼Œé›†æˆ Human Loop åŠŸèƒ½
    """
    
    def __init__(self, config=None):
        super().__init__()
        self.config = config or {}
        self.workflow_id = "general_processor_workflow"
        
        # AICore ç›¸é—œé…ç½®
        self.complexity_threshold = 0.7  # è¤‡é›œåº¦é–¾å€¼
        self.auto_retry_limit = 3  # è‡ªå‹•é‡è©¦æ¬¡æ•¸
        self.human_intervention_enabled = True
        
        # ä»»å‹™éšŠåˆ—
        self.task_queue = []
        self.processing_tasks = {}
    
    async def process_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        è™•ç†å–®å€‹ä»»å‹™
        
        Args:
            task_data: ä»»å‹™æ•¸æ“š
            
        Returns:
            è™•ç†çµæœ
        """
        task_id = task_data.get("task_id", f"task_{int(asyncio.get_event_loop().time())}")
        
        try:
            # 1. ä½¿ç”¨ AICore åˆ†æä»»å‹™
            analysis_result = await self._aicore_analyze_task(task_data)
            
            # 2. è©•ä¼°æ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
            intervention_needed = await self._should_request_human_intervention(
                task_data, analysis_result
            )
            
            if intervention_needed:
                # 3. è«‹æ±‚äººå·¥æ±ºç­–
                human_decision = await self._request_task_processing_strategy(
                    task_data, analysis_result
                )
                
                if not human_decision.get("approved"):
                    return {
                        "success": False,
                        "task_id": task_id,
                        "status": TaskStatus.CANCELLED.value,
                        "reason": "human_cancelled",
                        "message": human_decision.get("message", "ç”¨æˆ¶å–æ¶ˆä»»å‹™")
                    }
                
                # æ‡‰ç”¨äººå·¥æ±ºç­–
                processing_strategy = human_decision.get("strategy", "default")
                processing_params = human_decision.get("params", {})
            else:
                # ä½¿ç”¨ AICore æ¨è–¦çš„ç­–ç•¥
                processing_strategy = analysis_result.get("recommended_strategy", "default")
                processing_params = analysis_result.get("recommended_params", {})
            
            # 4. ä½¿ç”¨ AICore åŸ·è¡Œä»»å‹™
            execution_result = await self._aicore_execute_task(
                task_data, processing_strategy, processing_params, analysis_result
            )
            
            # 5. æª¢æŸ¥æ˜¯å¦éœ€è¦å“è³ªé©—è­‰
            if await self._should_request_quality_check(execution_result, analysis_result):
                quality_check = await self._request_quality_verification(
                    task_data, execution_result
                )
                
                if not quality_check.get("approved"):
                    # å“è³ªæª¢æŸ¥å¤±æ•—ï¼Œè«‹æ±‚è™•ç†ç­–ç•¥
                    retry_decision = await self._request_retry_strategy(
                        task_data, execution_result, quality_check
                    )
                    
                    if retry_decision.get("retry"):
                        # é‡æ–°è™•ç†
                        return await self.process_task({
                            **task_data,
                            "retry_count": task_data.get("retry_count", 0) + 1,
                            "previous_result": execution_result,
                            "quality_feedback": quality_check
                        })
                    else:
                        return {
                            "success": False,
                            "task_id": task_id,
                            "status": TaskStatus.FAILED.value,
                            "reason": "quality_check_failed",
                            "execution_result": execution_result,
                            "quality_check": quality_check
                        }
                
                # å“è³ªæª¢æŸ¥é€šéï¼Œæ›´æ–°çµæœ
                execution_result["quality_verified"] = True
                execution_result["quality_check"] = quality_check
            
            return {
                "success": True,
                "task_id": task_id,
                "status": TaskStatus.COMPLETED.value,
                "result": execution_result,
                "processing_strategy": processing_strategy,
                "human_intervention": intervention_needed
            }
            
        except Exception as e:
            # ç•°å¸¸è™•ç†
            return await self._handle_task_exception(task_data, str(e))
    
    async def process_batch_tasks(self, tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰¹é‡è™•ç†ä»»å‹™
        """
        if len(tasks) > 20:  # å¤§æ‰¹é‡ä»»å‹™
            # è«‹æ±‚æ‰¹é‡è™•ç†ç­–ç•¥
            batch_strategy = await self._request_batch_processing_strategy(tasks)
            
            if not batch_strategy.get("approved"):
                return {
                    "success": False,
                    "reason": "batch_cancelled",
                    "message": "ç”¨æˆ¶å–æ¶ˆæ‰¹é‡è™•ç†"
                }
            
            strategy = batch_strategy.get("strategy", "sequential")
            max_parallel = batch_strategy.get("max_parallel", 5)
            
            return await self._execute_batch_strategy(tasks, strategy, max_parallel)
        else:
            # å°æ‰¹é‡ï¼Œç›´æ¥é †åºè™•ç†
            return await self._execute_batch_strategy(tasks, "sequential", 1)
    
    async def _should_request_human_intervention(self, task_data: Dict[str, Any],
                                               analysis: Dict[str, Any]) -> bool:
        """
        ä½¿ç”¨ AICore æ±ºå®šæ˜¯å¦éœ€è¦äººå·¥ä»‹å…¥
        """
        # é«˜è¤‡é›œåº¦ä»»å‹™
        if analysis.get("complexity_score", 0) > self.complexity_threshold:
            return True
        
        # é—œéµä»»å‹™
        if task_data.get("priority") == "critical":
            return True
        
        # æ–°é¡å‹ä»»å‹™ (AICore ä¿¡å¿ƒåº¦ä½)
        if analysis.get("confidence_score", 1.0) < 0.6:
            return True
        
        # è³‡æºéœ€æ±‚è¶…éé–¾å€¼
        if analysis.get("resource_score", 0) > 0.8:
            return True
        
        # æœ‰é¢¨éšªè­¦å‘Š
        if analysis.get("risk_warnings"):
            return True
        
        return False
    
    async def _request_task_processing_strategy(self, task_data: Dict[str, Any],
                                              analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        è«‹æ±‚ä»»å‹™è™•ç†ç­–ç•¥
        """
        # æ§‹å»ºç­–ç•¥é¸æ“‡æ¶ˆæ¯
        message = self._build_strategy_message(task_data, analysis)
        
        # æ§‹å»ºç­–ç•¥é¸é …
        options = self._build_strategy_options(task_data, analysis)
        
        # è«‹æ±‚äººå·¥é¸æ“‡
        strategy_result = await self.request_human_selection(
            title=f"ä»»å‹™è™•ç†ç­–ç•¥ - {task_data.get('type', 'Unknown')}",
            message=message,
            options=options,
            timeout=300
        )
        
        if not strategy_result.get("success"):
            return {
                "approved": False,
                "message": "ç­–ç•¥é¸æ“‡å¤±æ•—æˆ–è¶…æ™‚"
            }
        
        strategy_choice = strategy_result.get("response", {}).get("choice")
        
        if strategy_choice == "cancel":
            return {
                "approved": False,
                "message": "ç”¨æˆ¶å–æ¶ˆä»»å‹™è™•ç†"
            }
        elif strategy_choice == "custom":
            # è«‹æ±‚è‡ªå®šç¾©åƒæ•¸
            return await self._request_custom_parameters(task_data, analysis)
        else:
            return {
                "approved": True,
                "strategy": strategy_choice,
                "params": self._get_strategy_params(strategy_choice, analysis)
            }
    
    async def _request_custom_parameters(self, task_data: Dict[str, Any],
                                       analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        è«‹æ±‚è‡ªå®šç¾©è™•ç†åƒæ•¸
        """
        # æ§‹å»ºåƒæ•¸è¼¸å…¥å­—æ®µ
        fields = [
            {
                "name": "processing_mode",
                "label": "è™•ç†æ¨¡å¼",
                "type": "select",
                "options": ["fast", "balanced", "thorough"],
                "default": "balanced",
                "required": True
            },
            {
                "name": "max_retries",
                "label": "æœ€å¤§é‡è©¦æ¬¡æ•¸",
                "type": "number",
                "min": 0,
                "max": 10,
                "default": 3,
                "required": True
            },
            {
                "name": "timeout_seconds",
                "label": "è¶…æ™‚æ™‚é–“ (ç§’)",
                "type": "number",
                "min": 30,
                "max": 3600,
                "default": 300,
                "required": True
            },
            {
                "name": "resource_limit",
                "label": "è³‡æºé™åˆ¶ (%)",
                "type": "number",
                "min": 10,
                "max": 100,
                "default": 80,
                "required": True
            },
            {
                "name": "special_instructions",
                "label": "ç‰¹æ®ŠæŒ‡ä»¤",
                "type": "textarea",
                "placeholder": "è¼¸å…¥ä»»ä½•ç‰¹æ®Šè™•ç†æŒ‡ä»¤...",
                "required": False
            }
        ]
        
        params_result = await self.request_human_input(
            title="è‡ªå®šç¾©è™•ç†åƒæ•¸",
            message=f"è«‹ç‚ºä»»å‹™ '{task_data.get('type')}' è¨­ç½®è‡ªå®šç¾©è™•ç†åƒæ•¸:",
            fields=fields,
            timeout=600
        )
        
        if not params_result.get("success"):
            return {
                "approved": False,
                "message": "åƒæ•¸è¨­ç½®å¤±æ•—æˆ–è¶…æ™‚"
            }
        
        custom_params = params_result.get("response", {})
        
        return {
            "approved": True,
            "strategy": "custom",
            "params": custom_params
        }
    
    async def _request_quality_verification(self, task_data: Dict[str, Any],
                                          execution_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        è«‹æ±‚å“è³ªé©—è­‰
        """
        message = self._build_quality_check_message(task_data, execution_result)
        
        options = [
            {"value": "approve", "label": "å“è³ªåˆæ ¼ï¼Œæ‰¹å‡†çµæœ"},
            {"value": "reject", "label": "å“è³ªä¸åˆæ ¼ï¼Œéœ€è¦é‡æ–°è™•ç†"},
            {"value": "modify", "label": "éœ€è¦å¾®èª¿ï¼Œæä¾›ä¿®æ”¹å»ºè­°"}
        ]
        
        quality_result = await self.request_human_confirmation(
            title=f"å“è³ªæª¢æŸ¥ - {task_data.get('type', 'Unknown')}",
            message=message,
            options=options,
            timeout=300
        )
        
        if not quality_result.get("success"):
            return {
                "approved": False,
                "message": "å“è³ªæª¢æŸ¥å¤±æ•—æˆ–è¶…æ™‚"
            }
        
        choice = quality_result.get("response", {}).get("choice")
        
        if choice == "approve":
            return {
                "approved": True,
                "quality_score": 1.0,
                "feedback": "äººå·¥é©—è­‰é€šé"
            }
        elif choice == "modify":
            # è«‹æ±‚ä¿®æ”¹å»ºè­°
            return await self._request_modification_suggestions(task_data, execution_result)
        else:  # reject
            return {
                "approved": False,
                "quality_score": 0.0,
                "feedback": "äººå·¥é©—è­‰ä¸é€šéï¼Œéœ€è¦é‡æ–°è™•ç†"
            }
    
    async def _request_batch_processing_strategy(self, tasks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        è«‹æ±‚æ‰¹é‡è™•ç†ç­–ç•¥
        """
        task_types = {}
        for task in tasks:
            task_type = task.get("type", "unknown")
            task_types[task_type] = task_types.get(task_type, 0) + 1
        
        type_summary = "\n".join([f"  â€¢ {t}: {c} å€‹" for t, c in task_types.items()])
        
        message = f"""å³å°‡æ‰¹é‡è™•ç† {len(tasks)} å€‹ä»»å‹™:

ğŸ“Š ä»»å‹™é¡å‹åˆ†å¸ƒ:
{type_summary}

âš ï¸ æ‰¹é‡è™•ç†æ³¨æ„äº‹é …:
â€¢ ä¸¦è¡Œè™•ç†é€Ÿåº¦å¿«ä½†å¯èƒ½æ¶ˆè€—æ›´å¤šè³‡æº
â€¢ é †åºè™•ç†ç©©å®šä½†è€—æ™‚è¼ƒé•·
â€¢ åˆ†æ‰¹è™•ç†æ˜¯å¹³è¡¡æ–¹æ¡ˆ

è«‹é¸æ“‡è™•ç†ç­–ç•¥:"""
        
        options = [
            {"value": "sequential", "label": "é †åºè™•ç† (ç©©å®šï¼Œè¼ƒæ…¢)"},
            {"value": "parallel", "label": "ä¸¦è¡Œè™•ç† (å¿«é€Ÿï¼Œé«˜è³‡æºæ¶ˆè€—)"},
            {"value": "batch", "label": "åˆ†æ‰¹è™•ç† (å¹³è¡¡æ–¹æ¡ˆ)"},
            {"value": "selective", "label": "é¸æ“‡æ€§è™•ç† (æ‰‹å‹•é¸æ“‡ä»»å‹™)"},
            {"value": "cancel", "label": "å–æ¶ˆæ‰¹é‡è™•ç†"}
        ]
        
        strategy_result = await self.request_human_selection(
            title=f"æ‰¹é‡è™•ç†ç­–ç•¥ ({len(tasks)} å€‹ä»»å‹™)",
            message=message,
            options=options,
            timeout=300
        )
        
        if not strategy_result.get("success"):
            return {"approved": False, "message": "ç­–ç•¥é¸æ“‡å¤±æ•—"}
        
        choice = strategy_result.get("response", {}).get("choice")
        
        if choice == "cancel":
            return {"approved": False, "message": "ç”¨æˆ¶å–æ¶ˆæ‰¹é‡è™•ç†"}
        elif choice == "selective":
            return await self._request_selective_processing(tasks)
        else:
            # è«‹æ±‚ä¸¦è¡Œåº¦è¨­ç½®
            if choice in ["parallel", "batch"]:
                parallel_params = await self._request_parallel_parameters(len(tasks))
                return {
                    "approved": True,
                    "strategy": choice,
                    "max_parallel": parallel_params.get("max_parallel", 5)
                }
            else:
                return {
                    "approved": True,
                    "strategy": choice,
                    "max_parallel": 1
                }
    
    def _build_strategy_message(self, task_data: Dict[str, Any], 
                              analysis: Dict[str, Any]) -> str:
        """
        æ§‹å»ºç­–ç•¥é¸æ“‡æ¶ˆæ¯
        """
        message_parts = [
            f"ä»»å‹™è™•ç†ç­–ç•¥é¸æ“‡",
            f"",
            f"ğŸ“‹ ä»»å‹™ä¿¡æ¯:",
            f"  â€¢ é¡å‹: {task_data.get('type', 'Unknown')}",
            f"  â€¢ å„ªå…ˆç´š: {task_data.get('priority', 'Normal')}",
            f"  â€¢ é ä¼°æ™‚é–“: {analysis.get('estimated_duration', 'Unknown')}",
            f"",
            f"ğŸ§  AICore åˆ†æ:",
            f"  â€¢ è¤‡é›œåº¦åˆ†æ•¸: {analysis.get('complexity_score', 0):.2f}",
            f"  â€¢ ä¿¡å¿ƒåº¦: {analysis.get('confidence_score', 0):.2f}",
            f"  â€¢ è³‡æºéœ€æ±‚: {analysis.get('resource_score', 0):.2f}",
        ]
        
        if analysis.get("risk_warnings"):
            message_parts.extend([
                f"",
                f"âš ï¸ é¢¨éšªè­¦å‘Š:",
            ])
            for warning in analysis["risk_warnings"]:
                message_parts.append(f"  â€¢ {warning}")
        
        if analysis.get("recommended_strategy"):
            message_parts.extend([
                f"",
                f"ğŸ’¡ AICore æ¨è–¦ç­–ç•¥: {analysis['recommended_strategy']}"
            ])
        
        message_parts.extend([
            f"",
            f"è«‹é¸æ“‡è™•ç†ç­–ç•¥:"
        ])
        
        return "\n".join(message_parts)
    
    def _build_strategy_options(self, task_data: Dict[str, Any],
                              analysis: Dict[str, Any]) -> List[Dict[str, str]]:
        """
        æ§‹å»ºç­–ç•¥é¸é …
        """
        options = [
            {"value": "fast", "label": "å¿«é€Ÿè™•ç† (å„ªå…ˆé€Ÿåº¦)"},
            {"value": "balanced", "label": "å¹³è¡¡è™•ç† (é€Ÿåº¦èˆ‡å“è³ªä¸¦é‡)"},
            {"value": "thorough", "label": "æ·±åº¦è™•ç† (å„ªå…ˆå“è³ª)"},
            {"value": "custom", "label": "è‡ªå®šç¾©åƒæ•¸"},
            {"value": "cancel", "label": "å–æ¶ˆè™•ç†"}
        ]
        
        # æ ¹æ“šä»»å‹™é¡å‹æ·»åŠ ç‰¹æ®Šé¸é …
        task_type = task_data.get("type", "")
        if "data" in task_type.lower():
            options.insert(-2, {"value": "data_optimized", "label": "æ•¸æ“šå„ªåŒ–è™•ç†"})
        elif "api" in task_type.lower():
            options.insert(-2, {"value": "api_optimized", "label": "API å„ªåŒ–è™•ç†"})
        
        return options
    
    # AICore é›†æˆæ–¹æ³•
    async def _aicore_analyze_task(self, task_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨ AICore åˆ†æä»»å‹™
        """
        # æ¨¡æ“¬ AICore ä»»å‹™åˆ†æ
        task_type = task_data.get("type", "unknown")
        data_size = len(str(task_data.get("data", "")))
        
        # è¨ˆç®—è¤‡é›œåº¦åˆ†æ•¸
        complexity_score = 0.3  # åŸºç¤è¤‡é›œåº¦
        
        if "complex" in task_type.lower():
            complexity_score += 0.4
        if data_size > 1000:
            complexity_score += 0.2
        if task_data.get("priority") == "critical":
            complexity_score += 0.1
        
        # è¨ˆç®—ä¿¡å¿ƒåº¦
        confidence_score = 0.9
        if task_type == "unknown":
            confidence_score -= 0.3
        if not task_data.get("data"):
            confidence_score -= 0.2
        
        # é¢¨éšªè­¦å‘Š
        risk_warnings = []
        if complexity_score > 0.8:
            risk_warnings.append("é«˜è¤‡é›œåº¦ä»»å‹™ï¼Œå»ºè­°ä»”ç´°ç›£æ§")
        if data_size > 10000:
            risk_warnings.append("å¤§æ•¸æ“šé‡è™•ç†ï¼Œæ³¨æ„è³‡æºæ¶ˆè€—")
        
        return {
            "complexity_score": complexity_score,
            "confidence_score": confidence_score,
            "resource_score": min(complexity_score + 0.1, 1.0),
            "estimated_duration": f"{int(complexity_score * 300)} ç§’",
            "recommended_strategy": "balanced" if complexity_score < 0.7 else "thorough",
            "risk_warnings": risk_warnings if risk_warnings else None,
            "analysis_timestamp": "2024-06-24T12:00:00Z"
        }
    
    async def _aicore_execute_task(self, task_data: Dict[str, Any], strategy: str,
                                 params: Dict[str, Any], analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä½¿ç”¨ AICore åŸ·è¡Œä»»å‹™
        """
        # æ¨¡æ“¬ä»»å‹™åŸ·è¡Œ
        execution_time = analysis.get("estimated_duration", "60 ç§’")
        await asyncio.sleep(2)  # æ¨¡æ“¬åŸ·è¡Œæ™‚é–“
        
        # æ ¹æ“šç­–ç•¥èª¿æ•´çµæœ
        quality_score = 0.8
        if strategy == "thorough":
            quality_score = 0.95
        elif strategy == "fast":
            quality_score = 0.7
        
        return {
            "execution_id": f"exec_{int(asyncio.get_event_loop().time())}",
            "strategy_used": strategy,
            "parameters_used": params,
            "execution_time": execution_time,
            "quality_score": quality_score,
            "output_data": {"processed": True, "result": "ä»»å‹™åŸ·è¡Œå®Œæˆ"},
            "resource_usage": {"cpu": "45%", "memory": "2.1GB", "time": execution_time},
            "execution_timestamp": "2024-06-24T12:02:00Z"
        }
```

### æ–¹å¼2: ç›´æ¥ä½¿ç”¨å®¢æˆ¶ç«¯

```python
from PowerAutomation.components.human_loop_mcp_adapter import HumanLoopMCPClient

class GeneralProcessorMCPDirect:
    """
    ä½¿ç”¨ç›´æ¥å®¢æˆ¶ç«¯æ–¹å¼çš„é€šç”¨è™•ç†å™¨
    """
    
    def __init__(self, mcp_url="http://localhost:8096"):
        self.human_loop_client = HumanLoopMCPClient(mcp_url)
        self.workflow_id = "general_processor_direct"
    
    async def handle_task_exception(self, task_data: Dict[str, Any], 
                                  error: str) -> Dict[str, Any]:
        """
        è™•ç†ä»»å‹™ç•°å¸¸ï¼Œè«‹æ±‚äººå·¥æ±ºç­–
        """
        recovery_session = await self.human_loop_client.create_interaction_session({
            "interaction_type": "selection",
            "title": f"ä»»å‹™ç•°å¸¸è™•ç† - {task_data.get('type', 'Unknown')}",
            "message": f"ä»»å‹™åŸ·è¡Œé‡åˆ°ç•°å¸¸:\n\néŒ¯èª¤ä¿¡æ¯: {error}\n\nè«‹é¸æ“‡è™•ç†æ–¹å¼:",
            "options": [
                {"value": "retry", "label": "é‡è©¦ä»»å‹™"},
                {"value": "skip", "label": "è·³éä»»å‹™"},
                {"value": "modify", "label": "ä¿®æ”¹åƒæ•¸å¾Œé‡è©¦"},
                {"value": "escalate", "label": "ä¸Šå ±çµ¦å°ˆå®¶è™•ç†"}
            ],
            "timeout": 300
        })
        
        if recovery_session.get("success"):
            session_id = recovery_session.get("session_id")
            response = await self.human_loop_client.wait_for_user_response(session_id)
            
            if response.get("success"):
                choice = response.get("response", {}).get("choice")
                return await self._execute_recovery_strategy(task_data, error, choice)
        
        # é»˜èªè·³éä»»å‹™
        return {"success": False, "action": "skipped", "reason": "ç„¡æ³•ç²å–äººå·¥æ±ºç­–"}
```

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨
```python
# åˆå§‹åŒ–è™•ç†å™¨
processor = GeneralProcessorMCP()

# è™•ç†ç°¡å–®ä»»å‹™ (é€šå¸¸ä¸éœ€è¦äººå·¥ä»‹å…¥)
simple_task = {
    "task_id": "task_001",
    "type": "data_processing",
    "priority": "normal",
    "data": {"records": 100}
}
result = await processor.process_task(simple_task)

# è™•ç†è¤‡é›œä»»å‹™ (æœƒè«‹æ±‚äººå·¥ç­–ç•¥é¸æ“‡)
complex_task = {
    "task_id": "task_002", 
    "type": "complex_analysis",
    "priority": "critical",
    "data": {"large_dataset": "..."}
}
result = await processor.process_task(complex_task)
```

### æ‰¹é‡è™•ç†
```python
# æ‰¹é‡ä»»å‹™è™•ç†
tasks = [
    {"type": "data_processing", "data": {"records": 50}},
    {"type": "api_integration", "data": {"endpoints": 10}},
    {"type": "report_generation", "data": {"templates": 5}}
]

batch_result = await processor.process_batch_tasks(tasks)
```

### ç•°å¸¸è™•ç†
```python
# å¸¶ç•°å¸¸è™•ç†çš„ä»»å‹™
try:
    result = await processor.process_task(risky_task)
except Exception as e:
    recovery_result = await processor.handle_task_exception(risky_task, str(e))
```

## ğŸ“‹ é…ç½®é¸é …

### ç’°å¢ƒè®Šé‡
```bash
# è¤‡é›œåº¦é–¾å€¼
export COMPLEXITY_THRESHOLD="0.7"

# è‡ªå‹•é‡è©¦é™åˆ¶
export AUTO_RETRY_LIMIT="3"

# å•Ÿç”¨äººå·¥ä»‹å…¥
export HUMAN_INTERVENTION_ENABLED="true"

# å“è³ªæª¢æŸ¥é–¾å€¼
export QUALITY_CHECK_THRESHOLD="0.8"
```

### é…ç½®æ–‡ä»¶
```yaml
# general_processor_config.yaml
processing:
  complexity_threshold: 0.7
  auto_retry_limit: 3
  human_intervention_enabled: true
  
quality_control:
  enabled: true
  threshold: 0.8
  require_verification_critical: true
  
batch_processing:
  max_parallel_tasks: 10
  batch_size: 50
  timeout_per_task: 300
```

é€™å°±æ˜¯ General Processor MCP çš„å®Œæ•´é›†æˆä½¿ç”¨æ–¹å¼ï¼æ¥ä¸‹ä¾†æˆ‘å°‡æä¾›å¯¦éš›ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å¯¦è¸ã€‚

