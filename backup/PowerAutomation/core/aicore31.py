#!/usr/bin/env python3
"""
AICore 3.1 - Enhanced Dynamic Expert System
å¢å¼ºç‰ˆåŠ¨æ€ä¸“å®¶ç³»ç»Ÿï¼Œä¼˜åŒ–æ€§èƒ½ç›‘æ§å’Œé”™è¯¯å¤„ç†
"""

import asyncio
import time
import logging
import json
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime
import hashlib
import traceback

# å¯¼å…¥ç»„ä»¶
from components.general_processor_mcp import GeneralProcessorMCP, create_general_processor_mcp
from components.dynamic_expert_registry import (
    DynamicExpertRegistry, create_dynamic_expert_registry,
    ExpertRegistrationRequest, ExpertProfile, ExpertStatus, ExpertType as DynamicExpertType
)
from components.expert_recommendation_aggregator import (
    ExpertRecommendationAggregator, create_expert_recommendation_aggregator,
    AggregationStrategy, AggregatedRecommendation, AggregationResult
)
from components.dynamic_mcp_generator import (
    DynamicMCPGenerator, create_dynamic_mcp_generator,
    MCPToolType, MCPToolSpec, DynamicMCPRequest
)
from tools.tool_registry import ToolRegistry
from actions.action_executor import ActionExecutor

# å¢å¼ºç‰ˆå¯¼å…¥
try:
    from components.enhanced_test_flow_mcp_v52 import TestFlowMCPv52
except ImportError:
    TestFlowMCPv52 = None

logger = logging.getLogger(__name__)

class ProcessingStage(Enum):
    """å¤„ç†é˜¶æ®µ - 6é˜¶æ®µå®Œæ•´æµç¨‹"""
    INTEGRATED_SEARCH_ANALYSIS = "integrated_search_analysis"      # æ•´åˆå¼æœç´¢å’Œåˆ†æ
    DYNAMIC_EXPERT_GENERATION = "dynamic_expert_generation"        # åŠ¨æ€ä¸“å®¶ç”Ÿæˆ
    EXPERT_RESPONSE_GENERATION = "expert_response_generation"      # ä¸“å®¶å›ç­”ç”Ÿæˆ
    EXPERT_RECOMMENDATION_AGGREGATION = "expert_recommendation_aggregation"  # ä¸“å®¶å»ºè®®èšåˆ
    DYNAMIC_TOOL_GENERATION = "dynamic_tool_generation"           # åŠ¨æ€å·¥å…·ç”Ÿæˆå’Œæ‰§è¡Œ
    FINAL_RESULT_GENERATION = "final_result_generation"           # æœ€ç»ˆç»“æœç”Ÿæˆ

class PerformanceLevel(Enum):
    """æ€§èƒ½ç­‰çº§"""
    EXCELLENT = "excellent"
    GOOD = "good"
    AVERAGE = "average"
    POOR = "poor"
    CRITICAL = "critical"

@dataclass
class PerformanceMetrics:
    """æ€§èƒ½æŒ‡æ ‡æ•°æ®ç»“æ„"""
    execution_time: float = 0.0
    memory_usage: float = 0.0
    cpu_usage: float = 0.0
    success_rate: float = 100.0
    error_count: int = 0
    warning_count: int = 0
    stage_timings: Dict[str, float] = None
    
    def __post_init__(self):
        if self.stage_timings is None:
            self.stage_timings = {}
    
    def get_performance_level(self) -> PerformanceLevel:
        """è·å–æ€§èƒ½ç­‰çº§"""
        if self.execution_time < 1.0 and self.success_rate >= 95:
            return PerformanceLevel.EXCELLENT
        elif self.execution_time < 3.0 and self.success_rate >= 90:
            return PerformanceLevel.GOOD
        elif self.execution_time < 5.0 and self.success_rate >= 80:
            return PerformanceLevel.AVERAGE
        elif self.execution_time < 10.0 and self.success_rate >= 70:
            return PerformanceLevel.POOR
        else:
            return PerformanceLevel.CRITICAL

@dataclass
class UserRequest:
    """ç”¨æˆ·è¯·æ±‚æ•°æ®ç»“æ„"""
    id: str
    content: str
    context: Dict[str, Any]
    priority: str = "normal"
    metadata: Dict[str, Any] = None
    timestamp: float = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
        if self.timestamp is None:
            self.timestamp = time.time()

@dataclass
class ExpertResponse:
    """ä¸“å®¶å“åº”æ•°æ®ç»“æ„"""
    expert_id: str
    expert_name: str
    expert_type: str
    analysis: str
    recommendations: List[str]
    tool_suggestions: List[Dict[str, Any]]
    confidence: float
    processing_time: float = 0.0
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

@dataclass
class ProcessingResult:
    """å¤„ç†ç»“æœæ•°æ®ç»“æ„"""
    request_id: str
    success: bool
    stage_results: Dict[str, Any]
    expert_analysis: List[ExpertResponse]
    tool_execution_results: List[Dict[str, Any]]
    final_answer: str
    confidence: float
    execution_time: float
    metadata: Dict[str, Any]
    performance_metrics: PerformanceMetrics = None
    timestamp: float = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()
        if self.performance_metrics is None:
            self.performance_metrics = PerformanceMetrics()

class EnhancedErrorHandler:
    """å¢å¼ºç‰ˆé”™è¯¯å¤„ç†å™¨"""
    
    def __init__(self):
        self.error_history = []
        self.error_patterns = {}
        
    def handle_error(self, error: Exception, context: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†é”™è¯¯"""
        error_info = {
            'error_type': type(error).__name__,
            'error_message': str(error),
            'context': context,
            'timestamp': datetime.now().isoformat(),
            'traceback': traceback.format_exc()
        }
        
        self.error_history.append(error_info)
        
        # åˆ†æé”™è¯¯æ¨¡å¼
        error_pattern = self._analyze_error_pattern(error_info)
        
        # ç”Ÿæˆæ¢å¤å»ºè®®
        recovery_suggestions = self._generate_recovery_suggestions(error_pattern)
        
        return {
            'error_info': error_info,
            'error_pattern': error_pattern,
            'recovery_suggestions': recovery_suggestions,
            'should_retry': self._should_retry(error_pattern),
            'retry_delay': self._get_retry_delay(error_pattern)
        }
    
    def _analyze_error_pattern(self, error_info: Dict[str, Any]) -> Dict[str, Any]:
        """åˆ†æé”™è¯¯æ¨¡å¼"""
        error_type = error_info['error_type']
        
        if error_type not in self.error_patterns:
            self.error_patterns[error_type] = {
                'count': 0,
                'first_occurrence': error_info['timestamp'],
                'last_occurrence': error_info['timestamp'],
                'contexts': []
            }
        
        pattern = self.error_patterns[error_type]
        pattern['count'] += 1
        pattern['last_occurrence'] = error_info['timestamp']
        pattern['contexts'].append(error_info['context'])
        
        return {
            'error_type': error_type,
            'frequency': pattern['count'],
            'is_recurring': pattern['count'] > 1,
            'time_span': pattern['last_occurrence']
        }
    
    def _generate_recovery_suggestions(self, error_pattern: Dict[str, Any]) -> List[str]:
        """ç”Ÿæˆæ¢å¤å»ºè®®"""
        suggestions = []
        error_type = error_pattern['error_type']
        
        if error_type == 'ModuleNotFoundError':
            suggestions.extend([
                "æ£€æŸ¥æ¨¡å—å¯¼å…¥è·¯å¾„æ˜¯å¦æ­£ç¡®",
                "ç¡®è®¤æ‰€éœ€çš„ä¾èµ–åŒ…å·²å®‰è£…",
                "éªŒè¯Pythonè·¯å¾„é…ç½®"
            ])
        elif error_type == 'ConnectionError':
            suggestions.extend([
                "æ£€æŸ¥ç½‘ç»œè¿æ¥çŠ¶æ€",
                "éªŒè¯æœåŠ¡ç«¯ç‚¹å¯ç”¨æ€§",
                "è€ƒè™‘å¢åŠ é‡è¯•æœºåˆ¶"
            ])
        elif error_type == 'TimeoutError':
            suggestions.extend([
                "å¢åŠ è¶…æ—¶æ—¶é—´é™åˆ¶",
                "ä¼˜åŒ–å¤„ç†é€»è¾‘æ€§èƒ½",
                "è€ƒè™‘å¼‚æ­¥å¤„ç†æ–¹æ¡ˆ"
            ])
        else:
            suggestions.append("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯å’Œå †æ ˆè·Ÿè¸ª")
        
        return suggestions
    
    def _should_retry(self, error_pattern: Dict[str, Any]) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥é‡è¯•"""
        error_type = error_pattern['error_type']
        frequency = error_pattern['frequency']
        
        # ç½‘ç»œç›¸å…³é”™è¯¯å¯ä»¥é‡è¯•ï¼Œä½†ä¸è¶…è¿‡3æ¬¡
        if error_type in ['ConnectionError', 'TimeoutError'] and frequency <= 3:
            return True
        
        # å…¶ä»–é”™è¯¯ç±»å‹ä¸€èˆ¬ä¸é‡è¯•
        return False
    
    def _get_retry_delay(self, error_pattern: Dict[str, Any]) -> float:
        """è·å–é‡è¯•å»¶è¿Ÿæ—¶é—´"""
        frequency = error_pattern['frequency']
        # æŒ‡æ•°é€€é¿ç­–ç•¥
        return min(2 ** frequency, 30.0)

class IntegratedCloudSearch:
    """æ•´åˆå¼Cloud Searchå¼•æ“"""
    
    def __init__(self):
        self.mock_mode = True  # å¼€å‘é˜¶æ®µä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼
        self.performance_tracker = {}
    
    async def integrated_search(self, params: Dict) -> Dict:
        """æ‰§è¡Œæ•´åˆå¼æœç´¢"""
        start_time = time.time()
        
        try:
            # æ¨¡æ‹Ÿæœç´¢è¿‡ç¨‹
            await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿ
            
            search_results = {
                'query': params.get('query', ''),
                'results': [
                    {
                        'title': f"æœç´¢ç»“æœ {i+1}",
                        'content': f"è¿™æ˜¯å…³äº '{params.get('query', '')}' çš„æœç´¢ç»“æœå†…å®¹ {i+1}",
                        'relevance': 0.9 - i * 0.1,
                        'source': f"source_{i+1}.com"
                    }
                    for i in range(3)
                ],
                'total_results': 3,
                'search_time': time.time() - start_time
            }
            
            # è®°å½•æ€§èƒ½æŒ‡æ ‡
            self.performance_tracker['last_search_time'] = time.time() - start_time
            
            return search_results
            
        except Exception as e:
            logger.error(f"æœç´¢è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}")
            return {
                'query': params.get('query', ''),
                'results': [],
                'total_results': 0,
                'error': str(e),
                'search_time': time.time() - start_time
            }

class AICore31:
    """AICore 3.1 - å¢å¼ºç‰ˆåŠ¨æ€ä¸“å®¶ç³»ç»Ÿ"""
    
    def __init__(self, config: Optional[Dict] = None):
        self.config = config or {}
        self.version = "3.1"
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = self._setup_logging()
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.general_processor = create_general_processor_mcp()
        self.expert_registry = create_dynamic_expert_registry()
        self.recommendation_aggregator = create_expert_recommendation_aggregator()
        self.mcp_generator = create_dynamic_mcp_generator()
        self.tool_registry = ToolRegistry()
        self.action_executor = ActionExecutor()
        
        # å¢å¼ºç‰ˆç»„ä»¶
        self.cloud_search = IntegratedCloudSearch()
        self.error_handler = EnhancedErrorHandler()
        self.test_flow_mcp = TestFlowMCPv52() if TestFlowMCPv52 else None
        
        # æ€§èƒ½ç›‘æ§
        self.performance_history = []
        self.processing_stats = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'average_processing_time': 0.0
        }
        
        self.logger.info(f"AICore {self.version} åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logger = logging.getLogger(f"AICore_{self.version}")
        logger.setLevel(logging.INFO)
        
        if not logger.handlers:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            handler.setFormatter(formatter)
            logger.addHandler(handler)
        
        return logger
    
    async def process_request(self, request: UserRequest) -> ProcessingResult:
        """å¤„ç†ç”¨æˆ·è¯·æ±‚ - ä¸»è¦å…¥å£ç‚¹"""
        start_time = time.time()
        request_id = request.id
        
        self.logger.info(f"å¼€å§‹å¤„ç†è¯·æ±‚: {request_id}")
        
        # åˆå§‹åŒ–ç»“æœç»“æ„
        result = ProcessingResult(
            request_id=request_id,
            success=False,
            stage_results={},
            expert_analysis=[],
            tool_execution_results=[],
            final_answer="",
            confidence=0.0,
            execution_time=0.0,
            metadata={}
        )
        
        try:
            # é˜¶æ®µ1: æ•´åˆå¼æœç´¢å’Œåˆ†æ
            stage1_result = await self._stage1_integrated_search_analysis(request)
            result.stage_results[ProcessingStage.INTEGRATED_SEARCH_ANALYSIS.value] = stage1_result
            
            # é˜¶æ®µ2: åŠ¨æ€ä¸“å®¶ç”Ÿæˆ
            stage2_result = await self._stage2_dynamic_expert_generation(request, stage1_result)
            result.stage_results[ProcessingStage.DYNAMIC_EXPERT_GENERATION.value] = stage2_result
            
            # é˜¶æ®µ3: ä¸“å®¶å›ç­”ç”Ÿæˆ
            stage3_result = await self._stage3_expert_response_generation(request, stage2_result)
            result.stage_results[ProcessingStage.EXPERT_RESPONSE_GENERATION.value] = stage3_result
            result.expert_analysis = stage3_result.get('expert_responses', [])
            
            # é˜¶æ®µ4: ä¸“å®¶å»ºè®®èšåˆ
            stage4_result = await self._stage4_expert_recommendation_aggregation(stage3_result)
            result.stage_results[ProcessingStage.EXPERT_RECOMMENDATION_AGGREGATION.value] = stage4_result
            
            # é˜¶æ®µ5: åŠ¨æ€å·¥å…·ç”Ÿæˆå’Œæ‰§è¡Œ
            stage5_result = await self._stage5_dynamic_tool_generation(stage4_result)
            result.stage_results[ProcessingStage.DYNAMIC_TOOL_GENERATION.value] = stage5_result
            result.tool_execution_results = stage5_result.get('tool_results', [])
            
            # é˜¶æ®µ6: æœ€ç»ˆç»“æœç”Ÿæˆ
            stage6_result = await self._stage6_final_result_generation(result.stage_results)
            result.stage_results[ProcessingStage.FINAL_RESULT_GENERATION.value] = stage6_result
            
            # è®¾ç½®æœ€ç»ˆç»“æœ
            result.final_answer = stage6_result.get('final_answer', '')
            result.confidence = stage6_result.get('confidence', 0.0)
            result.success = True
            
        except Exception as e:
            self.logger.error(f"å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
            
            # ä½¿ç”¨å¢å¼ºç‰ˆé”™è¯¯å¤„ç†
            error_analysis = self.error_handler.handle_error(e, {
                'request_id': request_id,
                'stage': 'processing',
                'request_content': request.content
            })
            
            result.metadata['error_analysis'] = error_analysis
            result.final_answer = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            result.success = False
        
        # è®¡ç®—æ‰§è¡Œæ—¶é—´å’Œæ€§èƒ½æŒ‡æ ‡
        execution_time = time.time() - start_time
        result.execution_time = execution_time
        
        # æ›´æ–°æ€§èƒ½æŒ‡æ ‡
        performance_metrics = PerformanceMetrics(
            execution_time=execution_time,
            success_rate=100.0 if result.success else 0.0,
            error_count=0 if result.success else 1
        )
        result.performance_metrics = performance_metrics
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self._update_processing_stats(result)
        
        self.logger.info(f"è¯·æ±‚å¤„ç†å®Œæˆ: {request_id}, æˆåŠŸ: {result.success}, è€—æ—¶: {execution_time:.2f}s")
        
        return result
    
    async def _stage1_integrated_search_analysis(self, request: UserRequest) -> Dict[str, Any]:
        """é˜¶æ®µ1: æ•´åˆå¼æœç´¢å’Œåˆ†æ"""
        start_time = time.time()
        
        try:
            # æ‰§è¡Œæœç´¢
            search_params = {
                'query': request.content,
                'context': request.context,
                'priority': request.priority
            }
            
            search_results = await self.cloud_search.integrated_search(search_params)
            
            # åˆ†ææœç´¢ç»“æœ
            analysis = {
                'search_quality': self._evaluate_search_quality(search_results),
                'key_topics': self._extract_key_topics(search_results),
                'complexity_level': self._assess_complexity(request.content),
                'recommended_experts': self._suggest_expert_types(search_results)
            }
            
            return {
                'search_results': search_results,
                'analysis': analysis,
                'processing_time': time.time() - start_time,
                'success': True
            }
            
        except Exception as e:
            self.logger.error(f"é˜¶æ®µ1å¤„ç†é”™è¯¯: {str(e)}")
            return {
                'search_results': {},
                'analysis': {},
                'processing_time': time.time() - start_time,
                'success': False,
                'error': str(e)
            }
    
    async def _stage2_dynamic_expert_generation(self, request: UserRequest, stage1_result: Dict) -> Dict[str, Any]:
        """é˜¶æ®µ2: åŠ¨æ€ä¸“å®¶ç”Ÿæˆ"""
        start_time = time.time()
        
        try:
            analysis = stage1_result.get('analysis', {})
            recommended_experts = analysis.get('recommended_experts', ['general'])
            
            generated_experts = []
            for expert_type in recommended_experts:
                expert_profile = await self._generate_expert_profile(expert_type, request, stage1_result)
                generated_experts.append(expert_profile)
            
            return {
                'generated_experts': generated_experts,
                'expert_count': len(generated_experts),
                'processing_time': time.time() - start_time,
                'success': True
            }
            
        except Exception as e:
            self.logger.error(f"é˜¶æ®µ2å¤„ç†é”™è¯¯: {str(e)}")
            return {
                'generated_experts': [],
                'expert_count': 0,
                'processing_time': time.time() - start_time,
                'success': False,
                'error': str(e)
            }
    
    async def _stage3_expert_response_generation(self, request: UserRequest, stage2_result: Dict) -> Dict[str, Any]:
        """é˜¶æ®µ3: ä¸“å®¶å›ç­”ç”Ÿæˆ"""
        start_time = time.time()
        
        try:
            experts = stage2_result.get('generated_experts', [])
            expert_responses = []
            
            for expert in experts:
                response = await self._generate_expert_response(expert, request)
                expert_responses.append(response)
            
            return {
                'expert_responses': expert_responses,
                'response_count': len(expert_responses),
                'processing_time': time.time() - start_time,
                'success': True
            }
            
        except Exception as e:
            self.logger.error(f"é˜¶æ®µ3å¤„ç†é”™è¯¯: {str(e)}")
            return {
                'expert_responses': [],
                'response_count': 0,
                'processing_time': time.time() - start_time,
                'success': False,
                'error': str(e)
            }
    
    async def _stage4_expert_recommendation_aggregation(self, stage3_result: Dict) -> Dict[str, Any]:
        """é˜¶æ®µ4: ä¸“å®¶å»ºè®®èšåˆ"""
        start_time = time.time()
        
        try:
            expert_responses = stage3_result.get('expert_responses', [])
            
            # èšåˆä¸“å®¶å»ºè®®
            aggregated_recommendations = []
            confidence_scores = []
            
            for response in expert_responses:
                aggregated_recommendations.extend(response.recommendations)
                confidence_scores.append(response.confidence)
            
            # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
            overall_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0.0
            
            # å»é‡å’Œæ’åºå»ºè®®
            unique_recommendations = list(set(aggregated_recommendations))
            
            return {
                'aggregated_recommendations': unique_recommendations,
                'overall_confidence': overall_confidence,
                'expert_count': len(expert_responses),
                'processing_time': time.time() - start_time,
                'success': True
            }
            
        except Exception as e:
            self.logger.error(f"é˜¶æ®µ4å¤„ç†é”™è¯¯: {str(e)}")
            return {
                'aggregated_recommendations': [],
                'overall_confidence': 0.0,
                'expert_count': 0,
                'processing_time': time.time() - start_time,
                'success': False,
                'error': str(e)
            }
    
    async def _stage5_dynamic_tool_generation(self, stage4_result: Dict) -> Dict[str, Any]:
        """é˜¶æ®µ5: åŠ¨æ€å·¥å…·ç”Ÿæˆå’Œæ‰§è¡Œ"""
        start_time = time.time()
        
        try:
            recommendations = stage4_result.get('aggregated_recommendations', [])
            
            # åŸºäºå»ºè®®ç”Ÿæˆå·¥å…·
            tool_results = []
            for i, recommendation in enumerate(recommendations[:3]):  # é™åˆ¶å·¥å…·æ•°é‡
                tool_result = await self._execute_recommendation_tool(recommendation, i)
                tool_results.append(tool_result)
            
            return {
                'tool_results': tool_results,
                'tool_count': len(tool_results),
                'processing_time': time.time() - start_time,
                'success': True
            }
            
        except Exception as e:
            self.logger.error(f"é˜¶æ®µ5å¤„ç†é”™è¯¯: {str(e)}")
            return {
                'tool_results': [],
                'tool_count': 0,
                'processing_time': time.time() - start_time,
                'success': False,
                'error': str(e)
            }
    
    async def _stage6_final_result_generation(self, stage_results: Dict) -> Dict[str, Any]:
        """é˜¶æ®µ6: æœ€ç»ˆç»“æœç”Ÿæˆ"""
        start_time = time.time()
        
        try:
            # æ•´åˆæ‰€æœ‰é˜¶æ®µçš„ç»“æœ
            search_analysis = stage_results.get(ProcessingStage.INTEGRATED_SEARCH_ANALYSIS.value, {})
            expert_responses = stage_results.get(ProcessingStage.EXPERT_RESPONSE_GENERATION.value, {})
            aggregated_recommendations = stage_results.get(ProcessingStage.EXPERT_RECOMMENDATION_AGGREGATION.value, {})
            tool_results = stage_results.get(ProcessingStage.DYNAMIC_TOOL_GENERATION.value, {})
            
            # ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            final_answer = self._synthesize_final_answer(
                search_analysis, expert_responses, aggregated_recommendations, tool_results
            )
            
            # è®¡ç®—æ•´ä½“ç½®ä¿¡åº¦
            confidence = aggregated_recommendations.get('overall_confidence', 0.0)
            
            return {
                'final_answer': final_answer,
                'confidence': confidence,
                'processing_time': time.time() - start_time,
                'success': True
            }
            
        except Exception as e:
            self.logger.error(f"é˜¶æ®µ6å¤„ç†é”™è¯¯: {str(e)}")
            return {
                'final_answer': f"ç”Ÿæˆæœ€ç»ˆç»“æœæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}",
                'confidence': 0.0,
                'processing_time': time.time() - start_time,
                'success': False,
                'error': str(e)
            }
    
    def _evaluate_search_quality(self, search_results: Dict) -> float:
        """è¯„ä¼°æœç´¢è´¨é‡"""
        results = search_results.get('results', [])
        if not results:
            return 0.0
        
        # åŸºäºç»“æœæ•°é‡å’Œç›¸å…³æ€§è¯„åˆ†
        relevance_scores = [r.get('relevance', 0.0) for r in results]
        avg_relevance = sum(relevance_scores) / len(relevance_scores)
        
        # ç»“æœæ•°é‡å› å­
        count_factor = min(len(results) / 5.0, 1.0)
        
        return avg_relevance * count_factor
    
    def _extract_key_topics(self, search_results: Dict) -> List[str]:
        """æå–å…³é”®ä¸»é¢˜"""
        # ç®€åŒ–å®ç°ï¼Œå®é™…åº”è¯¥ä½¿ç”¨NLPæŠ€æœ¯
        query = search_results.get('query', '')
        topics = []
        
        # åŸºäºæŸ¥è¯¢å†…å®¹æå–å…³é”®è¯
        keywords = query.lower().split()
        for keyword in keywords:
            if len(keyword) > 2:  # è¿‡æ»¤çŸ­è¯
                topics.append(keyword)
        
        return topics[:5]  # è¿”å›å‰5ä¸ªä¸»é¢˜
    
    def _assess_complexity(self, content: str) -> str:
        """è¯„ä¼°å¤æ‚åº¦"""
        word_count = len(content.split())
        
        if word_count < 10:
            return "simple"
        elif word_count < 50:
            return "medium"
        else:
            return "complex"
    
    def _suggest_expert_types(self, search_results: Dict) -> List[str]:
        """å»ºè®®ä¸“å®¶ç±»å‹"""
        query = search_results.get('query', '').lower()
        expert_types = []
        
        # åŸºäºå…³é”®è¯åŒ¹é…ä¸“å®¶ç±»å‹
        if any(keyword in query for keyword in ['code', 'programming', 'development']):
            expert_types.append('code_expert')
        if any(keyword in query for keyword in ['design', 'ui', 'ux']):
            expert_types.append('design_expert')
        if any(keyword in query for keyword in ['data', 'analysis', 'statistics']):
            expert_types.append('data_expert')
        
        # é»˜è®¤æ·»åŠ é€šç”¨ä¸“å®¶
        if not expert_types:
            expert_types.append('general_expert')
        
        return expert_types
    
    async def _generate_expert_profile(self, expert_type: str, request: UserRequest, stage1_result: Dict) -> Dict[str, Any]:
        """ç”Ÿæˆä¸“å®¶æ¡£æ¡ˆ"""
        expert_id = hashlib.md5(f"{expert_type}_{request.id}".encode()).hexdigest()[:8]
        
        return {
            'expert_id': expert_id,
            'expert_type': expert_type,
            'expert_name': f"{expert_type.replace('_', ' ').title()} Expert",
            'specialization': self._get_expert_specialization(expert_type),
            'confidence_level': 0.8,
            'created_at': datetime.now().isoformat()
        }
    
    def _get_expert_specialization(self, expert_type: str) -> List[str]:
        """è·å–ä¸“å®¶ä¸“ä¸šé¢†åŸŸ"""
        specializations = {
            'code_expert': ['è½¯ä»¶å¼€å‘', 'ä»£ç å®¡æŸ¥', 'æ¶æ„è®¾è®¡', 'æ€§èƒ½ä¼˜åŒ–'],
            'design_expert': ['ç”¨æˆ·ç•Œé¢è®¾è®¡', 'ç”¨æˆ·ä½“éªŒ', 'è§†è§‰è®¾è®¡', 'äº¤äº’è®¾è®¡'],
            'data_expert': ['æ•°æ®åˆ†æ', 'ç»Ÿè®¡å»ºæ¨¡', 'æœºå™¨å­¦ä¹ ', 'æ•°æ®å¯è§†åŒ–'],
            'general_expert': ['é—®é¢˜åˆ†æ', 'è§£å†³æ–¹æ¡ˆè®¾è®¡', 'é¡¹ç›®ç®¡ç†', 'å’¨è¯¢å»ºè®®']
        }
        
        return specializations.get(expert_type, ['é€šç”¨å’¨è¯¢'])
    
    async def _generate_expert_response(self, expert: Dict, request: UserRequest) -> ExpertResponse:
        """ç”Ÿæˆä¸“å®¶å›åº”"""
        expert_type = expert['expert_type']
        
        # æ¨¡æ‹Ÿä¸“å®¶åˆ†æè¿‡ç¨‹
        await asyncio.sleep(0.1)  # æ¨¡æ‹Ÿæ€è€ƒæ—¶é—´
        
        analysis = f"ä½œä¸º{expert['expert_name']}ï¼Œæˆ‘åˆ†æäº†æ‚¨çš„è¯·æ±‚ï¼š{request.content[:100]}..."
        
        recommendations = [
            f"å»ºè®®1ï¼šåŸºäº{expert_type}çš„è§’åº¦ï¼Œå»ºè®®é‡‡ç”¨æœ€ä½³å®è·µæ–¹æ³•",
            f"å»ºè®®2ï¼šè€ƒè™‘{expert['specialization'][0]}çš„ç›¸å…³å› ç´ ",
            f"å»ºè®®3ï¼šå»ºè®®è¿›ä¸€æ­¥æ·±å…¥{expert['specialization'][1] if len(expert['specialization']) > 1 else 'ç›¸å…³é¢†åŸŸ'}çš„ç ”ç©¶"
        ]
        
        tool_suggestions = [
            {
                'tool_name': f"{expert_type}_analyzer",
                'tool_description': f"ç”¨äº{expert_type}åˆ†æçš„ä¸“ç”¨å·¥å…·",
                'parameters': {'input': request.content}
            }
        ]
        
        return ExpertResponse(
            expert_id=expert['expert_id'],
            expert_name=expert['expert_name'],
            expert_type=expert_type,
            analysis=analysis,
            recommendations=recommendations,
            tool_suggestions=tool_suggestions,
            confidence=0.85,
            processing_time=0.1
        )
    
    async def _execute_recommendation_tool(self, recommendation: str, tool_index: int) -> Dict[str, Any]:
        """æ‰§è¡Œå»ºè®®å·¥å…·"""
        # æ¨¡æ‹Ÿå·¥å…·æ‰§è¡Œ
        await asyncio.sleep(0.05)
        
        return {
            'tool_id': f"tool_{tool_index}",
            'tool_name': f"recommendation_processor_{tool_index}",
            'input': recommendation,
            'output': f"å·²å¤„ç†å»ºè®®ï¼š{recommendation[:50]}...",
            'success': True,
            'execution_time': 0.05
        }
    
    def _synthesize_final_answer(self, search_analysis: Dict, expert_responses: Dict, 
                                aggregated_recommendations: Dict, tool_results: Dict) -> str:
        """ç»¼åˆç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ"""
        
        # è·å–å„é˜¶æ®µçš„å…³é”®ä¿¡æ¯
        search_quality = search_analysis.get('analysis', {}).get('search_quality', 0.0)
        expert_count = expert_responses.get('response_count', 0)
        recommendations = aggregated_recommendations.get('aggregated_recommendations', [])
        tool_count = tool_results.get('tool_count', 0)
        
        # æ„å»ºæœ€ç»ˆç­”æ¡ˆ
        answer_parts = []
        
        answer_parts.append("åŸºäºAICore 3.1çš„ç»¼åˆåˆ†æï¼Œæˆ‘ä¸ºæ‚¨æä¾›ä»¥ä¸‹è§£ç­”ï¼š")
        
        if search_quality > 0.7:
            answer_parts.append(f"âœ… é€šè¿‡é«˜è´¨é‡æœç´¢åˆ†æï¼ˆè´¨é‡è¯„åˆ†ï¼š{search_quality:.2f}ï¼‰ï¼Œæˆ‘ä»¬è·å¾—äº†ç›¸å…³ä¿¡æ¯ã€‚")
        
        if expert_count > 0:
            answer_parts.append(f"ğŸ§  {expert_count}ä½ä¸“ä¸šä¸“å®¶å‚ä¸äº†åˆ†æï¼Œæä¾›äº†å¤šè§’åº¦çš„è§è§£ã€‚")
        
        if recommendations:
            answer_parts.append("ğŸ“‹ ä¸»è¦å»ºè®®åŒ…æ‹¬ï¼š")
            for i, rec in enumerate(recommendations[:3], 1):
                answer_parts.append(f"   {i}. {rec}")
        
        if tool_count > 0:
            answer_parts.append(f"ğŸ”§ æ‰§è¡Œäº†{tool_count}ä¸ªä¸“ä¸šå·¥å…·è¿›è¡Œæ·±åº¦åˆ†æã€‚")
        
        answer_parts.append("ğŸ’¡ è¿™ä¸ªè§£ç­”ç»“åˆäº†æœç´¢åˆ†æã€ä¸“å®¶çŸ¥è¯†å’Œå·¥å…·æ‰§è¡Œçš„ç»“æœï¼Œä¸ºæ‚¨æä¾›å…¨é¢çš„è§£å†³æ–¹æ¡ˆã€‚")
        
        return "\n".join(answer_parts)
    
    def _update_processing_stats(self, result: ProcessingResult):
        """æ›´æ–°å¤„ç†ç»Ÿè®¡ä¿¡æ¯"""
        self.processing_stats['total_requests'] += 1
        
        if result.success:
            self.processing_stats['successful_requests'] += 1
        else:
            self.processing_stats['failed_requests'] += 1
        
        # æ›´æ–°å¹³å‡å¤„ç†æ—¶é—´
        total_time = (self.processing_stats['average_processing_time'] * 
                     (self.processing_stats['total_requests'] - 1) + result.execution_time)
        self.processing_stats['average_processing_time'] = total_time / self.processing_stats['total_requests']
        
        # è®°å½•æ€§èƒ½å†å²
        self.performance_history.append({
            'timestamp': result.timestamp,
            'execution_time': result.execution_time,
            'success': result.success,
            'performance_level': result.performance_metrics.get_performance_level().value
        })
        
        # ä¿æŒå†å²è®°å½•åœ¨åˆç†èŒƒå›´å†…
        if len(self.performance_history) > 1000:
            self.performance_history = self.performance_history[-1000:]
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        return {
            'version': self.version,
            'processing_stats': self.processing_stats.copy(),
            'performance_history_count': len(self.performance_history),
            'error_patterns': len(self.error_handler.error_patterns),
            'components_status': {
                'general_processor': bool(self.general_processor),
                'expert_registry': bool(self.expert_registry),
                'recommendation_aggregator': bool(self.recommendation_aggregator),
                'mcp_generator': bool(self.mcp_generator),
                'test_flow_mcp': bool(self.test_flow_mcp),
                'cloud_search': bool(self.cloud_search),
                'error_handler': bool(self.error_handler)
            },
            'timestamp': datetime.now().isoformat()
        }

# å·¥å‚å‡½æ•°
def create_aicore31(config: Optional[Dict] = None) -> AICore31:
    """åˆ›å»ºAICore 3.1å®ä¾‹"""
    return AICore31(config)

# å‘åå…¼å®¹æ€§
AICore3 = AICore31
create_aicore3 = create_aicore31

# ä¸»å‡½æ•°ç”¨äºæµ‹è¯•
async def main():
    """ä¸»å‡½æ•°"""
    print("AICore 3.1 - Enhanced Dynamic Expert System")
    print("=" * 50)
    
    # åˆ›å»ºAICoreå®ä¾‹
    aicore = create_aicore31()
    
    # åˆ›å»ºæµ‹è¯•è¯·æ±‚
    test_request = UserRequest(
        id="test_001",
        content="å¦‚ä½•è®¾è®¡ä¸€ä¸ªé«˜æ€§èƒ½çš„Webåº”ç”¨ç¨‹åºï¼Ÿ",
        context={
            'domain': 'web_development',
            'complexity': 'high',
            'requirements': ['performance', 'scalability', 'security']
        }
    )
    
    print(f"å¤„ç†æµ‹è¯•è¯·æ±‚: {test_request.content}")
    print("-" * 50)
    
    # å¤„ç†è¯·æ±‚
    result = await aicore.process_request(test_request)
    
    # æ˜¾ç¤ºç»“æœ
    print(f"å¤„ç†ç»“æœ:")
    print(f"  æˆåŠŸ: {result.success}")
    print(f"  æ‰§è¡Œæ—¶é—´: {result.execution_time:.2f}ç§’")
    print(f"  ç½®ä¿¡åº¦: {result.confidence:.2f}")
    print(f"  æ€§èƒ½ç­‰çº§: {result.performance_metrics.get_performance_level().value}")
    print(f"  ä¸“å®¶åˆ†ææ•°é‡: {len(result.expert_analysis)}")
    print(f"  å·¥å…·æ‰§è¡Œæ•°é‡: {len(result.tool_execution_results)}")
    
    print(f"\næœ€ç»ˆç­”æ¡ˆ:")
    print(result.final_answer)
    
    # æ˜¾ç¤ºç³»ç»ŸçŠ¶æ€
    print(f"\nç³»ç»ŸçŠ¶æ€:")
    status = aicore.get_system_status()
    for key, value in status.items():
        if key != 'components_status':
            print(f"  {key}: {value}")
    
    print(f"\nç»„ä»¶çŠ¶æ€:")
    for component, status in status['components_status'].items():
        status_icon = "âœ…" if status else "âŒ"
        print(f"  {status_icon} {component}")

if __name__ == "__main__":
    asyncio.run(main())

