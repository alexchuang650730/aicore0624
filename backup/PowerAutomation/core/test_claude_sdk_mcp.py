#!/usr/bin/env python3
"""
ClaudeSDKMCP æµ‹è¯•æ–‡ä»¶
æµ‹è¯•å„é¡¹åŠŸèƒ½å’Œæ€§èƒ½
"""

import asyncio
import json
import time
import sys
from pathlib import Path
from typing import Dict, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from claude_sdk_mcp_v2 import ClaudeSDKMCP, ExpertProfile, ExpertType, ExpertStatus, ExpertCapability, OperationType
from config import Config

class ClaudeSDKMCPTester:
    """ClaudeSDKMCP æµ‹è¯•ç±»"""
    
    def __init__(self):
        self.config = Config()
        self.claude_sdk = None
        self.test_results = []
    
    async def setup(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        print("ğŸ”§ è®¾ç½®æµ‹è¯•ç¯å¢ƒ...")
        self.claude_sdk = ClaudeSDKMCP(api_key=self.config.claude_api.api_key)
        print("âœ… ClaudeSDKMCP åˆå§‹åŒ–å®Œæˆ")
    
    async def test_basic_functionality(self):
        """æµ‹è¯•åŸºæœ¬åŠŸèƒ½"""
        print("\nğŸ“‹ æµ‹è¯•åŸºæœ¬åŠŸèƒ½...")
        
        test_cases = [
            {
                "name": "ç®€å•ä»£ç åˆ†æ",
                "input": "è¯·åˆ†æè¿™æ®µPythonä»£ç çš„é—®é¢˜",
                "context": {
                    "code": "def hello():\n    print('Hello World')",
                    "language": "python"
                }
            },
            {
                "name": "æ€§èƒ½ä¼˜åŒ–å’¨è¯¢",
                "input": "å¦‚ä½•ä¼˜åŒ–è¿™ä¸ªç®—æ³•çš„æ€§èƒ½ï¼Ÿ",
                "context": {
                    "code": "for i in range(1000000):\n    result = i * i",
                    "language": "python"
                }
            },
            {
                "name": "å®‰å…¨å®¡è®¡è¯·æ±‚",
                "input": "è¯·æ£€æŸ¥è¿™æ®µä»£ç çš„å®‰å…¨é—®é¢˜",
                "context": {
                    "code": "query = f\"SELECT * FROM users WHERE id = {user_id}\"",
                    "language": "python"
                }
            }
        ]
        
        for test_case in test_cases:
            print(f"  ğŸ§ª æµ‹è¯•: {test_case['name']}")
            start_time = time.time()
            
            try:
                result = await self.claude_sdk.process_request(
                    test_case["input"],
                    test_case["context"]
                )
                
                processing_time = time.time() - start_time
                
                test_result = {
                    "test_name": test_case["name"],
                    "success": result.success,
                    "processing_time": processing_time,
                    "confidence_score": result.confidence_score,
                    "operations_executed": len(result.operations_executed),
                    "expert_used": result.expert_used
                }
                
                self.test_results.append(test_result)
                
                if result.success:
                    print(f"    âœ… æˆåŠŸ - å¤„ç†æ—¶é—´: {processing_time:.2f}s, ä¿¡å¿ƒåº¦: {result.confidence_score:.2f}")
                    print(f"    ğŸ“Š æ‰§è¡Œæ“ä½œ: {len(result.operations_executed)}, ä½¿ç”¨ä¸“å®¶: {result.expert_used}")
                else:
                    print(f"    âŒ å¤±è´¥ - {result.error_message}")
                
            except Exception as e:
                print(f"    âŒ å¼‚å¸¸ - {e}")
                self.test_results.append({
                    "test_name": test_case["name"],
                    "success": False,
                    "error": str(e)
                })
    
    async def test_expert_system(self):
        """æµ‹è¯•ä¸“å®¶ç³»ç»Ÿ"""
        print("\nğŸ‘¨â€ğŸ’¼ æµ‹è¯•ä¸“å®¶ç³»ç»Ÿ...")
        
        # æµ‹è¯•ä¸“å®¶åˆ—è¡¨
        experts = self.claude_sdk.expert_registry.experts
        print(f"  ğŸ“Š å·²æ³¨å†Œä¸“å®¶æ•°é‡: {len(experts)}")
        
        for expert_id, expert in experts.items():
            print(f"    - {expert.name} ({expert_id}): {expert.status.value}")
        
        # æµ‹è¯•åŠ¨æ€ä¸“å®¶æ³¨å†Œ
        print("  ğŸ”„ æµ‹è¯•åŠ¨æ€ä¸“å®¶æ³¨å†Œ...")
        
        dynamic_expert = ExpertProfile(
            id="test_expert_001",
            name="æµ‹è¯•ä¸“å®¶",
            type=ExpertType.DYNAMIC_EXPERT,
            status=ExpertStatus.ACTIVE,
            specialties=["æµ‹è¯•", "éªŒè¯"],
            capabilities=[
                ExpertCapability(
                    name="æµ‹è¯•èƒ½åŠ›",
                    description="ä¸“é—¨ç”¨äºæµ‹è¯•çš„èƒ½åŠ›",
                    skill_level="expert",
                    domain="testing",
                    keywords=["æµ‹è¯•", "éªŒè¯", "è´¨é‡"],
                    confidence=0.9,
                    source="manual"
                )
            ],
            context_limit="200K tokens",
            supported_operations=[OperationType.SYNTAX_ANALYSIS],
            confidence_threshold=0.8
        )
        
        success = self.claude_sdk.add_dynamic_expert(dynamic_expert)
        if success:
            print("    âœ… åŠ¨æ€ä¸“å®¶æ³¨å†ŒæˆåŠŸ")
        else:
            print("    âŒ åŠ¨æ€ä¸“å®¶æ³¨å†Œå¤±è´¥")
    
    async def test_operation_handlers(self):
        """æµ‹è¯•æ“ä½œå¤„ç†å™¨"""
        print("\nâš™ï¸ æµ‹è¯•æ“ä½œå¤„ç†å™¨...")
        
        operation_count = len(self.claude_sdk.operation_handlers)
        print(f"  ğŸ“Š å·²æ³¨å†Œæ“ä½œå¤„ç†å™¨æ•°é‡: {operation_count}")
        
        # æµ‹è¯•å‡ ä¸ªå…³é”®æ“ä½œå¤„ç†å™¨
        test_operations = [
            OperationType.SYNTAX_ANALYSIS,
            OperationType.PERFORMANCE_PROFILING,
            OperationType.SECURITY_AUDIT,
            OperationType.API_DESIGN_REVIEW,
            OperationType.DATABASE_DESIGN_REVIEW
        ]
        
        from claude_sdk_mcp_v2 import ProcessingRequest
        from datetime import datetime
        
        test_request = ProcessingRequest(
            request_id="test_001",
            user_input="æµ‹è¯•è¯·æ±‚",
            context={"test": True},
            timestamp=datetime.now()
        )
        
        for operation in test_operations:
            if operation in self.claude_sdk.operation_handlers:
                try:
                    handler = self.claude_sdk.operation_handlers[operation]
                    result = await handler(test_request)
                    print(f"    âœ… {operation.value}: {result.get('status', 'unknown')}")
                except Exception as e:
                    print(f"    âŒ {operation.value}: {e}")
            else:
                print(f"    âš ï¸ {operation.value}: å¤„ç†å™¨æœªæ‰¾åˆ°")
    
    async def test_performance(self):
        """æµ‹è¯•æ€§èƒ½"""
        print("\nğŸš€ æµ‹è¯•æ€§èƒ½...")
        
        # å¹¶å‘æµ‹è¯•
        concurrent_requests = 3
        print(f"  ğŸ”„ å¹¶å‘æµ‹è¯• ({concurrent_requests} ä¸ªè¯·æ±‚)...")
        
        async def single_request(request_id: int):
            start_time = time.time()
            result = await self.claude_sdk.process_request(
                f"æµ‹è¯•è¯·æ±‚ {request_id}",
                {"test_id": request_id}
            )
            processing_time = time.time() - start_time
            return {
                "request_id": request_id,
                "success": result.success,
                "processing_time": processing_time
            }
        
        start_time = time.time()
        tasks = [single_request(i) for i in range(concurrent_requests)]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        total_time = time.time() - start_time
        
        successful_requests = sum(1 for r in results if isinstance(r, dict) and r.get("success", False))
        avg_processing_time = sum(r.get("processing_time", 0) for r in results if isinstance(r, dict)) / len(results)
        
        print(f"    ğŸ“Š æ€»æ—¶é—´: {total_time:.2f}s")
        print(f"    ğŸ“Š æˆåŠŸè¯·æ±‚: {successful_requests}/{concurrent_requests}")
        print(f"    ğŸ“Š å¹³å‡å¤„ç†æ—¶é—´: {avg_processing_time:.2f}s")
        
        # å†…å­˜ä½¿ç”¨æµ‹è¯•
        import psutil
        import os
        
        process = psutil.Process(os.getpid())
        memory_info = process.memory_info()
        print(f"    ğŸ’¾ å†…å­˜ä½¿ç”¨: {memory_info.rss / 1024 / 1024:.2f} MB")
    
    async def test_error_handling(self):
        """æµ‹è¯•é”™è¯¯å¤„ç†"""
        print("\nğŸ›¡ï¸ æµ‹è¯•é”™è¯¯å¤„ç†...")
        
        error_test_cases = [
            {
                "name": "ç©ºè¾“å…¥",
                "input": "",
                "context": {}
            },
            {
                "name": "æ— æ•ˆä¸Šä¸‹æ–‡",
                "input": "æµ‹è¯•",
                "context": None
            },
            {
                "name": "è¶…å¤§è¾“å…¥",
                "input": "x" * 10000,
                "context": {}
            }
        ]
        
        for test_case in error_test_cases:
            print(f"  ğŸ§ª æµ‹è¯•: {test_case['name']}")
            try:
                result = await self.claude_sdk.process_request(
                    test_case["input"],
                    test_case["context"]
                )
                
                if result.success:
                    print(f"    âœ… å¤„ç†æˆåŠŸ")
                else:
                    print(f"    âš ï¸ å¤„ç†å¤±è´¥ä½†é”™è¯¯å¤„ç†æ­£å¸¸: {result.error_message}")
                
            except Exception as e:
                print(f"    âŒ æœªæ•è·å¼‚å¸¸: {e}")
    
    async def test_statistics_and_monitoring(self):
        """æµ‹è¯•ç»Ÿè®¡å’Œç›‘æ§"""
        print("\nğŸ“ˆ æµ‹è¯•ç»Ÿè®¡å’Œç›‘æ§...")
        
        stats = self.claude_sdk.get_statistics()
        
        print(f"  ğŸ“Š ç‰ˆæœ¬: {stats['version']}")
        print(f"  ğŸ“Š æ€»è¯·æ±‚æ•°: {stats['total_requests']}")
        print(f"  ğŸ“Š ä¸“å®¶æ•°é‡: {stats['total_experts']}")
        print(f"  ğŸ“Š æ“ä½œå¤„ç†å™¨æ•°é‡: {stats['operation_handlers']}")
        
        print("  ğŸ‘¨â€ğŸ’¼ ä¸“å®¶ç»Ÿè®¡:")
        for expert_id, expert_stats in stats.get('expert_statistics', {}).items():
            print(f"    - {expert_stats['name']}: {expert_stats['total_requests']} è¯·æ±‚, "
                  f"æˆåŠŸç‡ {expert_stats['success_rate']:.2%}")
    
    def generate_test_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...")
        
        total_tests = len(self.test_results)
        successful_tests = sum(1 for r in self.test_results if r.get("success", False))
        
        report = {
            "test_summary": {
                "total_tests": total_tests,
                "successful_tests": successful_tests,
                "success_rate": successful_tests / total_tests if total_tests > 0 else 0,
                "timestamp": time.strftime("%Y-%m-%d %H:%M:%S")
            },
            "test_results": self.test_results,
            "system_info": {
                "version": "2.0.0",
                "features_tested": [
                    "åŸºæœ¬åŠŸèƒ½",
                    "ä¸“å®¶ç³»ç»Ÿ",
                    "æ“ä½œå¤„ç†å™¨",
                    "æ€§èƒ½æµ‹è¯•",
                    "é”™è¯¯å¤„ç†",
                    "ç»Ÿè®¡ç›‘æ§"
                ]
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = Path(__file__).parent / "test_report.json"
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"  ğŸ“„ æµ‹è¯•æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        print(f"  ğŸ“Š æµ‹è¯•æˆåŠŸç‡: {report['test_summary']['success_rate']:.2%}")
        
        return report
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.claude_sdk:
            await self.claude_sdk.close()

async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª ClaudeSDKMCP v2.0.0 æµ‹è¯•å¼€å§‹")
    print("=" * 50)
    
    tester = ClaudeSDKMCPTester()
    
    try:
        # è®¾ç½®æµ‹è¯•ç¯å¢ƒ
        await tester.setup()
        
        # è¿è¡Œå„é¡¹æµ‹è¯•
        await tester.test_basic_functionality()
        await tester.test_expert_system()
        await tester.test_operation_handlers()
        await tester.test_performance()
        await tester.test_error_handling()
        await tester.test_statistics_and_monitoring()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        report = tester.generate_test_report()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æµ‹è¯•å®Œæˆ!")
        
        if report["test_summary"]["success_rate"] >= 0.8:
            print("âœ… ç³»ç»Ÿè¿è¡Œè‰¯å¥½")
        else:
            print("âš ï¸ ç³»ç»Ÿå­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥æµ‹è¯•æŠ¥å‘Š")
    
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        await tester.cleanup()

if __name__ == "__main__":
    asyncio.run(main())

