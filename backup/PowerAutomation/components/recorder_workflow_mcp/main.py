"""
Recorder_Workflow MCP çµ„ä»¶
å·¥ä½œæµéŒ„è£½å’Œç®¡ç†çš„MCPçµ„ä»¶

åŸºæ–¼åŸæœ‰Workflow Recorderæ ¸å¿ƒåŠŸèƒ½ï¼Œæä¾›ï¼š
- å·¥ä½œæµéŒ„è£½æœƒè©±ç®¡ç†
- éŒ„è£½æ•¸æ“šè™•ç†å’Œåˆ†æ
- å·¥ä½œæµæ­¥é©Ÿè¿½è¹¤
- éŒ„è£½çµæœå°å‡º
- æ™ºèƒ½å·¥ä½œæµå­¸ç¿’

ä½œè€…: PowerAutomation Team
ç‰ˆæœ¬: 2.0.0
æ—¥æœŸ: 2025-06-23
"""

import json
import logging
import asyncio
import time
import os
import uuid
from typing import Dict, List, Any, Optional, Union
from datetime import datetime, timedelta
from pathlib import Path
from dataclasses import dataclass, asdict
from enum import Enum
import tempfile
import subprocess

logger = logging.getLogger(__name__)

class RecordingStatus(Enum):
    """éŒ„è£½ç‹€æ…‹æšèˆ‰"""
    IDLE = "idle"
    RECORDING = "recording"
    PROCESSING = "processing"
    COMPLETED = "completed"
    FAILED = "failed"

class WorkflowType(Enum):
    """å·¥ä½œæµé¡å‹æšèˆ‰"""
    FORM_FILLING = "form_filling"
    DATA_EXTRACTION = "data_extraction"
    NAVIGATION = "navigation"
    AUTOMATION = "automation"
    TESTING = "testing"
    GENERAL = "general"
    DEPLOYMENT = "deployment"
    CODING = "coding"

@dataclass
class RecordingSession:
    """éŒ„è£½æœƒè©±æ•¸æ“šçµæ§‹"""
    session_id: str
    session_name: str
    start_time: str
    end_time: Optional[str] = None
    status: RecordingStatus = RecordingStatus.IDLE
    workflow_type: WorkflowType = WorkflowType.AUTOMATION
    description: str = ""
    recorded_steps: int = 0
    workflow_file: Optional[str] = None
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

@dataclass
class WorkflowStep:
    """å·¥ä½œæµæ­¥é©Ÿæ•¸æ“šçµæ§‹"""
    step_id: int
    action_type: str
    selector: str
    value: Optional[str] = None
    wait_time: float = 0.0
    screenshot: Optional[str] = None
    success: bool = True
    error_message: Optional[str] = None
    execution_time: float = 0.0
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

class WorkflowDataProcessor:
    """å·¥ä½œæµæ•¸æ“šè™•ç†å™¨"""
    
    def __init__(self):
        self.logger = logging.getLogger(f"{__name__}.WorkflowDataProcessor")
    
    async def process_recording_data(self, session: RecordingSession, raw_data: Dict) -> Dict[str, Any]:
        """è™•ç†éŒ„è£½æ•¸æ“š"""
        try:
            processed_data = {
                "session_info": asdict(session),
                "workflow_steps": [],
                "statistics": {
                    "total_steps": 0,
                    "successful_steps": 0,
                    "failed_steps": 0,
                    "total_duration": 0.0,
                    "average_step_time": 0.0,
                    "complexity_score": 0.0,
                    "action_types": {}
                },
                "patterns": {
                    "common_selectors": [],
                    "frequent_actions": [],
                    "error_patterns": []
                },
                "metadata": {
                    "processed_at": datetime.now().isoformat(),
                    "processor_version": "2.0.0"
                }
            }
            
            # è™•ç†æ­¥é©Ÿæ•¸æ“š
            steps = raw_data.get("steps", [])
            action_counts = {}
            
            for i, step_data in enumerate(steps):
                step = WorkflowStep(
                    step_id=i + 1,
                    action_type=step_data.get("action", "unknown"),
                    selector=step_data.get("selector", ""),
                    value=step_data.get("value"),
                    wait_time=step_data.get("wait_time", 0.0),
                    success=step_data.get("success", True),
                    execution_time=step_data.get("execution_time", 0.0),
                    metadata={
                        "url": step_data.get("url"),
                        "element_text": step_data.get("element_text"),
                        "coordinates": step_data.get("coordinates"),
                        "timestamp": step_data.get("timestamp")
                    }
                )
                processed_data["workflow_steps"].append(asdict(step))
                
                # çµ±è¨ˆå‹•ä½œé¡å‹
                action_type = step.action_type
                action_counts[action_type] = action_counts.get(action_type, 0) + 1
            
            # è¨ˆç®—çµ±è¨ˆä¿¡æ¯
            stats = processed_data["statistics"]
            stats["total_steps"] = len(steps)
            stats["successful_steps"] = sum(1 for s in steps if s.get("success", True))
            stats["failed_steps"] = stats["total_steps"] - stats["successful_steps"]
            stats["total_duration"] = sum(s.get("execution_time", 0.0) for s in steps)
            stats["average_step_time"] = stats["total_duration"] / max(stats["total_steps"], 1)
            stats["action_types"] = action_counts
            stats["complexity_score"] = self._calculate_complexity_score(processed_data["workflow_steps"])
            
            # åˆ†ææ¨¡å¼
            processed_data["patterns"] = self._analyze_patterns(processed_data["workflow_steps"])
            
            return processed_data
            
        except Exception as e:
            self.logger.error(f"è™•ç†éŒ„è£½æ•¸æ“šå¤±æ•—: {e}")
            raise
    
    def _calculate_complexity_score(self, steps: List[Dict]) -> float:
        """è¨ˆç®—å·¥ä½œæµè¤‡é›œåº¦åˆ†æ•¸"""
        try:
            if not steps:
                return 0.0
            
            # åŸºæ–¼å¤šå€‹å› ç´ è¨ˆç®—è¤‡é›œåº¦
            step_count_factor = min(len(steps) / 20.0, 1.0)  # æ­¥é©Ÿæ•¸é‡
            unique_actions = len(set(step.get("action_type", "") for step in steps))
            action_variety_factor = min(unique_actions / 10.0, 1.0)  # å‹•ä½œå¤šæ¨£æ€§
            
            # éŒ¯èª¤ç‡å› ç´ 
            failed_steps = sum(1 for step in steps if not step.get("success", True))
            error_factor = failed_steps / len(steps) if steps else 0
            
            complexity_score = (
                step_count_factor * 0.4 +
                action_variety_factor * 0.4 +
                error_factor * 0.2
            )
            
            return min(complexity_score, 1.0)
            
        except Exception as e:
            self.logger.error(f"è¨ˆç®—è¤‡é›œåº¦åˆ†æ•¸å¤±æ•—: {e}")
            return 0.5
    
    def _analyze_patterns(self, steps: List[Dict]) -> Dict[str, List]:
        """åˆ†æå·¥ä½œæµæ¨¡å¼"""
        try:
            patterns = {
                "common_selectors": [],
                "frequent_actions": [],
                "error_patterns": []
            }
            
            if not steps:
                return patterns
            
            # åˆ†æå¸¸ç”¨é¸æ“‡å™¨
            selectors = [step.get("selector", "") for step in steps if step.get("selector")]
            selector_counts = {}
            for selector in selectors:
                selector_counts[selector] = selector_counts.get(selector, 0) + 1
            
            patterns["common_selectors"] = sorted(
                selector_counts.items(), 
                key=lambda x: x[1], 
                reverse=True
            )[:5]
            
            # åˆ†æé »ç¹å‹•ä½œ
            actions = [step.get("action_type", "") for step in steps]
            action_counts = {}
            for action in actions:
                action_counts[action] = action_counts.get(action, 0) + 1
            
            patterns["frequent_actions"] = sorted(
                action_counts.items(), 
                key=lambda x: x[1], 
                reverse=True
            )[:5]
            
            # åˆ†æéŒ¯èª¤æ¨¡å¼
            error_steps = [step for step in steps if not step.get("success", True)]
            patterns["error_patterns"] = [
                {
                    "step_id": step.get("step_id"),
                    "action_type": step.get("action_type"),
                    "error_message": step.get("error_message", "Unknown error")
                }
                for step in error_steps[:5]
            ]
            
            return patterns
            
        except Exception as e:
            self.logger.error(f"åˆ†ææ¨¡å¼å¤±æ•—: {e}")
            return {"common_selectors": [], "frequent_actions": [], "error_patterns": []}

class RecorderWorkflowMCP:
    """Recorder_Workflow MCP çµ„ä»¶"""
    
    def __init__(self, recordings_dir: str = "./recordings"):
        self.recordings_dir = Path(recordings_dir)
        self.recordings_dir.mkdir(exist_ok=True)
        
        self.current_session: Optional[RecordingSession] = None
        self.sessions_history: List[RecordingSession] = []
        self.data_processor = WorkflowDataProcessor()
        
        # çµ„ä»¶ä¿¡æ¯
        self.component_info = {
            "name": "Recorder_Workflow MCP",
            "version": "2.0.0",
            "description": "å·¥ä½œæµéŒ„è£½å’Œç®¡ç†çš„MCPçµ„ä»¶ï¼Œæ”¯æŒæ™ºèƒ½å­¸ç¿’å’Œæ¨¡å¼åˆ†æ",
            "tool_type": "MCP Component",
            "capabilities": {
                "workflow_recording": {
                    "description": "éŒ„è£½ç”¨æˆ¶å·¥ä½œæµæ“ä½œ",
                    "input_types": ["json"],
                    "output_types": ["json"],
                    "parameters": {
                        "session_name": "string",
                        "workflow_type": "string",
                        "description": "string"
                    }
                },
                "session_management": {
                    "description": "ç®¡ç†éŒ„è£½æœƒè©±ç”Ÿå‘½é€±æœŸ",
                    "input_types": ["json"],
                    "output_types": ["json"],
                    "parameters": {
                        "session_id": "string",
                        "action": "string"
                    }
                },
                "data_processing": {
                    "description": "è™•ç†å’Œåˆ†æéŒ„è£½æ•¸æ“š",
                    "input_types": ["json"],
                    "output_types": ["json"],
                    "parameters": {
                        "session_id": "string",
                        "analysis_type": "string"
                    }
                },
                "pattern_analysis": {
                    "description": "åˆ†æå·¥ä½œæµæ¨¡å¼å’Œå„ªåŒ–å»ºè­°",
                    "input_types": ["json"],
                    "output_types": ["json"],
                    "parameters": {
                        "workflow_data": "object",
                        "analysis_depth": "string"
                    }
                },
                "workflow_export": {
                    "description": "å°å‡ºå·¥ä½œæµæ•¸æ“šç‚ºä¸åŒæ ¼å¼",
                    "input_types": ["json"],
                    "output_types": ["json", "csv", "yaml"],
                    "parameters": {
                        "session_id": "string",
                        "format": "string"
                    }
                }
            },
            "supported_types": [wt.value for wt in WorkflowType],
            "tool_discovery": {
                "registry_compatible": True,
                "mcp_version": "2.0",
                "discovery_metadata": {
                    "tags": ["mcp", "component", "workflow", "recording", "automation"],
                    "category": "workflow_tools",
                    "priority": "high"
                }
            }
        }
        
        self.logger = logging.getLogger(f"{__name__}.RecorderWorkflowMCP")
        self.logger.info("ğŸ¬ Recorder_Workflow MCP çµ„ä»¶åˆå§‹åŒ–å®Œæˆ")
    
    @staticmethod
    def get_capabilities() -> Dict[str, Any]:
        """è¿”å›çµ„ä»¶èƒ½åŠ›æè¿°ï¼Œä¾›Tool Registryç™¼ç¾"""
        return {
            "name": "recorder_workflow_mcp",
            "description": "å·¥ä½œæµéŒ„è£½å’Œç®¡ç†çš„MCPçµ„ä»¶ï¼Œæ”¯æŒæ™ºèƒ½å­¸ç¿’å’Œæ¨¡å¼åˆ†æ",
            "tool_type": "MCP Component",
            "capabilities": {
                "workflow_recording": {
                    "description": "éŒ„è£½ç”¨æˆ¶å·¥ä½œæµæ“ä½œ",
                    "input_types": ["json"],
                    "output_types": ["json"],
                    "parameters": {
                        "session_name": "string",
                        "workflow_type": "string",
                        "description": "string"
                    }
                },
                "session_management": {
                    "description": "ç®¡ç†éŒ„è£½æœƒè©±ç”Ÿå‘½é€±æœŸ",
                    "input_types": ["json"],
                    "output_types": ["json"],
                    "parameters": {
                        "session_id": "string",
                        "action": "string"
                    }
                },
                "data_processing": {
                    "description": "è™•ç†å’Œåˆ†æéŒ„è£½æ•¸æ“š",
                    "input_types": ["json"],
                    "output_types": ["json"],
                    "parameters": {
                        "session_id": "string",
                        "analysis_type": "string"
                    }
                },
                "pattern_analysis": {
                    "description": "åˆ†æå·¥ä½œæµæ¨¡å¼å’Œå„ªåŒ–å»ºè­°",
                    "input_types": ["json"],
                    "output_types": ["json"],
                    "parameters": {
                        "workflow_data": "object",
                        "analysis_depth": "string"
                    }
                },
                "workflow_export": {
                    "description": "å°å‡ºå·¥ä½œæµæ•¸æ“šç‚ºä¸åŒæ ¼å¼",
                    "input_types": ["json"],
                    "output_types": ["json", "csv", "yaml"],
                    "parameters": {
                        "session_id": "string",
                        "format": "string"
                    }
                }
            },
            "tool_discovery": {
                "registry_compatible": True,
                "mcp_version": "2.0",
                "discovery_metadata": {
                    "tags": ["mcp", "component", "workflow", "recording", "automation"],
                    "category": "workflow_tools",
                    "priority": "high"
                }
            }
        }
    
    async def start_recording(self, session_name: str, 
                            workflow_type: str = "automation",
                            description: str = "") -> Dict[str, Any]:
        """é–‹å§‹éŒ„è£½å·¥ä½œæµ"""
        try:
            if self.current_session and self.current_session.status == RecordingStatus.RECORDING:
                return {
                    "success": False,
                    "error": "å·²æœ‰éŒ„è£½æœƒè©±æ­£åœ¨é€²è¡Œä¸­",
                    "current_session": asdict(self.current_session)
                }
            
            # å‰µå»ºæ–°çš„éŒ„è£½æœƒè©±
            session_id = f"workflow_{uuid.uuid4().hex[:8]}"
            session = RecordingSession(
                session_id=session_id,
                session_name=session_name,
                start_time=datetime.now().isoformat(),
                status=RecordingStatus.RECORDING,
                workflow_type=WorkflowType(workflow_type),
                description=description
            )
            
            # å‰µå»ºæœƒè©±ç›®éŒ„
            session_dir = self.recordings_dir / session_id
            session_dir.mkdir(exist_ok=True)
            
            self.current_session = session
            self.logger.info(f"ğŸ¬ é–‹å§‹éŒ„è£½æœƒè©±: {session_name} ({session_id})")
            
            return {
                "success": True,
                "session": asdict(session),
                "message": f"éŒ„è£½æœƒè©± '{session_name}' å·²é–‹å§‹"
            }
            
        except Exception as e:
            self.logger.error(f"âŒ é–‹å§‹éŒ„è£½å¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def stop_recording(self) -> Dict[str, Any]:
        """åœæ­¢éŒ„è£½ä¸¦è™•ç†çµæœ"""
        try:
            if not self.current_session or self.current_session.status != RecordingStatus.RECORDING:
                return {
                    "success": False,
                    "error": "æ²’æœ‰æ­£åœ¨é€²è¡Œçš„éŒ„è£½æœƒè©±"
                }
            
            # æ›´æ–°æœƒè©±ç‹€æ…‹
            self.current_session.status = RecordingStatus.PROCESSING
            self.current_session.end_time = datetime.now().isoformat()
            
            # æ¨¡æ“¬è™•ç†éŒ„è£½çµæœï¼ˆå¯¦éš›å¯¦ç¾ä¸­æœƒè™•ç†çœŸå¯¦çš„éŒ„è£½æ•¸æ“šï¼‰
            mock_recording_data = {
                "steps": [
                    {
                        "action": "click",
                        "selector": "#submit-button",
                        "success": True,
                        "execution_time": 0.5,
                        "url": "https://example.com/form",
                        "element_text": "Submit"
                    },
                    {
                        "action": "input",
                        "selector": "#username",
                        "value": "test_user",
                        "success": True,
                        "execution_time": 0.3,
                        "url": "https://example.com/form"
                    },
                    {
                        "action": "navigate",
                        "selector": "",
                        "value": "https://example.com/dashboard",
                        "success": True,
                        "execution_time": 1.2
                    }
                ]
            }
            
            # è™•ç†éŒ„è£½æ•¸æ“š
            processed_data = await self.data_processor.process_recording_data(
                self.current_session, mock_recording_data
            )
            
            # ä¿å­˜è™•ç†çµæœ
            result_file = self.recordings_dir / self.current_session.session_id / "workflow_data.json"
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(processed_data, f, ensure_ascii=False, indent=2)
            
            # æ›´æ–°æœƒè©±ä¿¡æ¯
            self.current_session.status = RecordingStatus.COMPLETED
            self.current_session.recorded_steps = len(mock_recording_data.get('steps', []))
            self.current_session.workflow_file = str(result_file)
            
            # ä¿å­˜åˆ°æ­·å²
            completed_session = self.current_session
            self.sessions_history.append(completed_session)
            self.current_session = None
            
            self.logger.info(f"âœ… éŒ„è£½æœƒè©±å®Œæˆ: {completed_session.session_name}")
            
            return {
                "success": True,
                "session": asdict(completed_session),
                "processed_data": processed_data,
                "message": f"éŒ„è£½æœƒè©± '{completed_session.session_name}' å·²å®Œæˆ"
            }
            
        except Exception as e:
            self.logger.error(f"âŒ åœæ­¢éŒ„è£½å¤±æ•—: {e}")
            if self.current_session:
                self.current_session.status = RecordingStatus.FAILED
            return {
                "success": False,
                "error": str(e)
            }
    
    async def get_recording_status(self) -> Dict[str, Any]:
        """ç²å–éŒ„è£½ç‹€æ…‹"""
        try:
            status_info = {
                "is_recording": self.current_session is not None and 
                              self.current_session.status == RecordingStatus.RECORDING,
                "current_session": asdict(self.current_session) if self.current_session else None,
                "total_sessions": len(self.sessions_history),
                "recent_sessions": [asdict(s) for s in self.sessions_history[-5:]],
                "component_info": self.component_info
            }
            
            return {
                "success": True,
                "data": status_info
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ç²å–éŒ„è£½ç‹€æ…‹å¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def analyze_workflow_patterns(self, workflow_data: Dict, analysis_depth: str = "basic") -> Dict[str, Any]:
        """åˆ†æå·¥ä½œæµæ¨¡å¼"""
        try:
            steps = workflow_data.get("workflow_steps", [])
            if not steps:
                return {
                    "success": False,
                    "error": "æ²’æœ‰å·¥ä½œæµæ­¥é©Ÿæ•¸æ“š"
                }
            
            analysis_result = {
                "analysis_type": analysis_depth,
                "timestamp": datetime.now().isoformat(),
                "patterns": self.data_processor._analyze_patterns(steps),
                "recommendations": [],
                "optimization_suggestions": []
            }
            
            # åŸºæ–¼åˆ†ææ·±åº¦æä¾›ä¸åŒç´šåˆ¥çš„å»ºè­°
            if analysis_depth == "advanced":
                analysis_result["recommendations"] = self._generate_advanced_recommendations(steps)
                analysis_result["optimization_suggestions"] = self._generate_optimization_suggestions(steps)
            else:
                analysis_result["recommendations"] = self._generate_basic_recommendations(steps)
            
            return {
                "success": True,
                "analysis": analysis_result
            }
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ†æå·¥ä½œæµæ¨¡å¼å¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def _generate_basic_recommendations(self, steps: List[Dict]) -> List[str]:
        """ç”ŸæˆåŸºæœ¬å»ºè­°"""
        recommendations = []
        
        # æª¢æŸ¥éŒ¯èª¤ç‡
        failed_steps = sum(1 for step in steps if not step.get("success", True))
        if failed_steps > 0:
            error_rate = failed_steps / len(steps)
            if error_rate > 0.1:
                recommendations.append(f"å·¥ä½œæµéŒ¯èª¤ç‡è¼ƒé«˜ ({error_rate:.1%})ï¼Œå»ºè­°æª¢æŸ¥å¤±æ•—æ­¥é©Ÿ")
        
        # æª¢æŸ¥åŸ·è¡Œæ™‚é–“
        total_time = sum(step.get("execution_time", 0) for step in steps)
        if total_time > 30:
            recommendations.append("å·¥ä½œæµåŸ·è¡Œæ™‚é–“è¼ƒé•·ï¼Œè€ƒæ…®å„ªåŒ–æ­¥é©Ÿé †åº")
        
        # æª¢æŸ¥é‡è¤‡å‹•ä½œ
        actions = [step.get("action_type") for step in steps]
        if len(set(actions)) < len(actions) * 0.5:
            recommendations.append("æª¢æ¸¬åˆ°é‡è¤‡å‹•ä½œï¼Œå¯èƒ½å­˜åœ¨å„ªåŒ–ç©ºé–“")
        
        return recommendations
    
    def _generate_advanced_recommendations(self, steps: List[Dict]) -> List[str]:
        """ç”Ÿæˆé«˜ç´šå»ºè­°"""
        recommendations = self._generate_basic_recommendations(steps)
        
        # é«˜ç´šåˆ†æ
        selectors = [step.get("selector") for step in steps if step.get("selector")]
        if len(set(selectors)) < len(selectors) * 0.3:
            recommendations.append("æª¢æ¸¬åˆ°å¤§é‡é‡è¤‡é¸æ“‡å™¨ï¼Œå»ºè­°ä½¿ç”¨å¾ªç’°æˆ–æ‰¹é‡æ“ä½œ")
        
        # åˆ†æç­‰å¾…æ™‚é–“
        wait_times = [step.get("wait_time", 0) for step in steps]
        avg_wait = sum(wait_times) / len(wait_times) if wait_times else 0
        if avg_wait > 2:
            recommendations.append("å¹³å‡ç­‰å¾…æ™‚é–“è¼ƒé•·ï¼Œå»ºè­°å„ªåŒ–é é¢åŠ è¼‰æˆ–ä½¿ç”¨æ™ºèƒ½ç­‰å¾…")
        
        return recommendations
    
    def _generate_optimization_suggestions(self, steps: List[Dict]) -> List[Dict]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        suggestions = []
        
        # å»ºè­°ä¸¦è¡ŒåŒ–
        navigation_steps = [step for step in steps if step.get("action_type") == "navigate"]
        if len(navigation_steps) > 2:
            suggestions.append({
                "type": "parallelization",
                "description": "å¤šå€‹å°èˆªæ­¥é©Ÿå¯ä»¥è€ƒæ…®ä¸¦è¡Œè™•ç†",
                "impact": "medium"
            })
        
        # å»ºè­°ç·©å­˜
        repeated_selectors = {}
        for step in steps:
            selector = step.get("selector", "")
            if selector:
                repeated_selectors[selector] = repeated_selectors.get(selector, 0) + 1
        
        high_frequency_selectors = [s for s, count in repeated_selectors.items() if count > 3]
        if high_frequency_selectors:
            suggestions.append({
                "type": "caching",
                "description": f"é«˜é »é¸æ“‡å™¨ {high_frequency_selectors[:3]} å»ºè­°ä½¿ç”¨å…ƒç´ ç·©å­˜",
                "impact": "high"
            })
        
        return suggestions
    
    async def list_sessions(self, limit: int = 10) -> Dict[str, Any]:
        """åˆ—å‡ºéŒ„è£½æœƒè©±"""
        try:
            sessions = self.sessions_history[-limit:] if limit > 0 else self.sessions_history
            
            return {
                "success": True,
                "sessions": [asdict(s) for s in sessions],
                "total_count": len(self.sessions_history)
            }
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ—å‡ºæœƒè©±å¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def get_session_data(self, session_id: str) -> Dict[str, Any]:
        """ç²å–æœƒè©±æ•¸æ“š"""
        try:
            # æŸ¥æ‰¾æœƒè©±
            session = None
            for s in self.sessions_history:
                if s.session_id == session_id:
                    session = s
                    break
            
            if not session:
                return {
                    "success": False,
                    "error": f"æœƒè©± {session_id} ä¸å­˜åœ¨"
                }
            
            # è®€å–æœƒè©±æ•¸æ“šæ–‡ä»¶
            data_file = self.recordings_dir / session_id / "workflow_data.json"
            if data_file.exists():
                with open(data_file, 'r', encoding='utf-8') as f:
                    workflow_data = json.load(f)
            else:
                workflow_data = None
            
            return {
                "success": True,
                "session": asdict(session),
                "workflow_data": workflow_data
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ç²å–æœƒè©±æ•¸æ“šå¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def export_workflow(self, session_id: str, format: str = "json") -> Dict[str, Any]:
        """å°å‡ºå·¥ä½œæµæ•¸æ“š"""
        try:
            session_data = await self.get_session_data(session_id)
            if not session_data["success"]:
                return session_data
            
            workflow_data = session_data["workflow_data"]
            if not workflow_data:
                return {
                    "success": False,
                    "error": "æœƒè©±æ•¸æ“šä¸å­˜åœ¨"
                }
            
            # æ ¹æ“šæ ¼å¼å°å‡º
            if format == "json":
                export_data = workflow_data
            elif format == "csv":
                # ç°¡åŒ–çš„CSVå°å‡º
                steps = workflow_data.get("workflow_steps", [])
                csv_data = "step_id,action_type,selector,value,success,execution_time\n"
                for step in steps:
                    csv_data += f"{step['step_id']},{step['action_type']},{step['selector']},{step.get('value', '')},{step['success']},{step['execution_time']}\n"
                export_data = csv_data
            elif format == "yaml":
                import yaml
                export_data = yaml.dump(workflow_data, default_flow_style=False, allow_unicode=True)
            else:
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„å°å‡ºæ ¼å¼: {format}"
                }
            
            return {
                "success": True,
                "format": format,
                "data": export_data,
                "session_id": session_id
            }
            
        except Exception as e:
            self.logger.error(f"âŒ å°å‡ºå·¥ä½œæµå¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    def get_component_info(self) -> Dict[str, Any]:
        """ç²å–çµ„ä»¶ä¿¡æ¯"""
        return self.component_info

def create_recorder_workflow_mcp(recordings_dir: str = "./recordings") -> RecorderWorkflowMCP:
    """å‰µå»ºRecorder_Workflow MCPçµ„ä»¶å¯¦ä¾‹"""
    return RecorderWorkflowMCP(recordings_dir)

# å°å‡ºä¸»è¦é¡å’Œå‡½æ•¸
__all__ = [
    "RecorderWorkflowMCP",
    "RecordingSession", 
    "WorkflowStep",
    "RecordingStatus",
    "WorkflowType",
    "create_recorder_workflow_mcp"
]

