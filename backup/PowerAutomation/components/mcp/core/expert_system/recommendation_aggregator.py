"""
å°ˆå®¶å»ºè­°èšåˆå™¨
Expert Recommendation Aggregator
"""

import asyncio
import logging
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class AggregationStrategy(Enum):
    """èšåˆç­–ç•¥"""
    CONSENSUS = "consensus"          # å…±è­˜èšåˆ
    WEIGHTED = "weighted"            # åŠ æ¬Šèšåˆ
    PRIORITY = "priority"            # å„ªå…ˆç´šèšåˆ
    HYBRID = "hybrid"               # æ··åˆèšåˆ

@dataclass
class AggregatedRecommendation:
    """èšåˆå¾Œçš„å»ºè­°"""
    category: str                    # å»ºè­°é¡åˆ¥
    recommendation: str              # å»ºè­°å…§å®¹
    confidence: float               # ä¿¡å¿ƒåº¦
    supporting_experts: List[str]    # æ”¯æŒçš„å°ˆå®¶
    priority: int                   # å„ªå…ˆç´š
    implementation_steps: List[str]  # å¯¦æ–½æ­¥é©Ÿ
    required_tools: List[str]       # éœ€è¦çš„å·¥å…·
    metadata: Dict[str, Any]        # å…ƒæ•¸æ“š

@dataclass
class AggregationResult:
    """èšåˆçµæœ"""
    aggregated_recommendations: List[AggregatedRecommendation]
    consensus_level: float          # å…±è­˜ç¨‹åº¦
    conflict_areas: List[str]       # è¡çªé ˜åŸŸ
    tool_requirements: Dict[str, Any]  # å·¥å…·éœ€æ±‚
    implementation_plan: Dict[str, Any]  # å¯¦æ–½è¨ˆåŠƒ
    metadata: Dict[str, Any]

class ExpertRecommendationAggregator:
    """å°ˆå®¶å»ºè­°èšåˆå™¨"""
    
    def __init__(self):
        self.aggregation_strategies = {
            AggregationStrategy.CONSENSUS: self._consensus_aggregation,
            AggregationStrategy.WEIGHTED: self._weighted_aggregation,
            AggregationStrategy.PRIORITY: self._priority_aggregation,
            AggregationStrategy.HYBRID: self._hybrid_aggregation
        }
    
    async def aggregate_expert_analysis(self, expert_responses: List, 
                                      strategy: AggregationStrategy = AggregationStrategy.HYBRID) -> AggregationResult:
        """èšåˆå°ˆå®¶åˆ†æ"""
        logger.info(f"ğŸ”„ é–‹å§‹èšåˆ {len(expert_responses)} å€‹å°ˆå®¶å»ºè­°ï¼Œç­–ç•¥: {strategy.value}")
        
        if not expert_responses:
            return AggregationResult(
                aggregated_recommendations=[],
                consensus_level=0.0,
                conflict_areas=[],
                tool_requirements={},
                implementation_plan={},
                metadata={"error": "æ²’æœ‰å°ˆå®¶å›æ‡‰å¯èšåˆ"}
            )
        
        # é è™•ç†å°ˆå®¶å›æ‡‰
        processed_responses = await self._preprocess_expert_responses(expert_responses)
        
        # åŸ·è¡Œèšåˆç­–ç•¥
        aggregation_func = self.aggregation_strategies[strategy]
        aggregation_result = await aggregation_func(processed_responses)
        
        # ç”Ÿæˆå·¥å…·éœ€æ±‚
        tool_requirements = await self._generate_tool_requirements(aggregation_result)
        
        # ç”Ÿæˆå¯¦æ–½è¨ˆåŠƒ
        implementation_plan = await self._generate_implementation_plan(aggregation_result)
        
        # æª¢æ¸¬è¡çª
        conflict_areas = await self._detect_conflicts(processed_responses)
        
        # è¨ˆç®—å…±è­˜ç¨‹åº¦
        consensus_level = await self._calculate_consensus_level(processed_responses)
        
        result = AggregationResult(
            aggregated_recommendations=aggregation_result,
            consensus_level=consensus_level,
            conflict_areas=conflict_areas,
            tool_requirements=tool_requirements,
            implementation_plan=implementation_plan,
            metadata={
                "strategy_used": strategy.value,
                "expert_count": len(expert_responses),
                "processing_time": 0.0
            }
        )
        
        logger.info(f"âœ… èšåˆå®Œæˆï¼Œç”Ÿæˆ {len(aggregation_result)} å€‹èšåˆå»ºè­°")
        return result
    
    async def _preprocess_expert_responses(self, expert_responses: List) -> List[Dict]:
        """é è™•ç†å°ˆå®¶å›æ‡‰"""
        processed = []
        
        for response in expert_responses:
            # æå–é—œéµä¿¡æ¯
            processed_response = {
                "expert_id": response.expert_id,
                "expert_name": response.expert_name,
                "expert_type": response.expert_type,
                "confidence": response.confidence,
                "analysis": response.analysis,
                "recommendations": response.recommendations,
                "tool_suggestions": response.tool_suggestions,
                "categories": await self._categorize_recommendations(response.recommendations),
                "keywords": await self._extract_keywords(response.analysis),
                "priority_indicators": await self._extract_priority_indicators(response.recommendations)
            }
            processed.append(processed_response)
        
        return processed
    
    async def _categorize_recommendations(self, recommendations: List[str]) -> Dict[str, List[str]]:
        """åˆ†é¡å»ºè­°"""
        categories = {
            "implementation": [],
            "testing": [],
            "deployment": [],
            "security": [],
            "performance": [],
            "monitoring": [],
            "documentation": [],
            "best_practices": []
        }
        
        category_keywords = {
            "implementation": ["å¯¦ç¾", "é–‹ç™¼", "ç·¨ç¢¼", "ç¨‹å¼", "ä»£ç¢¼"],
            "testing": ["æ¸¬è©¦", "é©—è­‰", "æª¢æŸ¥", "å“è³ª"],
            "deployment": ["éƒ¨ç½²", "ç™¼å¸ƒ", "ä¸Šç·š", "ç”Ÿç”¢"],
            "security": ["å®‰å…¨", "èªè­‰", "æˆæ¬Š", "åŠ å¯†"],
            "performance": ["æ€§èƒ½", "å„ªåŒ–", "æ•ˆç‡", "é€Ÿåº¦"],
            "monitoring": ["ç›£æ§", "æ—¥èªŒ", "è¿½è¹¤", "è§€å¯Ÿ"],
            "documentation": ["æ–‡æª”", "èªªæ˜", "è¨˜éŒ„", "è¨»é‡‹"],
            "best_practices": ["æœ€ä½³å¯¦è¸", "å»ºè­°", "è¦ç¯„", "æ¨™æº–"]
        }
        
        for recommendation in recommendations:
            rec_lower = recommendation.lower()
            categorized = False
            
            for category, keywords in category_keywords.items():
                if any(keyword in rec_lower for keyword in keywords):
                    categories[category].append(recommendation)
                    categorized = True
                    break
            
            if not categorized:
                categories["best_practices"].append(recommendation)
        
        return {k: v for k, v in categories.items() if v}
    
    async def _extract_keywords(self, analysis: str) -> List[str]:
        """æå–é—œéµè©"""
        # ç°¡åŒ–çš„é—œéµè©æå–
        common_words = {"çš„", "æ˜¯", "åœ¨", "æœ‰", "å’Œ", "èˆ‡", "æˆ–", "ä½†", "å¦‚æœ", "å› ç‚º", "æ‰€ä»¥"}
        words = analysis.split()
        keywords = [word for word in words if len(word) > 2 and word not in common_words]
        return keywords[:10]  # è¿”å›å‰10å€‹é—œéµè©
    
    async def _extract_priority_indicators(self, recommendations: List[str]) -> Dict[str, int]:
        """æå–å„ªå…ˆç´šæŒ‡æ¨™"""
        priority_keywords = {
            "critical": ["ç·Šæ€¥", "é—œéµ", "é‡è¦", "å¿…é ˆ", "ç«‹å³"],
            "high": ["å»ºè­°", "æ‡‰è©²", "éœ€è¦", "æ¨è–¦"],
            "medium": ["å¯ä»¥", "è€ƒæ…®", "å¯èƒ½", "æˆ–è¨±"],
            "low": ["é¸æ“‡æ€§", "å¯é¸", "é¡å¤–", "è£œå……"]
        }
        
        priority_counts = {"critical": 0, "high": 0, "medium": 0, "low": 0}
        
        for recommendation in recommendations:
            rec_lower = recommendation.lower()
            for priority, keywords in priority_keywords.items():
                if any(keyword in rec_lower for keyword in keywords):
                    priority_counts[priority] += 1
        
        return priority_counts
    
    async def _consensus_aggregation(self, processed_responses: List[Dict]) -> List[AggregatedRecommendation]:
        """å…±è­˜èšåˆç­–ç•¥"""
        # æ‰¾å‡ºæ‰€æœ‰å°ˆå®¶éƒ½åŒæ„çš„å»ºè­°
        all_categories = set()
        for response in processed_responses:
            all_categories.update(response["categories"].keys())
        
        aggregated = []
        
        for category in all_categories:
            # æ”¶é›†è©²é¡åˆ¥çš„æ‰€æœ‰å»ºè­°
            category_recommendations = []
            supporting_experts = []
            
            for response in processed_responses:
                if category in response["categories"]:
                    category_recommendations.extend(response["categories"][category])
                    supporting_experts.append(response["expert_name"])
            
            if len(supporting_experts) >= len(processed_responses) * 0.5:  # è‡³å°‘50%å°ˆå®¶æ”¯æŒ
                # åˆä½µç›¸ä¼¼å»ºè­°
                merged_recommendation = await self._merge_similar_recommendations(category_recommendations)
                
                aggregated.append(AggregatedRecommendation(
                    category=category,
                    recommendation=merged_recommendation,
                    confidence=len(supporting_experts) / len(processed_responses),
                    supporting_experts=supporting_experts,
                    priority=self._calculate_category_priority(category),
                    implementation_steps=await self._generate_implementation_steps(merged_recommendation),
                    required_tools=await self._identify_required_tools(merged_recommendation),
                    metadata={"aggregation_method": "consensus"}
                ))
        
        return sorted(aggregated, key=lambda x: x.priority, reverse=True)
    
    async def _weighted_aggregation(self, processed_responses: List[Dict]) -> List[AggregatedRecommendation]:
        """åŠ æ¬Šèšåˆç­–ç•¥"""
        # åŸºæ–¼å°ˆå®¶ä¿¡å¿ƒåº¦é€²è¡ŒåŠ æ¬Š
        category_weights = {}
        category_recommendations = {}
        
        for response in processed_responses:
            weight = response["confidence"]
            
            for category, recommendations in response["categories"].items():
                if category not in category_weights:
                    category_weights[category] = 0
                    category_recommendations[category] = []
                
                category_weights[category] += weight
                category_recommendations[category].extend(recommendations)
        
        aggregated = []
        total_weight = sum(category_weights.values())
        
        for category, weight in category_weights.items():
            if weight > 0:
                normalized_confidence = weight / total_weight
                merged_recommendation = await self._merge_similar_recommendations(category_recommendations[category])
                
                aggregated.append(AggregatedRecommendation(
                    category=category,
                    recommendation=merged_recommendation,
                    confidence=normalized_confidence,
                    supporting_experts=[r["expert_name"] for r in processed_responses if category in r["categories"]],
                    priority=self._calculate_category_priority(category),
                    implementation_steps=await self._generate_implementation_steps(merged_recommendation),
                    required_tools=await self._identify_required_tools(merged_recommendation),
                    metadata={"aggregation_method": "weighted", "weight": weight}
                ))
        
        return sorted(aggregated, key=lambda x: x.confidence, reverse=True)
    
    async def _priority_aggregation(self, processed_responses: List[Dict]) -> List[AggregatedRecommendation]:
        """å„ªå…ˆç´šèšåˆç­–ç•¥"""
        # åŸºæ–¼å„ªå…ˆç´šæŒ‡æ¨™é€²è¡Œèšåˆ
        priority_scores = {}
        category_recommendations = {}
        
        for response in processed_responses:
            priority_indicators = response["priority_indicators"]
            
            for category, recommendations in response["categories"].items():
                if category not in priority_scores:
                    priority_scores[category] = 0
                    category_recommendations[category] = []
                
                # è¨ˆç®—å„ªå…ˆç´šåˆ†æ•¸
                score = (priority_indicators.get("critical", 0) * 4 +
                        priority_indicators.get("high", 0) * 3 +
                        priority_indicators.get("medium", 0) * 2 +
                        priority_indicators.get("low", 0) * 1)
                
                priority_scores[category] += score
                category_recommendations[category].extend(recommendations)
        
        aggregated = []
        max_score = max(priority_scores.values()) if priority_scores else 1
        
        for category, score in priority_scores.items():
            if score > 0:
                normalized_confidence = score / max_score
                merged_recommendation = await self._merge_similar_recommendations(category_recommendations[category])
                
                aggregated.append(AggregatedRecommendation(
                    category=category,
                    recommendation=merged_recommendation,
                    confidence=normalized_confidence,
                    supporting_experts=[r["expert_name"] for r in processed_responses if category in r["categories"]],
                    priority=score,
                    implementation_steps=await self._generate_implementation_steps(merged_recommendation),
                    required_tools=await self._identify_required_tools(merged_recommendation),
                    metadata={"aggregation_method": "priority", "priority_score": score}
                ))
        
        return sorted(aggregated, key=lambda x: x.priority, reverse=True)
    
    async def _hybrid_aggregation(self, processed_responses: List[Dict]) -> List[AggregatedRecommendation]:
        """æ··åˆèšåˆç­–ç•¥"""
        # çµåˆå…±è­˜ã€åŠ æ¬Šå’Œå„ªå…ˆç´š
        consensus_result = await self._consensus_aggregation(processed_responses)
        weighted_result = await self._weighted_aggregation(processed_responses)
        priority_result = await self._priority_aggregation(processed_responses)
        
        # åˆä½µçµæœ
        hybrid_result = {}
        
        # è™•ç†å…±è­˜çµæœ
        for rec in consensus_result:
            hybrid_result[rec.category] = rec
            hybrid_result[rec.category].metadata["consensus_score"] = rec.confidence
        
        # æ•´åˆåŠ æ¬Šçµæœ
        for rec in weighted_result:
            if rec.category in hybrid_result:
                hybrid_result[rec.category].confidence = (
                    hybrid_result[rec.category].confidence * 0.4 + rec.confidence * 0.6
                )
                hybrid_result[rec.category].metadata["weighted_score"] = rec.confidence
            else:
                hybrid_result[rec.category] = rec
                hybrid_result[rec.category].metadata["weighted_score"] = rec.confidence
        
        # æ•´åˆå„ªå…ˆç´šçµæœ
        for rec in priority_result:
            if rec.category in hybrid_result:
                hybrid_result[rec.category].priority = max(
                    hybrid_result[rec.category].priority, rec.priority
                )
                hybrid_result[rec.category].metadata["priority_score"] = rec.priority
            else:
                hybrid_result[rec.category] = rec
                hybrid_result[rec.category].metadata["priority_score"] = rec.priority
        
        # é‡æ–°è¨ˆç®—æœ€çµ‚åˆ†æ•¸
        for rec in hybrid_result.values():
            consensus_score = rec.metadata.get("consensus_score", 0.5)
            weighted_score = rec.metadata.get("weighted_score", 0.5)
            priority_score = rec.metadata.get("priority_score", 5) / 10.0  # æ­£è¦åŒ–åˆ°0-1
            
            rec.confidence = (consensus_score * 0.3 + weighted_score * 0.4 + priority_score * 0.3)
            rec.metadata["aggregation_method"] = "hybrid"
            rec.metadata["final_score"] = rec.confidence
        
        return sorted(hybrid_result.values(), key=lambda x: x.confidence, reverse=True)
    
    async def _merge_similar_recommendations(self, recommendations: List[str]) -> str:
        """åˆä½µç›¸ä¼¼å»ºè­°"""
        if not recommendations:
            return ""
        
        if len(recommendations) == 1:
            return recommendations[0]
        
        # ç°¡åŒ–çš„åˆä½µé‚è¼¯
        merged = f"ç¶œåˆå»ºè­°ï¼š{recommendations[0]}"
        if len(recommendations) > 1:
            merged += f"ï¼ŒåŒæ™‚è€ƒæ…®{len(recommendations)-1}å€‹ç›¸é—œå»ºè­°"
        
        return merged
    
    def _calculate_category_priority(self, category: str) -> int:
        """è¨ˆç®—é¡åˆ¥å„ªå…ˆç´š"""
        priority_map = {
            "security": 10,
            "implementation": 9,
            "testing": 8,
            "performance": 7,
            "deployment": 6,
            "monitoring": 5,
            "documentation": 4,
            "best_practices": 3
        }
        return priority_map.get(category, 5)
    
    async def _generate_implementation_steps(self, recommendation: str) -> List[str]:
        """ç”Ÿæˆå¯¦æ–½æ­¥é©Ÿ"""
        # åŸºæ–¼å»ºè­°å…§å®¹ç”Ÿæˆå¯¦æ–½æ­¥é©Ÿ
        steps = [
            "1. åˆ†æç•¶å‰ç‹€æ³å’Œéœ€æ±‚",
            f"2. æ ¹æ“šå»ºè­°åˆ¶å®šå¯¦æ–½è¨ˆåŠƒï¼š{recommendation[:50]}...",
            "3. æº–å‚™å¿…è¦çš„å·¥å…·å’Œè³‡æº",
            "4. åŸ·è¡Œå¯¦æ–½è¨ˆåŠƒ",
            "5. æ¸¬è©¦å’Œé©—è­‰çµæœ",
            "6. ç›£æ§å’Œå„ªåŒ–"
        ]
        return steps
    
    async def _identify_required_tools(self, recommendation: str) -> List[str]:
        """è­˜åˆ¥éœ€è¦çš„å·¥å…·"""
        tools = []
        rec_lower = recommendation.lower()
        
        tool_keywords = {
            "general_processor_mcp": ["è™•ç†", "åˆ†æ", "ç¶œåˆ"],
            "test_flow_mcp": ["æ¸¬è©¦", "é©—è­‰", "æª¢æŸ¥"],
            "system_monitor_adapter_mcp": ["ç›£æ§", "è§€å¯Ÿ", "è¿½è¹¤"],
            "file_processor_adapter_mcp": ["æ–‡ä»¶", "æª”æ¡ˆ", "è™•ç†"]
        }
        
        for tool, keywords in tool_keywords.items():
            if any(keyword in rec_lower for keyword in keywords):
                tools.append(tool)
        
        return tools
    
    async def _generate_tool_requirements(self, aggregated_recommendations: List[AggregatedRecommendation]) -> Dict[str, Any]:
        """ç”Ÿæˆå·¥å…·éœ€æ±‚"""
        tool_requirements = {
            "required_tools": set(),
            "tool_priorities": {},
            "dynamic_tools_needed": [],
            "flow_mcp_requirements": [],
            "adapter_mcp_requirements": []
        }
        
        for rec in aggregated_recommendations:
            # æ”¶é›†æ‰€æœ‰éœ€è¦çš„å·¥å…·
            tool_requirements["required_tools"].update(rec.required_tools)
            
            # è¨­ç½®å·¥å…·å„ªå…ˆç´š
            for tool in rec.required_tools:
                if tool not in tool_requirements["tool_priorities"]:
                    tool_requirements["tool_priorities"][tool] = 0
                tool_requirements["tool_priorities"][tool] += rec.priority
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦å‹•æ…‹ç”ŸæˆFlow MCP
            if rec.category in ["implementation", "testing", "deployment"]:
                flow_requirement = {
                    "category": rec.category,
                    "recommendation": rec.recommendation,
                    "steps": rec.implementation_steps,
                    "confidence": rec.confidence
                }
                tool_requirements["flow_mcp_requirements"].append(flow_requirement)
            
            # æª¢æŸ¥æ˜¯å¦éœ€è¦å‹•æ…‹ç”ŸæˆAdapter MCP
            if rec.category in ["monitoring", "performance", "security"]:
                adapter_requirement = {
                    "category": rec.category,
                    "recommendation": rec.recommendation,
                    "target_system": self._extract_target_system(rec.recommendation),
                    "confidence": rec.confidence
                }
                tool_requirements["adapter_mcp_requirements"].append(adapter_requirement)
        
        # è½‰æ›setç‚ºlist
        tool_requirements["required_tools"] = list(tool_requirements["required_tools"])
        
        return tool_requirements
    
    def _extract_target_system(self, recommendation: str) -> str:
        """æå–ç›®æ¨™ç³»çµ±"""
        system_keywords = {
            "database": ["è³‡æ–™åº«", "æ•¸æ“šåº«", "database", "sql"],
            "web_server": ["ç¶²é ", "web", "server", "ä¼ºæœå™¨"],
            "api": ["api", "æ¥å£", "ä»‹é¢"],
            "file_system": ["æ–‡ä»¶", "æª”æ¡ˆ", "file"],
            "network": ["ç¶²è·¯", "ç¶²çµ¡", "network"]
        }
        
        rec_lower = recommendation.lower()
        for system, keywords in system_keywords.items():
            if any(keyword in rec_lower for keyword in keywords):
                return system
        
        return "general"
    
    async def _generate_implementation_plan(self, aggregated_recommendations: List[AggregatedRecommendation]) -> Dict[str, Any]:
        """ç”Ÿæˆå¯¦æ–½è¨ˆåŠƒ"""
        plan = {
            "phases": [],
            "timeline": {},
            "dependencies": {},
            "resource_requirements": {}
        }
        
        # æŒ‰å„ªå…ˆç´šåˆ†çµ„
        high_priority = [r for r in aggregated_recommendations if r.priority >= 8]
        medium_priority = [r for r in aggregated_recommendations if 5 <= r.priority < 8]
        low_priority = [r for r in aggregated_recommendations if r.priority < 5]
        
        # ç”Ÿæˆéšæ®µ
        if high_priority:
            plan["phases"].append({
                "phase": "immediate",
                "recommendations": [r.category for r in high_priority],
                "duration": "1-2 days"
            })
        
        if medium_priority:
            plan["phases"].append({
                "phase": "short_term",
                "recommendations": [r.category for r in medium_priority],
                "duration": "1-2 weeks"
            })
        
        if low_priority:
            plan["phases"].append({
                "phase": "long_term",
                "recommendations": [r.category for r in low_priority],
                "duration": "1-2 months"
            })
        
        return plan
    
    async def _detect_conflicts(self, processed_responses: List[Dict]) -> List[str]:
        """æª¢æ¸¬è¡çª"""
        conflicts = []
        
        # æª¢æŸ¥ç›¸åŒé¡åˆ¥çš„ä¸åŒå»ºè­°
        category_experts = {}
        for response in processed_responses:
            for category in response["categories"]:
                if category not in category_experts:
                    category_experts[category] = []
                category_experts[category].append(response["expert_name"])
        
        # å¦‚æœæŸå€‹é¡åˆ¥æœ‰å¤šå€‹å°ˆå®¶ä½†å»ºè­°å·®ç•°å¾ˆå¤§ï¼Œæ¨™è¨˜ç‚ºè¡çª
        for category, experts in category_experts.items():
            if len(experts) > 1 and len(set(experts)) == len(experts):
                conflicts.append(f"{category}é ˜åŸŸå°ˆå®¶æ„è¦‹åˆ†æ­§")
        
        return conflicts
    
    async def _calculate_consensus_level(self, processed_responses: List[Dict]) -> float:
        """è¨ˆç®—å…±è­˜ç¨‹åº¦"""
        if not processed_responses:
            return 0.0
        
        # è¨ˆç®—å°ˆå®¶åœ¨å„é¡åˆ¥ä¸Šçš„ä¸€è‡´æ€§
        all_categories = set()
        for response in processed_responses:
            all_categories.update(response["categories"].keys())
        
        consensus_scores = []
        for category in all_categories:
            experts_with_category = sum(1 for r in processed_responses if category in r["categories"])
            consensus_score = experts_with_category / len(processed_responses)
            consensus_scores.append(consensus_score)
        
        return sum(consensus_scores) / len(consensus_scores) if consensus_scores else 0.0

def create_expert_recommendation_aggregator() -> ExpertRecommendationAggregator:
    """å‰µå»ºå°ˆå®¶å»ºè­°èšåˆå™¨"""
    return ExpertRecommendationAggregator()

