"""
AICore 3.0 - å‹•æ…‹å°ˆå®¶ç³»çµ±æ•´åˆç‰ˆ
Enhanced AICore with Dynamic Expert System Integration
"""

import asyncio
import time
import logging
import json
from typing import Dict, List, Any, Optional, Union
from dataclasses import dataclass, asdict
from enum import Enum
from datetime import datetime

# å°å…¥çµ„ä»¶
from components.general_processor_mcp import GeneralProcessorMCP, create_general_processor_mcp
from components.dynamic_expert_registry import (
    DynamicExpertRegistry, create_dynamic_expert_registry,
    ExpertRegistrationRequest, ExpertProfile, ExpertStatus, ExpertType as DynamicExpertType
)
from components.expert_recommendation_aggregator import (
    ExpertRecommendationAggregator, create_expert_recommendation_aggregator,
    AggregationStrategy, AggregatedRecommendation, AggregationResult
)
from components.dynamic_mcp_generator import (
    DynamicMCPGenerator, create_dynamic_mcp_generator,
    MCPToolType, MCPToolSpec, DynamicMCPRequest
)
from tools.tool_registry import ToolRegistry
from actions.action_executor import ActionExecutor

logger = logging.getLogger(__name__)

class ProcessingStage(Enum):
    """è™•ç†éšæ®µ - 6éšæ®µå®Œæ•´æµç¨‹"""
    INTEGRATED_SEARCH_ANALYSIS = "integrated_search_analysis"      # æ•´åˆå¼æœç´¢å’Œåˆ†æ
    DYNAMIC_EXPERT_GENERATION = "dynamic_expert_generation"        # å‹•æ…‹å°ˆå®¶ç”Ÿæˆ
    EXPERT_RESPONSE_GENERATION = "expert_response_generation"      # å°ˆå®¶å›ç­”ç”Ÿæˆ
    EXPERT_RECOMMENDATION_AGGREGATION = "expert_recommendation_aggregation"  # å°ˆå®¶å»ºè­°èšåˆ
    DYNAMIC_TOOL_GENERATION = "dynamic_tool_generation"           # å‹•æ…‹å·¥å…·ç”Ÿæˆå’ŒåŸ·è¡Œ
    FINAL_RESULT_GENERATION = "final_result_generation"           # æœ€çµ‚çµæœç”Ÿæˆ

@dataclass
class UserRequest:
    """ç”¨æˆ¶è«‹æ±‚æ•¸æ“šçµæ§‹"""
    id: str
    content: str
    context: Dict[str, Any]
    priority: str = "normal"
    metadata: Dict[str, Any] = None
    timestamp: float = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
        if self.timestamp is None:
            self.timestamp = time.time()

@dataclass
class ExpertResponse:
    """å°ˆå®¶éŸ¿æ‡‰æ•¸æ“šçµæ§‹"""
    expert_id: str
    expert_name: str
    expert_type: str
    analysis: str
    recommendations: List[str]
    tool_suggestions: List[Dict[str, Any]]
    confidence: float
    processing_time: float = 0.0
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}

@dataclass
class ProcessingResult:
    """è™•ç†çµæœæ•¸æ“šçµæ§‹"""
    request_id: str
    success: bool
    stage_results: Dict[str, Any]
    expert_analysis: List[ExpertResponse]
    tool_execution_results: List[Dict[str, Any]]
    final_answer: str
    confidence: float
    execution_time: float
    metadata: Dict[str, Any]
    timestamp: float = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = time.time()

class IntegratedCloudSearch:
    """æ•´åˆå¼Cloud Searchå¼•æ“"""
    
    def __init__(self):
        self.mock_mode = True  # é–‹ç™¼éšæ®µä½¿ç”¨æ¨¡æ“¬æ¨¡å¼
    
    async def integrated_search(self, params: Dict) -> Dict:
        """æ•´åˆå¼æœç´¢ - ä¸€æ¬¡æœç´¢è§£æ±ºå¤šå€‹ç›®æ¨™"""
        primary_query = params["primary_query"]
        context = params.get("context", {})
        objectives = params.get("search_objectives", [])
        
        logger.info(f"ğŸ” åŸ·è¡Œæ•´åˆå¼æœç´¢: {primary_query}")
        
        if self.mock_mode:
            return await self._mock_integrated_search(primary_query, context, objectives)
        else:
            return await self._real_integrated_search(primary_query, context, objectives)
    
    async def _mock_integrated_search(self, query: str, context: Dict, objectives: List[str]) -> Dict:
        """æ¨¡æ“¬æ•´åˆå¼æœç´¢"""
        
        # æ¨¡æ“¬èƒŒæ™¯ä¿¡æ¯æœç´¢çµæœ
        background_results = {
            "documents": [
                f"ç›¸é—œæ–‡æª”1: {query} çš„æŠ€è¡“å¯¦ç¾æŒ‡å—",
                f"ç›¸é—œæ–‡æª”2: {query} çš„æœ€ä½³å¯¦è¸",
                f"ç›¸é—œæ–‡æª”3: {query} çš„æ¡ˆä¾‹ç ”ç©¶"
            ],
            "context_enrichment": {
                "technologies": self._extract_technologies(query),
                "domains": self._extract_domains(query),
                "complexity": self._assess_complexity(query)
            },
            "relevance_score": 0.85
        }
        
        # æ¨¡æ“¬å°ˆå®¶è­˜åˆ¥çµæœ
        expert_results = {
            "detected_domains": self._detect_expert_domains(query),
            "expert_requirements": self._generate_expert_requirements(query),
            "dynamic_experts_needed": len(self._detect_expert_domains(query)) > 2,
            "complexity_level": self._assess_complexity(query)
        }
        
        # æ¨¡æ“¬å ´æ™¯åˆ†æçµæœ
        scenario_results = {
            "scenario_type": self._classify_scenario(query),
            "use_cases": self._extract_use_cases(query),
            "patterns": self._extract_patterns(query),
            "recommendations": self._generate_recommendations(query)
        }
        
        return {
            "background": background_results,
            "experts": expert_results,
            "scenario": scenario_results,
            "metadata": {
                "search_time": time.time(),
                "objectives_completed": len(objectives),
                "total_results": 15
            }
        }
    
    def _extract_technologies(self, query: str) -> List[str]:
        """æå–æŠ€è¡“é—œéµè©"""
        tech_keywords = {
            "python": ["python", "django", "flask", "fastapi"],
            "javascript": ["javascript", "react", "vue", "node"],
            "testing": ["test", "pytest", "selenium", "cypress"],
            "deployment": ["deploy", "docker", "kubernetes", "ci/cd"],
            "database": ["database", "sql", "mongodb", "redis"]
        }
        
        detected = []
        query_lower = query.lower()
        
        for tech, keywords in tech_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                detected.append(tech)
        
        return detected
    
    def _extract_domains(self, query: str) -> List[str]:
        """æå–æ¥­å‹™é ˜åŸŸ"""
        domain_keywords = {
            "web_development": ["web", "website", "frontend", "backend"],
            "data_analysis": ["data", "analysis", "analytics", "visualization"],
            "testing": ["test", "qa", "quality", "automation"],
            "deployment": ["deploy", "devops", "infrastructure", "production"],
            "security": ["security", "auth", "encryption", "vulnerability"]
        }
        
        detected = []
        query_lower = query.lower()
        
        for domain, keywords in domain_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                detected.append(domain)
        
        return detected
    
    def _assess_complexity(self, query: str) -> str:
        """è©•ä¼°è¤‡é›œåº¦"""
        complexity_indicators = {
            "HIGH": ["enterprise", "large scale", "distributed", "microservice", "complex"],
            "MEDIUM": ["integration", "multiple", "several", "moderate"],
            "LOW": ["simple", "basic", "single", "straightforward"]
        }
        
        query_lower = query.lower()
        
        for level, indicators in complexity_indicators.items():
            if any(indicator in query_lower for indicator in indicators):
                return level
        
        return "MEDIUM"
    
    def _detect_expert_domains(self, query: str) -> List[str]:
        """æª¢æ¸¬éœ€è¦çš„å°ˆå®¶é ˜åŸŸ"""
        expert_patterns = {
            "testing": ["test", "qa", "quality assurance", "automation", "bug"],
            "deployment": ["deploy", "devops", "ci/cd", "infrastructure", "production"],
            "coding": ["code", "programming", "development", "implement"],
            "debugging": ["debug", "error", "exception", "troubleshoot"],
            "architecture": ["architecture", "design", "system design", "scalability"],
            "performance": ["performance", "optimization", "speed", "latency"],
            "security": ["security", "authentication", "encryption", "vulnerability"],
            "data_analysis": ["data", "analysis", "analytics", "visualization"],
            "integration": ["integration", "api", "interface", "connector"],
            "monitoring": ["monitoring", "logging", "observability", "metrics"]
        }
        
        detected = []
        query_lower = query.lower()
        
        for domain, patterns in expert_patterns.items():
            if any(pattern in query_lower for pattern in patterns):
                detected.append(domain)
        
        return detected or ["coding"]  # é»˜èªéœ€è¦ç·¨ç¨‹å°ˆå®¶
    
    def _generate_expert_requirements(self, query: str) -> List[Dict]:
        """ç”Ÿæˆå°ˆå®¶éœ€æ±‚"""
        domains = self._detect_expert_domains(query)
        technologies = self._extract_technologies(query)
        complexity = self._assess_complexity(query)
        
        requirements = []
        
        for domain in domains:
            requirement = {
                "domain": domain,
                "scenario_type": self._map_domain_to_scenario(domain),
                "skill_level": self._determine_skill_level(complexity),
                "specific_skills": self._get_domain_skills(domain, technologies),
                "priority": self._calculate_domain_priority(domain),
                "knowledge_sources": [
                    {"type": "search_result", "content": f"{domain} best practices for {query}"},
                    {"type": "documentation", "content": f"{domain} implementation guide"},
                    {"type": "example", "content": f"{domain} code examples"}
                ]
            }
            requirements.append(requirement)
        
        return requirements
    
    def _map_domain_to_scenario(self, domain: str) -> str:
        """å°‡é ˜åŸŸæ˜ å°„åˆ°å ´æ™¯é¡å‹"""
        mapping = {
            "testing": "TESTING",
            "deployment": "DEPLOYMENT",
            "coding": "CODING",
            "debugging": "DEBUGGING",
            "architecture": "ARCHITECTURE",
            "performance": "PERFORMANCE",
            "security": "SECURITY",
            "data_analysis": "DATA_ANALYSIS",
            "integration": "INTEGRATION",
            "monitoring": "MONITORING"
        }
        return mapping.get(domain, "GENERAL")
    
    def _determine_skill_level(self, complexity: str) -> str:
        """ç¢ºå®šæŠ€èƒ½ç­‰ç´š"""
        mapping = {
            "HIGH": "expert",
            "MEDIUM": "advanced",
            "LOW": "intermediate"
        }
        return mapping.get(complexity, "intermediate")
    
    def _get_domain_skills(self, domain: str, technologies: List[str]) -> List[str]:
        """ç²å–é ˜åŸŸæŠ€èƒ½"""
        base_skills = {
            "testing": ["unit_testing", "integration_testing", "test_automation"],
            "deployment": ["ci_cd", "containerization", "infrastructure_as_code"],
            "coding": ["clean_code", "design_patterns", "algorithms"],
            "debugging": ["troubleshooting", "log_analysis", "performance_profiling"],
            "architecture": ["system_design", "scalability", "microservices"],
            "performance": ["optimization", "caching", "load_testing"],
            "security": ["authentication", "authorization", "encryption"],
            "data_analysis": ["data_processing", "visualization", "statistics"],
            "integration": ["api_design", "message_queues", "webhooks"],
            "monitoring": ["logging", "metrics", "alerting"]
        }
        
        skills = base_skills.get(domain, ["general"])
        skills.extend(technologies)  # æ·»åŠ æŠ€è¡“ç›¸é—œæŠ€èƒ½
        
        return skills
    
    def _calculate_domain_priority(self, domain: str) -> int:
        """è¨ˆç®—é ˜åŸŸå„ªå…ˆç´š"""
        priority_map = {
            "security": 10,
            "performance": 9,
            "testing": 8,
            "deployment": 8,
            "architecture": 7,
            "coding": 7,
            "debugging": 6,
            "integration": 6,
            "data_analysis": 5,
            "monitoring": 5
        }
        return priority_map.get(domain, 5)
    
    def _classify_scenario(self, query: str) -> str:
        """åˆ†é¡å ´æ™¯é¡å‹"""
        domains = self._detect_expert_domains(query)
        if domains:
            return self._map_domain_to_scenario(domains[0])
        return "GENERAL"
    
    def _extract_use_cases(self, query: str) -> List[str]:
        """æå–ä½¿ç”¨æ¡ˆä¾‹"""
        return [
            f"Use case 1: {query} implementation",
            f"Use case 2: {query} optimization",
            f"Use case 3: {query} troubleshooting"
        ]
    
    def _extract_patterns(self, query: str) -> List[str]:
        """æå–æ¨¡å¼"""
        return [
            f"Pattern 1: Standard {query} approach",
            f"Pattern 2: Advanced {query} techniques"
        ]
    
    def _generate_recommendations(self, query: str) -> List[str]:
        """ç”Ÿæˆå»ºè­°"""
        return [
            f"å»ºè­°1: éµå¾ª {query} æœ€ä½³å¯¦è¸",
            f"å»ºè­°2: è€ƒæ…® {query} çš„æ€§èƒ½å„ªåŒ–",
            f"å»ºè­°3: å¯¦æ–½ {query} çš„å®‰å…¨æªæ–½"
        ]

class AICore3:
    """AICore 3.0 - å‹•æ…‹å°ˆå®¶ç³»çµ±æ•´åˆç‰ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–AICore 3.0"""
        logger.info("ğŸš€ åˆå§‹åŒ–AICore 3.0 - å‹•æ…‹å°ˆå®¶ç³»çµ±")
        
        # æ ¸å¿ƒçµ„ä»¶
        self.general_processor = create_general_processor_mcp()
        self.dynamic_expert_registry = create_dynamic_expert_registry()
        self.expert_aggregator = create_expert_recommendation_aggregator()
        self.dynamic_mcp_generator = create_dynamic_mcp_generator()
        self.integrated_search = IntegratedCloudSearch()
        
        # å·¥å…·å’ŒåŸ·è¡Œå™¨
        self.tool_registry = ToolRegistry()
        self.action_executor = ActionExecutor()
        
        # Smartinvention Adapter MCP
        from components.smartinvention_adapter_mcp import SmartinventionAdapterMCP
        self.smartinvention_adapter = None  # å»¶é²åˆå§‹åŒ–
        
        # çµ±è¨ˆå’Œç›£æ§
        self.stage_statistics = {}
        self.expert_usage_stats = {}
        self.performance_metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "average_response_time": 0.0,
            "expert_hit_rate": 0.0,
            "dynamic_tools_generated": 0
        }
        
        logger.info("ğŸš€ AICore 3.0 åˆå§‹åŒ–å®Œæˆ - å‹•æ…‹å°ˆå®¶ç³»çµ±å·²å•Ÿç”¨")    
    async def initialize(self):
        """åˆå§‹åŒ–AICore 3.0"""
        logger.info("ğŸ”§ åˆå§‹åŒ–AICore 3.0çµ„ä»¶...")
        
        try:
            # åˆå§‹åŒ–å·¥å…·è¨»å†Šè¡¨
            await self.tool_registry.initialize()
            
            # åˆå§‹åŒ–å‹•æ…‹å°ˆå®¶è¨»å†Šä¸­å¿ƒ
            await self.dynamic_expert_registry.initialize()
            
            # åˆå§‹åŒ–Smartinvention Adapter MCP
            if self.smartinvention_adapter is None:
                from components.smartinvention_adapter_mcp import SmartinventionAdapterMCP
                smartinvention_config = {
                    'data_dir': '/tmp/smartinvention_data',
                    'sync_interval': 30,
                    'max_retries': 3,
                    'local_endpoint': 'http://localhost:8000',
                    'cloud_endpoint': 'http://18.212.97.173:8000'
                }
                self.smartinvention_adapter = SmartinventionAdapterMCP(smartinvention_config)
                await self.smartinvention_adapter.initialize()
                logger.info("âœ… Smartinvention Adapter MCP åˆå§‹åŒ–å®Œæˆ")
            
            # åˆå§‹åŒ–çµ±è¨ˆ
            for stage in ProcessingStage:
                self.stage_statistics[stage.value] = {
                    "count": 0,
                    "total_time": 0.0,
                    "average_time": 0.0,
                    "success_rate": 0.0
                }
            
            logger.info("âœ… AICore 3.0 åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ AICore 3.0 åˆå§‹åŒ–å¤±æ•—: {e}")
            raise
    
    async def process_request(self, request: UserRequest) -> ProcessingResult:
        """è™•ç†ç”¨æˆ¶è«‹æ±‚ - 5éšæ®µå‹•æ…‹å°ˆå®¶æµç¨‹"""
        start_time = time.time()
        stage_results = {}
        
        logger.info(f"ğŸ¯ é–‹å§‹è™•ç†è«‹æ±‚: {request.id}")
        
        try:
            # éšæ®µ1: æ•´åˆå¼æœç´¢å’Œåˆ†æ
            stage_results['integrated_search'] = await self._stage1_integrated_search_and_analysis(request)
            
            # éšæ®µ2: å‹•æ…‹å°ˆå®¶ç”Ÿæˆ
            stage_results['dynamic_expert_generation'] = await self._stage2_dynamic_expert_generation(
                request, stage_results['integrated_search']
            )
            
            # éšæ®µ3: å°ˆå®¶å›ç­”ç”Ÿæˆ (ä¸¦è¡Œ)
            stage_results['expert_response_generation'] = await self._stage3_expert_response_generation(
                request, stage_results['dynamic_expert_generation']['selected_experts']
            )
            
            # éšæ®µ4: æ™ºèƒ½å·¥å…·åŸ·è¡Œ
            stage_results['intelligent_tool_execution'] = await self._stage4_intelligent_tool_execution(
                request, stage_results['expert_response_generation']['expert_responses']
            )
            
            # éšæ®µ5: æœ€çµ‚çµæœç”Ÿæˆ
            final_result = await self._stage5_final_result_generation(
                request, stage_results, start_time
            )
            
            # æ›´æ–°çµ±è¨ˆ
            await self._update_execution_stats(final_result, stage_results)
            
            logger.info(f"âœ… è«‹æ±‚è™•ç†å®Œæˆ: {request.id}, è€—æ™‚: {final_result.execution_time:.2f}s")
            return final_result
            
        except Exception as e:
            execution_time = time.time() - start_time
            logger.error(f"âŒ è«‹æ±‚è™•ç†å¤±æ•—: {request.id}, éŒ¯èª¤: {e}")
            
            return ProcessingResult(
                request_id=request.id,
                success=False,
                stage_results=stage_results,
                expert_analysis=[],
                tool_execution_results=[],
                final_answer=f"è™•ç†å¤±æ•—: {str(e)}",
                confidence=0.0,
                execution_time=execution_time,
                metadata={"error": str(e), "failed_stage": len(stage_results)}
            )
    
    async def _stage1_integrated_search_and_analysis(self, request: UserRequest) -> Dict[str, Any]:
        """éšæ®µ1: æ•´åˆå¼æœç´¢å’Œåˆ†æ"""
        stage_start = time.time()
        logger.info(f"ğŸ” éšæ®µ1: æ•´åˆå¼æœç´¢å’Œåˆ†æ - {request.id}")
        
        # åŸ·è¡Œæ•´åˆå¼æœç´¢
        search_result = await self.integrated_search.integrated_search({
            "primary_query": request.content,
            "context": request.context,
            "search_objectives": [
                "background_information",
                "expert_identification",
                "scenario_analysis"
            ]
        })
        
        stage_time = time.time() - stage_start
        await self._update_stage_stats(ProcessingStage.INTEGRATED_SEARCH_ANALYSIS, stage_time)
        
        logger.info(f"ğŸ“Š æœç´¢å®Œæˆï¼Œç™¼ç¾ {len(search_result['experts']['detected_domains'])} å€‹å°ˆå®¶é ˜åŸŸ")
        
        return {
            "background_info": search_result["background"],
            "expert_analysis": search_result["experts"],
            "scenario_context": search_result["scenario"],
            "search_metadata": search_result["metadata"],
            "stage_execution_time": stage_time
        }
    
    async def _stage2_dynamic_expert_generation(self, request: UserRequest, 
                                              search_results: Dict[str, Any]) -> Dict[str, Any]:
        """éšæ®µ2: å‹•æ…‹å°ˆå®¶ç”Ÿæˆ"""
        stage_start = time.time()
        logger.info(f"ğŸ§  éšæ®µ2: å‹•æ…‹å°ˆå®¶ç”Ÿæˆ - {request.id}")
        
        expert_analysis = search_results["expert_analysis"]
        scenario_context = search_results["scenario_context"]
        
        # ç²å–ç¾æœ‰å°ˆå®¶
        existing_experts = await self.dynamic_expert_registry.find_experts_for_scenario({
            "type": scenario_context["scenario_type"],
            "domains": expert_analysis["detected_domains"],
            "complexity": expert_analysis["complexity_level"]
        })
        
        # è¨»å†Šæ–°çš„å‹•æ…‹å°ˆå®¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
        new_experts = []
        if expert_analysis.get("dynamic_experts_needed", False):
            for requirement in expert_analysis["expert_requirements"]:
                try:
                    registration_request = ExpertRegistrationRequest(
                        domain=requirement["domain"],
                        scenario_type=requirement["scenario_type"],
                        skill_requirements=requirement["specific_skills"],
                        knowledge_sources=requirement["knowledge_sources"],
                        priority=requirement["priority"],
                        context=request.context,
                        requester=f"request_{request.id}"
                    )
                    
                    # æª¢æŸ¥æ˜¯å¦å·²æœ‰é¡ä¼¼å°ˆå®¶
                    similar_expert = await self.dynamic_expert_registry._find_similar_expert(registration_request)
                    if not similar_expert:
                        new_expert = await self.dynamic_expert_registry.register_dynamic_expert(registration_request)
                        new_experts.append(new_expert)
                        logger.info(f"âœ¨ å‰µå»ºæ–°å°ˆå®¶: {new_expert.name}")
                    else:
                        logger.info(f"ğŸ”„ ä½¿ç”¨ç¾æœ‰å°ˆå®¶: {similar_expert.name}")
                        
                except Exception as e:
                    logger.warning(f"âš ï¸ å°ˆå®¶å‰µå»ºå¤±æ•—: {requirement['domain']}, éŒ¯èª¤: {e}")
        
        # é¸æ“‡æœ€çµ‚å°ˆå®¶çµ„åˆ
        all_experts = existing_experts + new_experts
        selected_experts = await self._select_optimal_expert_combination(
            all_experts, expert_analysis, scenario_context
        )
        
        stage_time = time.time() - stage_start
        await self._update_stage_stats(ProcessingStage.DYNAMIC_EXPERT_GENERATION, stage_time)
        
        logger.info(f"ğŸ‘¥ å°ˆå®¶é¸æ“‡å®Œæˆï¼Œå…±é¸ä¸­ {len(selected_experts)} ä½å°ˆå®¶")
        
        return {
            "existing_experts": len(existing_experts),
            "new_experts": len(new_experts),
            "selected_experts": selected_experts,
            "expert_selection_reasoning": self._generate_selection_reasoning(selected_experts),
            "stage_execution_time": stage_time
        }
    
    async def _stage3_expert_response_generation(self, request: UserRequest, 
                                               selected_experts: List[ExpertProfile]) -> Dict[str, Any]:
        """éšæ®µ3: å°ˆå®¶å›ç­”ç”Ÿæˆ (ä¸¦è¡Œ)"""
        stage_start = time.time()
        logger.info(f"ğŸ­ éšæ®µ3: å°ˆå®¶å›ç­”ç”Ÿæˆ - {request.id}")
        
        # ä¸¦è¡Œç”Ÿæˆå°ˆå®¶å›ç­”
        expert_tasks = []
        for expert in selected_experts:
            task = asyncio.create_task(
                self._generate_expert_response(expert, request)
            )
            expert_tasks.append(task)
        
        # ç­‰å¾…æ‰€æœ‰å°ˆå®¶å›ç­”å®Œæˆ
        expert_responses = []
        for i, task in enumerate(expert_tasks):
            try:
                response = await task
                expert_responses.append(response)
                logger.info(f"âœ… å°ˆå®¶ {selected_experts[i].name} å›ç­”å®Œæˆ")
            except Exception as e:
                logger.error(f"âŒ å°ˆå®¶ {selected_experts[i].name} å›ç­”å¤±æ•—: {e}")
                # å‰µå»ºéŒ¯èª¤å›ç­”
                error_response = ExpertResponse(
                    expert_id=selected_experts[i].id,
                    expert_name=selected_experts[i].name,
                    expert_type=selected_experts[i].type.value,
                    analysis=f"å°ˆå®¶å›ç­”ç”Ÿæˆå¤±æ•—: {str(e)}",
                    recommendations=[],
                    tool_suggestions=[],
                    confidence=0.0,
                    metadata={"error": str(e)}
                )
                expert_responses.append(error_response)
        
        # æ›´æ–°å°ˆå®¶ä½¿ç”¨çµ±è¨ˆ
        for expert in selected_experts:
            await self._update_expert_usage_stats(expert.id)
        
        stage_time = time.time() - stage_start
        await self._update_stage_stats(ProcessingStage.EXPERT_RESPONSE_GENERATION, stage_time)
        
        logger.info(f"ğŸ“ å°ˆå®¶å›ç­”ç”Ÿæˆå®Œæˆï¼Œå…± {len(expert_responses)} å€‹å›ç­”")
        
        return {
            "expert_responses": expert_responses,
            "parallel_execution_time": stage_time,
            "expert_count": len(selected_experts),
            "success_rate": len([r for r in expert_responses if r.confidence > 0]) / len(expert_responses)
        }
    
    async def _stage4_intelligent_tool_execution(self, request: UserRequest, 
                                                expert_responses: List[ExpertResponse]) -> Dict[str, Any]:
        """éšæ®µ4: æ™ºèƒ½å·¥å…·åŸ·è¡Œ"""
        stage_start = time.time()
        logger.info(f"ğŸ› ï¸ éšæ®µ4: æ™ºèƒ½å·¥å…·åŸ·è¡Œ - {request.id}")
        
        # æ”¶é›†æ‰€æœ‰å°ˆå®¶çš„å·¥å…·å»ºè­°
        all_tool_suggestions = []
        for response in expert_responses:
            all_tool_suggestions.extend(response.tool_suggestions)
        
        # æ™ºèƒ½é¸æ“‡å·¥å…·
        selected_tools = await self._intelligent_tool_selection(all_tool_suggestions, request)
        
        # åŸ·è¡Œé¸ä¸­çš„å·¥å…·
        tool_execution_results = []
        for tool_suggestion in selected_tools:
            try:
                result = await self._execute_tool(tool_suggestion, request)
                tool_execution_results.append(result)
                logger.info(f"ğŸ”§ å·¥å…·åŸ·è¡Œå®Œæˆ: {tool_suggestion['tool_name']}")
            except Exception as e:
                logger.error(f"âŒ å·¥å…·åŸ·è¡Œå¤±æ•—: {tool_suggestion['tool_name']}, éŒ¯èª¤: {e}")
                tool_execution_results.append({
                    "tool_name": tool_suggestion['tool_name'],
                    "success": False,
                    "error": str(e),
                    "result": None
                })
        
        stage_time = time.time() - stage_start
        await self._update_stage_stats(ProcessingStage.INTELLIGENT_TOOL_EXECUTION, stage_time)
        
        logger.info(f"âš™ï¸ å·¥å…·åŸ·è¡Œå®Œæˆï¼Œå…±åŸ·è¡Œ {len(tool_execution_results)} å€‹å·¥å…·")
        
        return {
            "tool_suggestions": all_tool_suggestions,
            "selected_tools": selected_tools,
            "execution_results": tool_execution_results,
            "stage_execution_time": stage_time,
            "tool_success_rate": len([r for r in tool_execution_results if r.get("success", False)]) / len(tool_execution_results) if tool_execution_results else 0
        }
    
    async def _stage5_final_result_generation(self, request: UserRequest, 
                                            stage_results: Dict[str, Any], 
                                            start_time: float) -> ProcessingResult:
        """éšæ®µ5: æœ€çµ‚çµæœç”Ÿæˆ"""
        stage_start = time.time()
        logger.info(f"ğŸ“‹ éšæ®µ5: æœ€çµ‚çµæœç”Ÿæˆ - {request.id}")
        
        # èšåˆæ‰€æœ‰å°ˆå®¶åˆ†æ
        expert_responses = stage_results['expert_response_generation']['expert_responses']
        tool_results = stage_results['intelligent_tool_execution']['execution_results']
        
        # ç”Ÿæˆç¶œåˆåˆ†æ
        comprehensive_analysis = await self._generate_comprehensive_analysis(
            expert_responses, tool_results, request
        )
        
        # è¨ˆç®—æ•´é«”ä¿¡å¿ƒåº¦
        overall_confidence = await self._calculate_overall_confidence(
            expert_responses, tool_results, stage_results
        )
        
        # ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ
        final_answer = await self._generate_final_answer(
            comprehensive_analysis, expert_responses, tool_results
        )
        
        execution_time = time.time() - start_time
        stage_time = time.time() - stage_start
        await self._update_stage_stats(ProcessingStage.FINAL_RESULT_GENERATION, stage_time)
        
        logger.info(f"ğŸ‰ æœ€çµ‚çµæœç”Ÿæˆå®Œæˆï¼Œä¿¡å¿ƒåº¦: {overall_confidence:.2f}")
        
        return ProcessingResult(
            request_id=request.id,
            success=True,
            stage_results=stage_results,
            expert_analysis=expert_responses,
            tool_execution_results=tool_results,
            final_answer=final_answer,
            confidence=overall_confidence,
            execution_time=execution_time,
            metadata={
                "comprehensive_analysis": comprehensive_analysis,
                "stage_count": len(stage_results),
                "expert_count": len(expert_responses),
                "tool_count": len(tool_results),
                "processing_stages": list(stage_results.keys())
            }
        )
    
    # è¼”åŠ©æ–¹æ³•
    async def _select_optimal_expert_combination(self, experts: List[ExpertProfile], 
                                               expert_analysis: Dict, 
                                               scenario_context: Dict) -> List[ExpertProfile]:
        """é¸æ“‡æœ€å„ªå°ˆå®¶çµ„åˆ"""
        if not experts:
            return []
        
        # æŒ‰æ€§èƒ½å’Œç›¸é—œæ€§æ’åº
        scored_experts = []
        for expert in experts:
            score = await self._calculate_expert_score(expert, expert_analysis, scenario_context)
            scored_experts.append((expert, score))
        
        # æ’åºä¸¦é¸æ“‡å‰Nå€‹
        scored_experts.sort(key=lambda x: x[1], reverse=True)
        
        # æ ¹æ“šè¤‡é›œåº¦ç¢ºå®šå°ˆå®¶æ•¸é‡
        max_experts = {
            "LOW": 2,
            "MEDIUM": 3,
            "HIGH": 4,
            "CRITICAL": 5
        }.get(expert_analysis.get("complexity_level", "MEDIUM"), 3)
        
        selected = [expert for expert, score in scored_experts[:max_experts]]
        return selected
    
    async def _calculate_expert_score(self, expert: ExpertProfile, 
                                    expert_analysis: Dict, 
                                    scenario_context: Dict) -> float:
        """è¨ˆç®—å°ˆå®¶åˆ†æ•¸"""
        score = 0.0
        
        # æ€§èƒ½åˆ†æ•¸ (40%)
        performance_score = (
            expert.performance_metrics.get("success_rate", 0.8) * 0.4 +
            expert.performance_metrics.get("accuracy", 0.8) * 0.3 +
            expert.performance_metrics.get("user_satisfaction", 0.8) * 0.3
        )
        score += performance_score * 0.4
        
        # é ˜åŸŸåŒ¹é…åˆ†æ•¸ (30%)
        domain_match = 0.0
        for domain in expert_analysis.get("detected_domains", []):
            if domain in expert.specializations:
                domain_match += 1.0
        domain_score = min(1.0, domain_match / len(expert_analysis.get("detected_domains", [1])))
        score += domain_score * 0.3
        
        # èƒ½åŠ›åŒ¹é…åˆ†æ•¸ (20%)
        capability_match = 0.0
        expert_capabilities = [cap.name for cap in expert.capabilities]
        for req in expert_analysis.get("expert_requirements", []):
            for skill in req.get("specific_skills", []):
                if skill in expert_capabilities:
                    capability_match += 1.0
        
        total_required_skills = sum(len(req.get("specific_skills", [])) for req in expert_analysis.get("expert_requirements", []))
        capability_score = min(1.0, capability_match / max(1, total_required_skills))
        score += capability_score * 0.2
        
        # ä½¿ç”¨é »ç‡åˆ†æ•¸ (10%)
        usage_count = expert.performance_metrics.get("usage_count", 0)
        usage_score = min(1.0, usage_count / 100.0)  # 100æ¬¡ä½¿ç”¨ç‚ºæ»¿åˆ†
        score += usage_score * 0.1
        
        return score
    
    def _generate_selection_reasoning(self, experts: List[ExpertProfile]) -> str:
        """ç”Ÿæˆå°ˆå®¶é¸æ“‡ç†ç”±"""
        if not experts:
            return "æœªæ‰¾åˆ°åˆé©çš„å°ˆå®¶"
        
        reasoning = f"é¸æ“‡äº† {len(experts)} ä½å°ˆå®¶ï¼š\n"
        for expert in experts:
            reasoning += f"- {expert.name}: å°ˆç²¾æ–¼ {', '.join(expert.specializations)}\n"
        
        return reasoning
    
    async def _generate_expert_response(self, expert: ExpertProfile, request: UserRequest) -> ExpertResponse:
        """ç”Ÿæˆå°ˆå®¶å›ç­”"""
        response_start = time.time()
        
        try:
            # åŸºæ–¼å°ˆå®¶çŸ¥è­˜åº«ç”Ÿæˆå›ç­”
            analysis = await self._generate_expert_analysis(expert, request)
            recommendations = await self._generate_expert_recommendations(expert, request)
            tool_suggestions = await self._generate_expert_tool_suggestions(expert, request)
            confidence = await self._calculate_expert_confidence(expert, request)
            
            # æ›´æ–°å°ˆå®¶æ€§èƒ½
            performance_data = {
                "success": True,
                "response_time": time.time() - response_start,
                "context": {"request_id": request.id}
            }
            await self.dynamic_expert_registry.update_expert_performance(expert.id, performance_data)
            
            return ExpertResponse(
                expert_id=expert.id,
                expert_name=expert.name,
                expert_type=expert.type.value,
                analysis=analysis,
                recommendations=recommendations,
                tool_suggestions=tool_suggestions,
                confidence=confidence,
                processing_time=time.time() - response_start,
                metadata={
                    "expert_specializations": expert.specializations,
                    "capability_count": len(expert.capabilities)
                }
            )
            
        except Exception as e:
            # æ›´æ–°å¤±æ•—æ€§èƒ½
            performance_data = {
                "success": False,
                "response_time": time.time() - response_start,
                "error": str(e),
                "context": {"request_id": request.id}
            }
            await self.dynamic_expert_registry.update_expert_performance(expert.id, performance_data)
            raise
    
    async def _generate_expert_analysis(self, expert: ExpertProfile, request: UserRequest) -> str:
        """ç”Ÿæˆå°ˆå®¶åˆ†æ"""
        # åŸºæ–¼å°ˆå®¶çŸ¥è­˜åº«å’Œèƒ½åŠ›ç”Ÿæˆåˆ†æ
        analysis = f"ä½œç‚º {expert.name}ï¼Œæˆ‘åˆ†æäº†æ‚¨çš„è«‹æ±‚ï¼š{request.content[:100]}...\n\n"
        
        # æ·»åŠ å°ˆæ¥­é ˜åŸŸåˆ†æ
        for specialization in expert.specializations:
            analysis += f"å¾ {specialization} è§’åº¦ä¾†çœ‹ï¼Œ"
            
            # åŸºæ–¼çŸ¥è­˜åº«å…§å®¹
            knowledge_content = expert.knowledge_base.get("content", [])
            if knowledge_content:
                analysis += f"æ ¹æ“šç›¸é—œçŸ¥è­˜å’Œæœ€ä½³å¯¦è¸ï¼Œ{knowledge_content[0][:100]}...\n"
            else:
                analysis += f"å»ºè­°æ¡ç”¨æ¨™æº–çš„ {specialization} æ–¹æ³•ä¾†è§£æ±ºé€™å€‹å•é¡Œã€‚\n"
        
        # æ·»åŠ èƒ½åŠ›ç›¸é—œåˆ†æ
        relevant_capabilities = [cap for cap in expert.capabilities if any(keyword in request.content.lower() for keyword in cap.keywords)]
        if relevant_capabilities:
            analysis += f"\nåŸºæ–¼æˆ‘åœ¨ {', '.join([cap.name for cap in relevant_capabilities])} æ–¹é¢çš„å°ˆæ¥­èƒ½åŠ›ï¼Œ"
            analysis += "æˆ‘å»ºè­°æ¡ç”¨ä»¥ä¸‹æ–¹æ³•ä¾†å¯¦ç¾æ‚¨çš„éœ€æ±‚ã€‚"
        
        return analysis
    
    async def _generate_expert_recommendations(self, expert: ExpertProfile, request: UserRequest) -> List[str]:
        """ç”Ÿæˆå°ˆå®¶å»ºè­°"""
        recommendations = []
        
        # åŸºæ–¼å°ˆå®¶èƒ½åŠ›ç”Ÿæˆå»ºè­°
        for capability in expert.capabilities:
            if any(keyword in request.content.lower() for keyword in capability.keywords):
                recommendations.append(f"å»ºè­°ä½¿ç”¨ {capability.name} ç›¸é—œçš„æœ€ä½³å¯¦è¸")
        
        # åŸºæ–¼å°ˆæ¥­é ˜åŸŸç”Ÿæˆå»ºè­°
        for specialization in expert.specializations:
            recommendations.append(f"å¾ {specialization} è§’åº¦ï¼Œå»ºè­°é€²è¡Œè©³ç´°çš„éœ€æ±‚åˆ†æ")
        
        # åŸºæ–¼çŸ¥è­˜åº«ç”Ÿæˆå»ºè­°
        best_practices = expert.knowledge_base.get("best_practices", [])
        for practice in best_practices[:2]:  # æœ€å¤š2å€‹æœ€ä½³å¯¦è¸
            recommendations.append(practice)
        
        return recommendations[:5]  # æœ€å¤š5å€‹å»ºè­°
    
    async def _generate_expert_tool_suggestions(self, expert: ExpertProfile, request: UserRequest) -> List[Dict[str, Any]]:
        """ç”Ÿæˆå°ˆå®¶å·¥å…·å»ºè­°"""
        suggestions = []
        
        # åŸºæ–¼å°ˆå®¶é¡å‹æ¨è–¦å·¥å…·
        if expert.type == DynamicExpertType.DYNAMIC_EXPERT:
            # å‹•æ…‹å°ˆå®¶æ¨è–¦General Processor
            suggestions.append({
                "tool_name": "general_processor_mcp",
                "mode": "auto",
                "reason": f"éœ€è¦ {expert.name} çš„å°ˆæ¥­è™•ç†",
                "priority": "high",
                "confidence": expert.performance_metrics.get("success_rate", 0.8)
            })
        
        # åŸºæ–¼å°ˆæ¥­é ˜åŸŸæ¨è–¦å·¥å…·
        for specialization in expert.specializations:
            if specialization == "testing":
                suggestions.append({
                    "tool_name": "test_flow_mcp",
                    "reason": "éœ€è¦æ¸¬è©¦ç›¸é—œåŠŸèƒ½",
                    "priority": "medium"
                })
            elif specialization in ["monitoring", "system"]:
                suggestions.append({
                    "tool_name": "system_monitor_adapter_mcp",
                    "reason": "éœ€è¦ç³»çµ±ç›£æ§åŠŸèƒ½",
                    "priority": "medium"
                })
        
        return suggestions
    
    async def _calculate_expert_confidence(self, expert: ExpertProfile, request: UserRequest) -> float:
        """è¨ˆç®—å°ˆå®¶ä¿¡å¿ƒåº¦"""
        confidence = expert.performance_metrics.get("success_rate", 0.8)
        
        # åŸºæ–¼èƒ½åŠ›åŒ¹é…èª¿æ•´ä¿¡å¿ƒåº¦
        matching_capabilities = 0
        for capability in expert.capabilities:
            if any(keyword in request.content.lower() for keyword in capability.keywords):
                matching_capabilities += 1
                confidence += capability.confidence * 0.1
        
        # åŸºæ–¼çŸ¥è­˜åº«è±å¯Œåº¦èª¿æ•´
        knowledge_richness = len(expert.knowledge_base.get("content", []))
        confidence += min(0.1, knowledge_richness * 0.02)
        
        return min(0.95, confidence)
    
    async def _intelligent_tool_selection(self, tool_suggestions: List[Dict], request: UserRequest) -> List[Dict]:
        """æ™ºèƒ½å·¥å…·é¸æ“‡"""
        if not tool_suggestions:
            return []
        
        # æŒ‰å„ªå…ˆç´šå’Œä¿¡å¿ƒåº¦æ’åº
        def tool_score(suggestion):
            priority_score = {"high": 3, "medium": 2, "low": 1}.get(suggestion.get("priority", "medium"), 2)
            confidence_score = suggestion.get("confidence", 0.8)
            return priority_score + confidence_score
        
        sorted_suggestions = sorted(tool_suggestions, key=tool_score, reverse=True)
        
        # å»é‡ï¼ˆç›¸åŒå·¥å…·åªé¸ä¸€å€‹ï¼‰
        selected_tools = []
        used_tools = set()
        
        for suggestion in sorted_suggestions:
            tool_name = suggestion["tool_name"]
            if tool_name not in used_tools:
                selected_tools.append(suggestion)
                used_tools.add(tool_name)
        
        return selected_tools[:3]  # æœ€å¤šé¸æ“‡3å€‹å·¥å…·
    
    async def _execute_tool(self, tool_suggestion: Dict, request: UserRequest) -> Dict:
        """åŸ·è¡Œå·¥å…·"""
        tool_name = tool_suggestion["tool_name"]
        
        try:
            if tool_name == "general_processor_mcp":
                mode = tool_suggestion.get("mode", "auto")
                result = await self.general_processor.process(request.content, mode=mode)
                return {
                    "tool_name": tool_name,
                    "success": True,
                    "result": result,
                    "mode": mode
                }
            else:
                # å…¶ä»–å·¥å…·é€šéaction_executoråŸ·è¡Œ
                result = await self.action_executor.execute_action({
                    "tool_name": tool_name,
                    "parameters": {"content": request.content}
                })
                return {
                    "tool_name": tool_name,
                    "success": True,
                    "result": result
                }
                
        except Exception as e:
            return {
                "tool_name": tool_name,
                "success": False,
                "error": str(e),
                "result": None
            }
    
    async def _generate_comprehensive_analysis(self, expert_responses: List[ExpertResponse], 
                                             tool_results: List[Dict], 
                                             request: UserRequest) -> str:
        """ç”Ÿæˆç¶œåˆåˆ†æ"""
        analysis = f"åŸºæ–¼ {len(expert_responses)} ä½å°ˆå®¶çš„åˆ†æå’Œ {len(tool_results)} å€‹å·¥å…·çš„åŸ·è¡Œçµæœï¼š\n\n"
        
        # å°ˆå®¶åˆ†ææ‘˜è¦
        analysis += "## å°ˆå®¶åˆ†ææ‘˜è¦\n"
        for response in expert_responses:
            analysis += f"**{response.expert_name}** (ä¿¡å¿ƒåº¦: {response.confidence:.2f}):\n"
            analysis += f"{response.analysis[:200]}...\n\n"
        
        # å·¥å…·åŸ·è¡Œæ‘˜è¦
        if tool_results:
            analysis += "## å·¥å…·åŸ·è¡Œçµæœ\n"
            for result in tool_results:
                status = "âœ… æˆåŠŸ" if result.get("success", False) else "âŒ å¤±æ•—"
                analysis += f"- {result['tool_name']}: {status}\n"
        
        return analysis
    
    async def _calculate_overall_confidence(self, expert_responses: List[ExpertResponse], 
                                          tool_results: List[Dict], 
                                          stage_results: Dict) -> float:
        """è¨ˆç®—æ•´é«”ä¿¡å¿ƒåº¦"""
        if not expert_responses:
            return 0.0
        
        # å°ˆå®¶ä¿¡å¿ƒåº¦å¹³å‡å€¼
        expert_confidence = sum(r.confidence for r in expert_responses) / len(expert_responses)
        
        # å·¥å…·æˆåŠŸç‡
        tool_success_rate = 0.0
        if tool_results:
            successful_tools = len([r for r in tool_results if r.get("success", False)])
            tool_success_rate = successful_tools / len(tool_results)
        
        # éšæ®µå®Œæˆåº¦
        stage_completion = len(stage_results) / 5.0  # 5å€‹éšæ®µ
        
        # ç¶œåˆè¨ˆç®—
        overall_confidence = (
            expert_confidence * 0.6 +
            tool_success_rate * 0.3 +
            stage_completion * 0.1
        )
        
        return min(0.95, overall_confidence)
    
    async def _generate_final_answer(self, comprehensive_analysis: str, 
                                   expert_responses: List[ExpertResponse], 
                                   tool_results: List[Dict]) -> str:
        """ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ"""
        answer = "## ç¶œåˆè§£æ±ºæ–¹æ¡ˆ\n\n"
        answer += comprehensive_analysis + "\n"
        
        # æ•´åˆå°ˆå®¶å»ºè­°
        all_recommendations = []
        for response in expert_responses:
            all_recommendations.extend(response.recommendations)
        
        if all_recommendations:
            answer += "## å°ˆå®¶å»ºè­°\n"
            for i, rec in enumerate(all_recommendations[:5], 1):  # æœ€å¤š5å€‹å»ºè­°
                answer += f"{i}. {rec}\n"
        
        # æ·»åŠ å·¥å…·åŸ·è¡Œçµæœ
        successful_tools = [r for r in tool_results if r.get("success", False)]
        if successful_tools:
            answer += "\n## åŸ·è¡Œçµæœ\n"
            for result in successful_tools:
                if result.get("result"):
                    answer += f"- {result['tool_name']}: åŸ·è¡ŒæˆåŠŸ\n"
        
        answer += "\n## ç¸½çµ\n"
        answer += f"åŸºæ–¼ {len(expert_responses)} ä½å°ˆå®¶çš„å°ˆæ¥­åˆ†æï¼Œæˆ‘å€‘ç‚ºæ‚¨æä¾›äº†ä¸Šè¿°ç¶œåˆè§£æ±ºæ–¹æ¡ˆã€‚"
        
        return answer
    
    # çµ±è¨ˆå’Œç›£æ§æ–¹æ³•
    async def _update_stage_stats(self, stage: ProcessingStage, execution_time: float):
        """æ›´æ–°éšæ®µçµ±è¨ˆ"""
        stats = self.stage_statistics[stage.value]
        stats["count"] += 1
        stats["total_time"] += execution_time
        stats["average_time"] = stats["total_time"] / stats["count"]
    
    async def _update_expert_usage_stats(self, expert_id: str):
        """æ›´æ–°å°ˆå®¶ä½¿ç”¨çµ±è¨ˆ"""
        if expert_id not in self.expert_usage_stats:
            self.expert_usage_stats[expert_id] = {"usage_count": 0, "last_used": datetime.now()}
        
        self.expert_usage_stats[expert_id]["usage_count"] += 1
        self.expert_usage_stats[expert_id]["last_used"] = datetime.now()
    
    async def _update_execution_stats(self, result: ProcessingResult, stage_results: Dict):
        """æ›´æ–°åŸ·è¡Œçµ±è¨ˆ"""
        self.performance_metrics["total_requests"] += 1
        
        if result.success:
            self.performance_metrics["successful_requests"] += 1
        
        # æ›´æ–°å¹³å‡éŸ¿æ‡‰æ™‚é–“
        current_avg = self.performance_metrics["average_response_time"]
        total_requests = self.performance_metrics["total_requests"]
        self.performance_metrics["average_response_time"] = (
            (current_avg * (total_requests - 1) + result.execution_time) / total_requests
        )
        
        # æ›´æ–°å°ˆå®¶å‘½ä¸­ç‡
        expert_count = len(result.expert_analysis)
        if expert_count > 0:
            successful_experts = len([e for e in result.expert_analysis if e.confidence > 0.5])
            expert_hit_rate = successful_experts / expert_count
            current_hit_rate = self.performance_metrics["expert_hit_rate"]
            self.performance_metrics["expert_hit_rate"] = (
                (current_hit_rate * (total_requests - 1) + expert_hit_rate) / total_requests
            )
    
    async def get_system_statistics(self) -> Dict[str, Any]:
        """ç²å–ç³»çµ±çµ±è¨ˆä¿¡æ¯"""
        expert_stats = await self.dynamic_expert_registry.get_expert_statistics()
        
        return {
            "performance_metrics": self.performance_metrics,
            "stage_statistics": self.stage_statistics,
            "expert_usage_stats": self.expert_usage_stats,
            "expert_registry_stats": expert_stats,
            "system_health": {
                "total_experts": expert_stats["total_experts"],
                "active_experts": expert_stats["by_status"].get("active", 0),
                "success_rate": self.performance_metrics["successful_requests"] / max(1, self.performance_metrics["total_requests"]),
                "average_response_time": self.performance_metrics["average_response_time"]
            }
        }

# å·¥å» å‡½æ•¸
def create_aicore3() -> AICore3:
    """å‰µå»ºAICore 3.0å¯¦ä¾‹"""
    return AICore3()

# ä½¿ç”¨ç¤ºä¾‹
async def main():
    """ä½¿ç”¨ç¤ºä¾‹"""
    # å‰µå»ºAICore 3.0
    aicore = create_aicore3()
    await aicore.initialize()
    
    # å‰µå»ºæ¸¬è©¦è«‹æ±‚
    request = UserRequest(
        id="test_001",
        content="æˆ‘éœ€è¦ç‚ºæˆ‘çš„Python Webæ‡‰ç”¨å¯¦ç¾è‡ªå‹•åŒ–æ¸¬è©¦ï¼ŒåŒ…æ‹¬å–®å…ƒæ¸¬è©¦å’Œé›†æˆæ¸¬è©¦",
        context={
            "technology": "python",
            "framework": "flask",
            "urgency": "high"
        }
    )
    
    # è™•ç†è«‹æ±‚
    result = await aicore.process_request(request)
    
    # è¼¸å‡ºçµæœ
    print(f"è™•ç†çµæœ: {result.success}")
    print(f"åŸ·è¡Œæ™‚é–“: {result.execution_time:.2f}s")
    print(f"ä¿¡å¿ƒåº¦: {result.confidence:.2f}")
    print(f"å°ˆå®¶æ•¸é‡: {len(result.expert_analysis)}")
    print(f"æœ€çµ‚ç­”æ¡ˆ: {result.final_answer[:200]}...")
    
    # ç²å–ç³»çµ±çµ±è¨ˆ
    stats = await aicore.get_system_statistics()
    print(f"ç³»çµ±çµ±è¨ˆ: {stats['system_health']}")

if __name__ == "__main__":
    asyncio.run(main())


    # Smartinvention Adapter APIç«¯é»è™•ç†æ–¹æ³•
    async def handle_smartinvention_request(self, endpoint: str, request_data: Dict) -> Dict:
        """è™•ç†Smartinventionç›¸é—œè«‹æ±‚ - æ¥æ‰‹åŸEC2ç«¯å£"""
        try:
            if self.smartinvention_adapter is None:
                return {
                    "success": False,
                    "error": "Smartinvention Adapteræœªåˆå§‹åŒ–",
                    "timestamp": datetime.now().isoformat()
                }
            
            # æ ¹æ“šç«¯é»è·¯ç”±åˆ°å°æ‡‰çš„è™•ç†æ–¹æ³•
            if endpoint == "/api/sync/conversations":
                return await self.smartinvention_adapter.process_conversation_sync(request_data)
            
            elif endpoint == "/api/conversations/latest":
                return await self.smartinvention_adapter.get_latest_conversations(request_data)
            
            elif endpoint == "/api/interventions/needed":
                return await self.smartinvention_adapter.get_interventions_needed(request_data)
            
            elif endpoint == "/api/health":
                return await self.smartinvention_adapter.health_check()
            
            elif endpoint == "/api/statistics":
                return await self.smartinvention_adapter.get_statistics()
            
            elif endpoint == "/api/local-models/connect":
                return await self.smartinvention_adapter.connect_local_model(request_data)
            
            elif endpoint == "/api/local-models/query":
                return await self.smartinvention_adapter.query_local_model(request_data)
            
            elif endpoint == "/api/local-models/status":
                return await self.smartinvention_adapter.get_model_status(request_data)
            
            elif endpoint == "/api/sync/start":
                return await self.smartinvention_adapter.start_sync(request_data)
            
            elif endpoint == "/api/sync/status":
                return await self.smartinvention_adapter.get_sync_status(request_data)
            
            else:
                return {
                    "success": False,
                    "error": f"æœªçŸ¥çš„Smartinventionç«¯é»: {endpoint}",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"è™•ç†Smartinventionè«‹æ±‚å¤±æ•— {endpoint}: {e}")
            return {
                "success": False,
                "error": str(e),
                "endpoint": endpoint,
                "timestamp": datetime.now().isoformat()
            }
    
    async def handle_unified_request(self, endpoint: str, request_data: Dict) -> Dict:
        """çµ±ä¸€è«‹æ±‚è™•ç† - æ•´åˆAICoreå’ŒSmartinventionç«¯é»"""
        from config.endpoint_mapping import is_smartinvention_endpoint, is_aicore_endpoint
        
        try:
            if is_smartinvention_endpoint(endpoint):
                # è™•ç†Smartinventionç›¸é—œè«‹æ±‚
                return await self.handle_smartinvention_request(endpoint, request_data)
            
            elif is_aicore_endpoint(endpoint):
                # è™•ç†AICoreæ ¸å¿ƒè«‹æ±‚
                return await self.handle_aicore_request(endpoint, request_data)
            
            else:
                return {
                    "success": False,
                    "error": f"æœªçŸ¥ç«¯é»: {endpoint}",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"çµ±ä¸€è«‹æ±‚è™•ç†å¤±æ•— {endpoint}: {e}")
            return {
                "success": False,
                "error": str(e),
                "endpoint": endpoint,
                "timestamp": datetime.now().isoformat()
            }
    
    async def handle_aicore_request(self, endpoint: str, request_data: Dict) -> Dict:
        """è™•ç†AICoreæ ¸å¿ƒè«‹æ±‚"""
        try:
            if endpoint == "/api/aicore/process":
                # è™•ç†æ ¸å¿ƒè«‹æ±‚
                user_request = UserRequest(
                    id=request_data.get("id", f"req_{int(time.time())}"),
                    content=request_data.get("content", ""),
                    context=request_data.get("context", {}),
                    priority=request_data.get("priority", "normal")
                )
                result = await self.process_request(user_request)
                return {
                    "success": result.success,
                    "result": asdict(result),
                    "timestamp": datetime.now().isoformat()
                }
            
            elif endpoint == "/api/aicore/status":
                return await self.get_system_status()
            
            elif endpoint == "/api/aicore/experts":
                experts = await self.dynamic_expert_registry.get_all_experts()
                return {
                    "success": True,
                    "experts": [asdict(expert) for expert in experts],
                    "count": len(experts),
                    "timestamp": datetime.now().isoformat()
                }
            
            elif endpoint == "/api/aicore/tools":
                tools = await self.tool_registry.get_all_tools()
                return {
                    "success": True,
                    "tools": [asdict(tool) for tool in tools],
                    "count": len(tools),
                    "timestamp": datetime.now().isoformat()
                }
            
            else:
                return {
                    "success": False,
                    "error": f"æœªçŸ¥çš„AICoreç«¯é»: {endpoint}",
                    "timestamp": datetime.now().isoformat()
                }
                
        except Exception as e:
            logger.error(f"è™•ç†AICoreè«‹æ±‚å¤±æ•— {endpoint}: {e}")
            return {
                "success": False,
                "error": str(e),
                "endpoint": endpoint,
                "timestamp": datetime.now().isoformat()
            }
    
    async def get_system_status(self) -> Dict:
        """ç²å–ç³»çµ±æ•´é«”ç‹€æ…‹"""
        try:
            # ç²å–å„çµ„ä»¶ç‹€æ…‹
            smartinvention_health = await self.smartinvention_adapter.health_check() if self.smartinvention_adapter else {"healthy": False}
            
            # ç²å–å°ˆå®¶å’Œå·¥å…·çµ±è¨ˆ
            experts = await self.dynamic_expert_registry.get_all_experts()
            tools = await self.tool_registry.get_all_tools()
            
            return {
                "success": True,
                "system_status": {
                    "aicore_version": "3.0.0",
                    "components": {
                        "dynamic_expert_registry": True,
                        "tool_registry": True,
                        "smartinvention_adapter": smartinvention_health.get("healthy", False),
                        "general_processor": True,
                        "expert_aggregator": True
                    },
                    "statistics": {
                        "total_experts": len(experts),
                        "total_tools": len(tools),
                        "total_requests": self.performance_metrics["total_requests"],
                        "successful_requests": self.performance_metrics["successful_requests"],
                        "average_response_time": self.performance_metrics["average_response_time"]
                    },
                    "smartinvention_status": smartinvention_health
                },
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"ç²å–ç³»çµ±ç‹€æ…‹å¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

# å‰µå»ºAICore 3.0å¯¦ä¾‹çš„å·¥å» å‡½æ•¸
def create_aicore3() -> AICore3:
    """å‰µå»ºAICore 3.0å¯¦ä¾‹"""
    return AICore3()

# å°å‡ºä¸»è¦é¡å’Œå‡½æ•¸
__all__ = [
    "AICore3",
    "UserRequest", 
    "ExpertResponse",
    "ProcessingResult",
    "ProcessingStage",
    "create_aicore3"
]

