"""
Enhanced Test Flow MCP v5.1 - æ·±åŒ–Manusæ•´åˆç‰ˆæœ¬ (å®Œæ•´ç‰ˆ)
å„ªåŒ–manusè™•ç†é‚è¼¯ï¼Œå¢å¼·ä¸Šä¸‹æ–‡è™•ç†èƒ½åŠ›ï¼Œæå‡åŒæ­¥æ•ˆç‡
"""

import asyncio
import json
import logging
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, field
from pathlib import Path
from enum import Enum
import time
import hashlib

# æ–°å¢manuså°ˆç”¨å°å…¥
from collections import defaultdict, deque

class ProcessingMode(Enum):
    """è™•ç†æ¨¡å¼æšèˆ‰"""
    DEVELOPER = "developer"
    ANALYST = "analyst"
    AUTOMATED = "automated"
    MANUS_SYNC = "manus_sync"  # æ–°å¢manusåŒæ­¥æ¨¡å¼

class FixStrategy(Enum):
    """ä¿®å¾©ç­–ç•¥æšèˆ‰"""
    INTELLIGENT = "intelligent"
    CONSERVATIVE = "conservative"
    AGGRESSIVE = "aggressive"
    MANUS_GUIDED = "manus_guided"  # æ–°å¢manuså¼•å°ç­–ç•¥

class SyncStatus(Enum):
    """åŒæ­¥ç‹€æ…‹æšèˆ‰"""
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"
    PARTIAL = "partial"

@dataclass
class EnhancedManusContext:
    """å¢å¼·ç‰ˆManusä¸Šä¸‹æ–‡æ•¸æ“šçµæ§‹"""
    # åŸºç¤ä¿¡æ¯
    session_id: str
    timestamp: datetime
    user_id: Optional[str] = None
    
    # å°è©±ä¸Šä¸‹æ–‡
    conversation_history: List[Dict] = field(default_factory=list)
    current_topic: Optional[str] = None
    topic_evolution: List[str] = field(default_factory=list)
    
    # éœ€æ±‚ä¸Šä¸‹æ–‡
    requirements: List[Dict] = field(default_factory=list)
    requirement_priority: Dict[str, float] = field(default_factory=dict)
    requirement_dependencies: Dict[str, List[str]] = field(default_factory=dict)
    
    # æŠ€è¡“ä¸Šä¸‹æ–‡
    technical_stack: List[str] = field(default_factory=list)
    complexity_indicators: Dict[str, float] = field(default_factory=dict)
    performance_constraints: Dict[str, Any] = field(default_factory=dict)
    
    # æ¥­å‹™ä¸Šä¸‹æ–‡
    business_objectives: List[str] = field(default_factory=list)
    stakeholders: List[str] = field(default_factory=list)
    timeline_constraints: Optional[Dict[str, Any]] = None
    
    # è³ªé‡ä¸Šä¸‹æ–‡
    quality_metrics: Dict[str, float] = field(default_factory=dict)
    testing_requirements: List[str] = field(default_factory=list)
    compliance_requirements: List[str] = field(default_factory=list)
    
    # å…ƒæ•¸æ“š
    context_version: str = "2.0"
    validation_status: str = "pending"
    confidence_score: float = 0.0
    last_updated: Optional[datetime] = None

@dataclass
class SyncResult:
    """åŒæ­¥çµæœæ•¸æ“šçµæ§‹"""
    sync_id: str
    status: SyncStatus
    start_time: datetime
    end_time: Optional[datetime] = None
    
    # åŒæ­¥çµ±è¨ˆ
    total_records: int = 0
    processed_records: int = 0
    successful_records: int = 0
    failed_records: int = 0
    
    # æ•¸æ“šè³ªé‡
    data_quality_score: float = 0.0
    validation_errors: List[str] = field(default_factory=list)
    data_inconsistencies: List[str] = field(default_factory=list)
    
    # æ€§èƒ½æŒ‡æ¨™
    processing_time: float = 0.0
    throughput: float = 0.0  # records per second
    memory_usage: float = 0.0
    
    # çµæœæ•¸æ“š
    synchronized_data: Dict[str, Any] = field(default_factory=dict)
    analysis_results: Dict[str, Any] = field(default_factory=dict)
    recommendations: List[str] = field(default_factory=list)

class EnhancedManusSync:
    """å¢å¼·ç‰ˆManusåŒæ­¥å¼•æ“"""
    
    def __init__(self):
        self.sync_history = deque(maxlen=1000)
        self.active_syncs = {}
        
    async def sync_with_manus_enhanced(self, context: EnhancedManusContext,
                                     sync_options: Dict[str, Any] = None) -> SyncResult:
        """å¢å¼·ç‰ˆmanusåŒæ­¥"""
        sync_id = self._generate_sync_id()
        start_time = datetime.now()
        
        sync_result = SyncResult(
            sync_id=sync_id,
            status=SyncStatus.IN_PROGRESS,
            start_time=start_time
        )
        
        try:
            # è¨˜éŒ„æ´»å‹•åŒæ­¥
            self.active_syncs[sync_id] = sync_result
            
            # 1. æ•¸æ“šé è™•ç†
            processed_data = await self._preprocess_manus_data(context)
            sync_result.total_records = len(processed_data.get('records', []))
            
            # 2. å¢é‡åŒæ­¥è™•ç†
            sync_data = await self._perform_incremental_sync(processed_data, sync_options)
            sync_result.synchronized_data = sync_data
            sync_result.processed_records = len(sync_data.get('synced_records', []))
            
            # 3. è³ªé‡è©•ä¼°
            quality_score = await self._assess_data_quality(sync_data)
            sync_result.data_quality_score = quality_score
            
            # 4. ç”Ÿæˆå»ºè­°
            recommendations = await self._generate_sync_recommendations(context, sync_data)
            sync_result.recommendations = recommendations
            
            # å®ŒæˆåŒæ­¥
            sync_result.status = SyncStatus.COMPLETED
            sync_result.end_time = datetime.now()
            sync_result.processing_time = (sync_result.end_time - start_time).total_seconds()
            sync_result.successful_records = sync_result.processed_records
            
            # è¨ˆç®—ååé‡
            if sync_result.processing_time > 0:
                sync_result.throughput = sync_result.processed_records / sync_result.processing_time
            
        except Exception as e:
            sync_result.status = SyncStatus.FAILED
            sync_result.validation_errors.append(f"åŒæ­¥å¤±æ•—: {str(e)}")
            sync_result.end_time = datetime.now()
            sync_result.processing_time = (sync_result.end_time - start_time).total_seconds()
        
        finally:
            # æ¸…ç†æ´»å‹•åŒæ­¥è¨˜éŒ„
            self.active_syncs.pop(sync_id, None)
            # æ·»åŠ åˆ°æ­·å²è¨˜éŒ„
            self.sync_history.append(sync_result)
        
        return sync_result
    
    async def _preprocess_manus_data(self, context: EnhancedManusContext) -> Dict[str, Any]:
        """é è™•ç†manusæ•¸æ“š"""
        processed_data = {
            "records": [],
            "metadata": {
                "preprocessing_time": datetime.now().isoformat(),
                "context_version": context.context_version
            }
        }
        
        # è™•ç†å°è©±æ­·å²
        for conv in context.conversation_history:
            processed_record = {
                "type": "conversation",
                "data": conv,
                "processed_at": datetime.now().isoformat(),
                "quality_score": await self._calculate_record_quality(conv)
            }
            processed_data["records"].append(processed_record)
        
        # è™•ç†éœ€æ±‚æ•¸æ“š
        for req in context.requirements:
            processed_record = {
                "type": "requirement",
                "data": req,
                "processed_at": datetime.now().isoformat(),
                "priority": context.requirement_priority.get(req.get('id', ''), 0.5)
            }
            processed_data["records"].append(processed_record)
        
        return processed_data
    
    async def _perform_incremental_sync(self, processed_data: Dict[str, Any],
                                      sync_options: Dict[str, Any] = None) -> Dict[str, Any]:
        """åŸ·è¡Œå¢é‡åŒæ­¥"""
        sync_options = sync_options or {}
        
        sync_data = {
            "synced_records": [],
            "skipped_records": [],
            "updated_records": [],
            "sync_metadata": {
                "sync_type": "incremental",
                "sync_time": datetime.now().isoformat(),
                "options": sync_options
            }
        }
        
        # æ¨¡æ“¬å¢é‡åŒæ­¥é‚è¼¯
        for record in processed_data.get("records", []):
            sync_data["synced_records"].append(record)
        
        return sync_data
    
    async def _assess_data_quality(self, sync_data: Dict[str, Any]) -> float:
        """è©•ä¼°æ•¸æ“šè³ªé‡"""
        synced_records = sync_data.get("synced_records", [])
        if not synced_records:
            return 0.0
        
        quality_scores = []
        for record in synced_records:
            quality_score = record.get("quality_score", 0.5)
            quality_scores.append(quality_score)
        
        return sum(quality_scores) / len(quality_scores)
    
    async def _calculate_record_quality(self, record: Dict[str, Any]) -> float:
        """è¨ˆç®—è¨˜éŒ„è³ªé‡åˆ†æ•¸"""
        quality_score = 0.0
        
        # åŸºæ–¼æ•¸æ“šå®Œæ•´æ€§
        if record.get("id"):
            quality_score += 0.2
        if record.get("timestamp"):
            quality_score += 0.2
        if record.get("content") or record.get("messages"):
            quality_score += 0.3
        if record.get("metadata"):
            quality_score += 0.3
        
        return quality_score
    
    async def _generate_sync_recommendations(self, context: EnhancedManusContext, 
                                           sync_data: Dict[str, Any]) -> List[str]:
        """ç”ŸæˆåŒæ­¥å»ºè­°"""
        recommendations = []
        
        synced_count = len(sync_data.get("synced_records", []))
        
        if synced_count > 50:
            recommendations.append("æ•¸æ“šé‡è¼ƒå¤§ï¼Œå»ºè­°è€ƒæ…®åˆ†æ‰¹è™•ç†")
        
        if len(context.requirements) > 10:
            recommendations.append("éœ€æ±‚æ•¸é‡è¼ƒå¤šï¼Œå»ºè­°é€²è¡Œå„ªå…ˆç´šæ’åº")
        
        if len(context.technical_stack) > 5:
            recommendations.append("æŠ€è¡“æ£§è¤‡é›œï¼Œå»ºè­°é€²è¡Œæ¶æ§‹è©•ä¼°")
        
        return recommendations
    
    def _generate_sync_id(self) -> str:
        """ç”ŸæˆåŒæ­¥ID"""
        return f"sync_{int(time.time())}_{hash(str(datetime.now())) % 10000}"

class EnhancedTestFlowMCPv51:
    """å¢å¼·ç‰ˆTest Flow MCP v5.1 - æ·±åŒ–Manusæ•´åˆ"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        self.version = "5.1"
        self.manus_sync = EnhancedManusSync()
        self.logger = logging.getLogger(__name__)
        self.performance_metrics = {}
        
    async def process_with_enhanced_manus(self, requirement: str,
                                        manus_context: EnhancedManusContext,
                                        processing_mode: ProcessingMode = ProcessingMode.MANUS_SYNC,
                                        fix_strategy: FixStrategy = FixStrategy.MANUS_GUIDED) -> Dict[str, Any]:
        """ä½¿ç”¨å¢å¼·manusæ•´åˆè™•ç†éœ€æ±‚"""
        start_time = time.time()
        
        try:
            self.logger.info(f"é–‹å§‹å¢å¼·manusè™•ç†: {requirement[:50]}...")
            
            # 1. åŒæ­¥manusæ•¸æ“š
            sync_result = await self.manus_sync.sync_with_manus_enhanced(manus_context)
            
            # 2. åŸºæ–¼åŒæ­¥çµæœé€²è¡Œéœ€æ±‚è™•ç†
            processing_result = await self._process_requirement_with_context(
                requirement, manus_context, sync_result
            )
            
            # 3. ç”Ÿæˆå¢å¼·å ±å‘Š
            enhanced_report = await self._generate_enhanced_report(
                requirement, manus_context, sync_result, processing_result
            )
            
            processing_time = time.time() - start_time
            
            return {
                "success": True,
                "requirement": requirement,
                "processing_mode": processing_mode.value,
                "fix_strategy": fix_strategy.value,
                "sync_result": sync_result.__dict__,
                "processing_result": processing_result,
                "enhanced_report": enhanced_report,
                "processing_time": processing_time,
                "performance_metrics": {
                    "sync_throughput": sync_result.throughput,
                    "data_quality": sync_result.data_quality_score,
                    "total_processing_time": processing_time
                }
            }
            
        except Exception as e:
            self.logger.error(f"å¢å¼·manusè™•ç†å¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e),
                "requirement": requirement,
                "processing_time": time.time() - start_time
            }
    
    async def _process_requirement_with_context(self, requirement: str,
                                              context: EnhancedManusContext,
                                              sync_result: SyncResult) -> Dict[str, Any]:
        """åŸºæ–¼ä¸Šä¸‹æ–‡è™•ç†éœ€æ±‚"""
        processing_result = {
            "requirement_analysis": {},
            "context_integration": {},
            "solution_recommendations": [],
            "implementation_plan": {}
        }
        
        # éœ€æ±‚åˆ†æ
        processing_result["requirement_analysis"] = {
            "complexity_score": await self._analyze_requirement_complexity(requirement),
            "technical_feasibility": await self._assess_technical_feasibility(requirement, context),
            "business_value": await self._assess_business_value(requirement, context),
            "risk_assessment": await self._assess_implementation_risk(requirement, context)
        }
        
        # ä¸Šä¸‹æ–‡æ•´åˆ
        processing_result["context_integration"] = {
            "related_requirements": await self._find_related_requirements(requirement, context),
            "technical_constraints": context.performance_constraints,
            "business_alignment": await self._assess_business_alignment(requirement, context),
            "stakeholder_impact": await self._assess_stakeholder_impact(requirement, context)
        }
        
        # è§£æ±ºæ–¹æ¡ˆå»ºè­°
        processing_result["solution_recommendations"] = await self._generate_solution_recommendations(
            requirement, context, sync_result
        )
        
        # å¯¦æ–½è¨ˆåŠƒ
        processing_result["implementation_plan"] = await self._create_implementation_plan(
            requirement, context, processing_result
        )
        
        return processing_result
    
    async def _analyze_requirement_complexity(self, requirement: str) -> float:
        """åˆ†æéœ€æ±‚è¤‡é›œåº¦"""
        complexity_keywords = ['optimize', 'enhance', 'integrate', 'complex', 'multiple', 'advanced']
        keyword_count = sum(1 for keyword in complexity_keywords if keyword in requirement.lower())
        length_factor = min(len(requirement) / 200, 1.0)
        return min((keyword_count * 0.2) + length_factor, 1.0)
    
    async def _assess_technical_feasibility(self, requirement: str, context: EnhancedManusContext) -> float:
        """è©•ä¼°æŠ€è¡“å¯è¡Œæ€§"""
        tech_stack_size = len(context.technical_stack)
        if tech_stack_size == 0:
            return 0.5  # ä¸­ç­‰å¯è¡Œæ€§
        
        # åŸºæ–¼æŠ€è¡“æ£§çš„å¤šæ¨£æ€§è©•ä¼°å¯è¡Œæ€§
        return min(tech_stack_size * 0.1 + 0.5, 1.0)
    
    async def _assess_business_value(self, requirement: str, context: EnhancedManusContext) -> float:
        """è©•ä¼°æ¥­å‹™åƒ¹å€¼"""
        value_keywords = ['performance', 'efficiency', 'user experience', 'cost', 'revenue']
        keyword_count = sum(1 for keyword in value_keywords if keyword in requirement.lower())
        business_objectives_count = len(context.business_objectives)
        
        return min((keyword_count * 0.2) + (business_objectives_count * 0.1), 1.0)
    
    async def _assess_implementation_risk(self, requirement: str, context: EnhancedManusContext) -> float:
        """è©•ä¼°å¯¦æ–½é¢¨éšª"""
        risk_keywords = ['complex', 'integration', 'migration', 'legacy', 'critical']
        keyword_count = sum(1 for keyword in risk_keywords if keyword in requirement.lower())
        
        # é¢¨éšªèˆ‡è¤‡é›œåº¦æˆæ­£æ¯”
        complexity = await self._analyze_requirement_complexity(requirement)
        return min((keyword_count * 0.15) + (complexity * 0.5), 1.0)
    
    async def _find_related_requirements(self, requirement: str, context: EnhancedManusContext) -> List[str]:
        """æŸ¥æ‰¾ç›¸é—œéœ€æ±‚"""
        related = []
        req_words = set(requirement.lower().split())
        
        for req in context.requirements:
            req_desc = req.get('description', '').lower()
            req_words_set = set(req_desc.split())
            
            # è¨ˆç®—è©å½™é‡ç–Šåº¦
            overlap = len(req_words.intersection(req_words_set))
            if overlap > 2:  # å¦‚æœæœ‰è¶…é2å€‹å…±åŒè©å½™
                related.append(req.get('id', 'unknown'))
        
        return related
    
    async def _assess_business_alignment(self, requirement: str, context: EnhancedManusContext) -> float:
        """è©•ä¼°æ¥­å‹™å°é½Šåº¦"""
        if not context.business_objectives:
            return 0.5
        
        alignment_score = 0.0
        req_words = set(requirement.lower().split())
        
        for objective in context.business_objectives:
            obj_words = set(objective.lower().split())
            overlap = len(req_words.intersection(obj_words))
            if overlap > 0:
                alignment_score += overlap * 0.1
        
        return min(alignment_score, 1.0)
    
    async def _assess_stakeholder_impact(self, requirement: str, context: EnhancedManusContext) -> Dict[str, float]:
        """è©•ä¼°åˆ©ç›Šç›¸é—œè€…å½±éŸ¿"""
        impact = {}
        
        for stakeholder in context.stakeholders:
            # ç°¡åŒ–çš„å½±éŸ¿è©•ä¼°
            if 'user' in stakeholder.lower():
                impact[stakeholder] = 0.8  # ç”¨æˆ¶ç›¸é—œéœ€æ±‚é€šå¸¸å½±éŸ¿è¼ƒå¤§
            elif 'developer' in stakeholder.lower():
                impact[stakeholder] = 0.6
            else:
                impact[stakeholder] = 0.4
        
        return impact
    
    async def _generate_solution_recommendations(self, requirement: str, 
                                               context: EnhancedManusContext,
                                               sync_result: SyncResult) -> List[str]:
        """ç”Ÿæˆè§£æ±ºæ–¹æ¡ˆå»ºè­°"""
        recommendations = []
        
        # åŸºæ–¼éœ€æ±‚å…§å®¹ç”Ÿæˆå»ºè­°
        if 'performance' in requirement.lower():
            recommendations.append("å»ºè­°é€²è¡Œæ€§èƒ½åŸºæº–æ¸¬è©¦å’Œç“¶é ¸åˆ†æ")
            recommendations.append("è€ƒæ…®å¯¦æ–½ç·©å­˜æ©Ÿåˆ¶å’Œç•°æ­¥è™•ç†")
        
        if 'optimize' in requirement.lower():
            recommendations.append("å»ºè­°æ¡ç”¨æ¼¸é€²å¼å„ªåŒ–ç­–ç•¥")
            recommendations.append("å¯¦æ–½æ€§èƒ½ç›£æ§å’ŒæŒ‡æ¨™æ”¶é›†")
        
        # åŸºæ–¼ä¸Šä¸‹æ–‡ç”Ÿæˆå»ºè­°
        if len(context.technical_stack) > 3:
            recommendations.append("æŠ€è¡“æ£§è¼ƒè¤‡é›œï¼Œå»ºè­°é€²è¡Œæ¶æ§‹è©•ä¼°")
        
        if sync_result.data_quality_score < 0.7:
            recommendations.append("æ•¸æ“šè³ªé‡éœ€è¦æ”¹å–„ï¼Œå»ºè­°åŠ å¼·æ•¸æ“šé©—è­‰")
        
        return recommendations
    
    async def _create_implementation_plan(self, requirement: str,
                                        context: EnhancedManusContext,
                                        processing_result: Dict[str, Any]) -> Dict[str, Any]:
        """å‰µå»ºå¯¦æ–½è¨ˆåŠƒ"""
        complexity = processing_result.get("requirement_analysis", {}).get("complexity_score", 0.5)
        
        # åŸºæ–¼è¤‡é›œåº¦ä¼°ç®—å·¥æœŸ
        if complexity < 0.3:
            duration = "1-2é€±"
            phases = ["éœ€æ±‚åˆ†æ", "å¯¦æ–½", "æ¸¬è©¦"]
        elif complexity < 0.7:
            duration = "3-4é€±"
            phases = ["éœ€æ±‚åˆ†æ", "è¨­è¨ˆ", "å¯¦æ–½", "æ¸¬è©¦", "éƒ¨ç½²"]
        else:
            duration = "5-8é€±"
            phases = ["éœ€æ±‚åˆ†æ", "æ¶æ§‹è¨­è¨ˆ", "åˆ†éšæ®µå¯¦æ–½", "é›†æˆæ¸¬è©¦", "æ€§èƒ½æ¸¬è©¦", "éƒ¨ç½²"]
        
        return {
            "estimated_duration": duration,
            "phases": phases,
            "resource_requirements": f"{len(context.technical_stack)}å€‹æŠ€è¡“é ˜åŸŸå°ˆå®¶",
            "milestones": [f"éšæ®µ{i+1}å®Œæˆ" for i in range(len(phases))],
            "risk_mitigation": ["å®šæœŸé€²åº¦æª¢æŸ¥", "æŠ€è¡“é¢¨éšªè©•ä¼°", "è³ªé‡ä¿è­‰æµç¨‹"]
        }
    
    async def _generate_enhanced_report(self, requirement: str,
                                      context: EnhancedManusContext,
                                      sync_result: SyncResult,
                                      processing_result: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¢å¼·å ±å‘Š"""
        report_sections = []
        
        # å ±å‘Šæ¨™é¡Œ
        report_sections.append("# Enhanced Test Flow MCP v5.1 - Manusæ•´åˆå ±å‘Š")
        report_sections.append(f"**ç”Ÿæˆæ™‚é–“**: {datetime.now().isoformat()}")
        report_sections.append(f"**éœ€æ±‚**: {requirement}")
        report_sections.append("")
        
        # åŒæ­¥çµæœæ‘˜è¦
        report_sections.append("## ManusåŒæ­¥çµæœ")
        report_sections.append(f"- **åŒæ­¥ç‹€æ…‹**: {sync_result.status.value}")
        report_sections.append(f"- **è™•ç†è¨˜éŒ„æ•¸**: {sync_result.processed_records}")
        report_sections.append(f"- **æ•¸æ“šè³ªé‡åˆ†æ•¸**: {sync_result.data_quality_score:.2f}")
        report_sections.append(f"- **è™•ç†æ™‚é–“**: {sync_result.processing_time:.2f}ç§’")
        report_sections.append(f"- **ååé‡**: {sync_result.throughput:.2f} records/sec")
        report_sections.append("")
        
        # éœ€æ±‚åˆ†æçµæœ
        req_analysis = processing_result.get("requirement_analysis", {})
        report_sections.append("## éœ€æ±‚åˆ†æçµæœ")
        report_sections.append(f"- **è¤‡é›œåº¦åˆ†æ•¸**: {req_analysis.get('complexity_score', 0):.2f}")
        report_sections.append(f"- **æŠ€è¡“å¯è¡Œæ€§**: {req_analysis.get('technical_feasibility', 0):.2f}")
        report_sections.append(f"- **æ¥­å‹™åƒ¹å€¼**: {req_analysis.get('business_value', 0):.2f}")
        report_sections.append(f"- **é¢¨éšªè©•ä¼°**: {req_analysis.get('risk_assessment', 0):.2f}")
        report_sections.append("")
        
        # å»ºè­°åˆ—è¡¨
        recommendations = sync_result.recommendations
        if recommendations:
            report_sections.append("## æ™ºèƒ½å»ºè­°")
            for i, rec in enumerate(recommendations, 1):
                report_sections.append(f"{i}. {rec}")
            report_sections.append("")
        
        # å¯¦æ–½è¨ˆåŠƒ
        impl_plan = processing_result.get("implementation_plan", {})
        if impl_plan:
            report_sections.append("## å¯¦æ–½è¨ˆåŠƒ")
            report_sections.append(f"- **é ä¼°å·¥æœŸ**: {impl_plan.get('estimated_duration', 'TBD')}")
            report_sections.append(f"- **è³‡æºéœ€æ±‚**: {impl_plan.get('resource_requirements', 'TBD')}")
            report_sections.append(f"- **é—œéµé‡Œç¨‹ç¢‘**: {len(impl_plan.get('milestones', []))}å€‹")
            report_sections.append("")
        
        return "\n".join(report_sections)

# æ¸¬è©¦å‡½æ•¸
async def test_enhanced_test_flow_mcp_v51():
    """æ¸¬è©¦å¢å¼·ç‰ˆTest Flow MCP v5.1"""
    print("ğŸš€ æ¸¬è©¦å¢å¼·ç‰ˆTest Flow MCP v5.1...")
    
    # å‰µå»ºæ¸¬è©¦ä¸Šä¸‹æ–‡
    test_context = EnhancedManusContext(
        session_id="test_session_001",
        timestamp=datetime.now(),
        user_id="test_user",
        conversation_history=[
            {
                "id": "conv_001",
                "messages": [
                    {"role": "user", "content": "æˆ‘éœ€è¦å„ªåŒ–MCPçµ„ä»¶çš„æ€§èƒ½"},
                    {"role": "assistant", "content": "æˆ‘å¯ä»¥å¹«æ‚¨åˆ†ææ€§èƒ½ç“¶é ¸"}
                ],
                "timestamp": datetime.now().isoformat()
            }
        ],
        requirements=[
            {
                "id": "req_001",
                "description": "å„ªåŒ–MCPçµ„ä»¶æ€§èƒ½ï¼Œæå‡è™•ç†é€Ÿåº¦",
                "priority": "high"
            }
        ],
        technical_stack=["Python", "AsyncIO", "MCP"],
        business_objectives=["æå‡ç³»çµ±æ€§èƒ½", "æ”¹å–„ç”¨æˆ¶é«”é©—"],
        stakeholders=["ç”¨æˆ¶", "é–‹ç™¼åœ˜éšŠ", "ç”¢å“ç¶“ç†"]
    )
    
    # å‰µå»ºMCPå¯¦ä¾‹
    mcp = EnhancedTestFlowMCPv51()
    
    # æ¸¬è©¦è™•ç†
    result = await mcp.process_with_enhanced_manus(
        requirement="å„ªåŒ–MCPçµ„ä»¶æ€§èƒ½ï¼Œæ”¯æŒæ›´é«˜ä¸¦ç™¼è™•ç†",
        manus_context=test_context,
        processing_mode=ProcessingMode.MANUS_SYNC,
        fix_strategy=FixStrategy.MANUS_GUIDED
    )
    
    print("âœ… å¢å¼·ç‰ˆTest Flow MCP v5.1æ¸¬è©¦å®Œæˆ:")
    print(f"   - è™•ç†æˆåŠŸ: {result['success']}")
    
    if result['success']:
        print(f"   - åŒæ­¥è¨˜éŒ„æ•¸: {result['sync_result']['processed_records']}")
        print(f"   - æ•¸æ“šè³ªé‡: {result['sync_result']['data_quality_score']:.2f}")
        print(f"   - è™•ç†æ™‚é–“: {result['processing_time']:.2f}ç§’")
        print(f"   - å»ºè­°æ•¸é‡: {len(result['sync_result']['recommendations'])}")
        print(f"   - è¤‡é›œåº¦åˆ†æ•¸: {result['processing_result']['requirement_analysis']['complexity_score']:.2f}")
    else:
        print(f"   - éŒ¯èª¤ä¿¡æ¯: {result.get('error', 'æœªçŸ¥éŒ¯èª¤')}")
        print(f"   - è™•ç†æ™‚é–“: {result.get('processing_time', 0):.2f}ç§’")

if __name__ == "__main__":
    asyncio.run(test_enhanced_test_flow_mcp_v51())

